{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2462811a",
   "metadata": {},
   "source": [
    "# S3W8D1: 统一接口封装 (The Universal Adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad461cbe",
   "metadata": {},
   "source": [
    "\n",
    "### 📂 1. 今日工作区准备\n",
    "\n",
    "请在终端执行以下命令，创建目录并启动 Notebook：\n",
    "\n",
    "```bash\n",
    "mkdir -p stage3/week8/data\n",
    "# 建议的文件名：\n",
    "touch stage3/week8/S3W8D1_LLM_Interface_Basics.ipynb\n",
    "```\n",
    "\n",
    "**文件名确认**：`S3W8D1_LLM_Interface_Basics.ipynb`\n",
    "\n",
    "接下来，请打开这个 Notebook，我们将分三步完成今天的任务。\n",
    "\n",
    "-----\n",
    "\n",
    "### 🧪 2. Notebook 实验环节 (交互式学习)\n",
    "\n",
    "#### **Step 1: 环境配置与密钥管理**\n",
    "\n",
    "在 Notebook 的第一个 Cell 中，我们需要安装依赖并设置环境变量。\n",
    "**注意**：为了防止密钥泄露到 Git 仓库，**永远不要**把 API Key 硬编码在代码里，而是使用 `.env` 文件。\n",
    "\n",
    "**操作：**\n",
    "\n",
    "1.  在项目根目录（`project_root/`）新建一个 `.env` 文件：\n",
    "    ```text\n",
    "    # .env 文件内容 (替换为你申请的 Key，建议用 DeepSeek 或 Moonshot)\n",
    "    LLM_API_KEY=sk-xxxxxxxxxxxxxxxxxxxx\n",
    "    LLM_BASE_URL=https://api.deepseek.com\n",
    "    # 或者 Moonshot: https://api.moonshot.cn/v1\n",
    "    ```\n",
    "2.  在 Notebook 中运行：\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```python\n",
    "# Cell 1\n",
    "!pip install openai python-dotenv\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载 .env 环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# 验证加载是否成功 (不要打印出完整的 Key，只打印前几位)\n",
    "api_key = os.getenv(\"LLM_API_KEY\")\n",
    "base_url = os.getenv(\"LLM_BASE_URL\")\n",
    "\n",
    "print(f\"Base URL: {base_url}\")\n",
    "print(f\"API Key loaded: {'Yes' if api_key else 'No'} ({api_key[:4]}...)\")\n",
    "```\n",
    "\n",
    "#### **Step 2: 编写与测试 LLMClient 类**\n",
    "\n",
    "在 Notebook 中定义类，方便随时修改调试。我们需要处理 **网络错误** 和 **参数配置**。\n",
    "\n",
    "```python\n",
    "# Cell 2\n",
    "from openai import OpenAI\n",
    "from typing import Optional\n",
    "\n",
    "class LLMClient:\n",
    "    def __init__(self, \n",
    "                 api_key: Optional[str] = None, \n",
    "                 base_url: Optional[str] = None, \n",
    "                 model: str = \"deepseek-chat\"): # 根据你的服务商修改默认模型名\n",
    "        \n",
    "        self.api_key = api_key or os.getenv(\"LLM_API_KEY\")\n",
    "        self.base_url = base_url or os.getenv(\"LLM_BASE_URL\")\n",
    "        self.model = model\n",
    "        \n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"API Key 未找到，请检查 .env 文件或参数传入\")\n",
    "\n",
    "        # 初始化 OpenAI SDK\n",
    "        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)\n",
    "\n",
    "    def generate(self, prompt: str, system_prompt: str = \"You are a helpful assistant.\", temperature: float = 0.7) -> str:\n",
    "        \"\"\"\n",
    "        生成回复\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                max_tokens=512 # 防止生成过长\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        \n",
    "        except Exception as e:\n",
    "            # 面试加分点：生产环境中这里应该接入日志系统 (logging)\n",
    "            print(f\"[Error]生成失败: {e}\")\n",
    "            return \"Error: 模型调用失败，请检查网络或Key。\"\n",
    "\n",
    "# 实例化测试\n",
    "client = LLMClient()\n",
    "print(\"测试连接...\")\n",
    "print(client.generate(\"你好，请做个自我介绍。\"))\n",
    "```\n",
    "\n",
    "#### **Step 3: Temperature 实验 (面试核心考点)**\n",
    "\n",
    "这是今天的重头戏。我们要直观感受 `Temperature` 对输出分布的影响。\n",
    "\n",
    "> **医学图像类比**：\n",
    ">\n",
    ">   * **Temperature -\\> 0**: 像是把图像分割的 **二值化阈值 (Thresholding)** 卡得很死。稍微有点不确定的像素直接丢弃，只保留概率最高的区域。结果非常锐利、确定，但可能丢失边缘细节。\n",
    ">   * **Temperature -\\> High**: 像是引入了 **高斯噪声**。虽然可能捕捉到更多潜在特征，但也可能把噪点当成病灶（产生幻觉）。\n",
    "\n",
    "在 Notebook 中运行以下对比代码：\n",
    "\n",
    "```python\n",
    "# Cell 3\n",
    "prompt = \"请用3个词形容春天。\"\n",
    "\n",
    "print(\"--- Temperature = 0.1 (严谨/确定) ---\")\n",
    "for _ in range(3):\n",
    "    print(client.generate(prompt, temperature=0.1))\n",
    "\n",
    "print(\"\\n--- Temperature = 0.9 (发散/创造) ---\")\n",
    "for _ in range(3):\n",
    "    print(client.generate(prompt, temperature=0.9))\n",
    "    \n",
    "print(\"\\n--- Temperature = 1.8 (极端/混乱) ---\")\n",
    "for _ in range(3):\n",
    "    print(client.generate(prompt, temperature=1.8))\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "### 🧠 3. 深度原理 (面试官视角)\n",
    "\n",
    "在你运行完上述代码后，请仔细阅读这一段，这是你能否过面试的关键。\n",
    "\n",
    "#### **Q1: Temperature 数学原理**\n",
    "\n",
    "面试官问：“为什么 Temperature 变高，输出就变乱了？”\n",
    "\n",
    "**回答逻辑**：\n",
    "LLM 输出的本质是词表中每个 token 的 Logits（未归一化的分数）。Softmax 函数将 Logits 转化为概率。加入 Temperature ($T$) 后的公式为：\n",
    "\n",
    "$$P_i = \\frac{\\exp(z_i / T)}{\\sum_j \\exp(z_j / T)}$$\n",
    "\n",
    "  * $z_i$ 是第 $i$ 个词的 Logit。\n",
    "  * **当 $T \\to 0$ (低温)**：\n",
    "      * $z_i / T$ 变得非常大（如果 $z_i$ 是正数）或非常小。\n",
    "      * 指数运算 $\\exp$ 会极度放大最大值和其他值的差距。\n",
    "      * 结果：概率分布变成 **One-hot (尖峰)**，模型只选概率最大的那个词。**每次输出都一样。**\n",
    "  * **当 $T \\to \\infty$ (高温)**：\n",
    "      * $z_i / T \\to 0$。\n",
    "      * $\\exp(0) = 1$。\n",
    "      * 所有词的概率都趋近于相等（均匀分布）。\n",
    "      * 结果：模型开始随机抽样，甚至选出原本概率极低的生僻词（胡言乱语）。\n",
    "\n",
    "#### **Q2: 无状态 (Stateless)**\n",
    "\n",
    "面试官问：“OpenAI API 是 Stateless 的，这对开发有什么影响？”\n",
    "\n",
    "**回答逻辑**：\n",
    "\n",
    "  * **含义**：服务器不保存任何上下文。你发给它“你好”，它回“你好”。你再发“我是谁？”，它不知道你是谁，因为它忘了上一轮对话。\n",
    "  * **开发影响**：我们必须在客户端维护 **History (对话历史)**。每次请求时，都要把 `[SystemPrompt, User:你好, AI:你好, User:我是谁]` 这一整串 List 发给 API。\n",
    "  * **代价**：Token 消耗随着对话轮数增加而线性（甚至二次方）增长。\n",
    "\n",
    "-----\n",
    "\n",
    "### 🏗️ 4. 工程封装 (Refactoring)\n",
    "\n",
    "Notebook 跑通后，请把 `LLMClient` 类的代码正式写入工程文件。\n",
    "\n",
    "**操作：**\n",
    "把 Notebook 中的 `LLMClient` 类代码复制并粘贴到 `src/llm/client.py` 中。确保包含 `import os`, `dotenv` 等引用。\n",
    "\n",
    "-----\n",
    "\n",
    "### ✅ 5. 你的下一步\n",
    "\n",
    "完成以上步骤后，请在 Notebook 结尾运行一次从 `src` 导入的测试，确保封装成功：\n",
    "\n",
    "```python\n",
    "# Cell 4\n",
    "# 重新加载模块 (如果修改了 .py 文件需要这两行)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.llm.client import LLMClient\n",
    "\n",
    "# 最终验证\n",
    "final_client = LLMClient()\n",
    "print(final_client.generate(\"测试 src 模块封装是否成功\"))\n",
    "```\n",
    "\n",
    "**任务完成后，请回复“W8D1 笔记已完成，封装通过”，我们将进入 Day 2 的 Prompt Engineering 环节！**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
