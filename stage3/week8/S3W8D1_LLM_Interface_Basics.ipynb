{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2462811a",
   "metadata": {},
   "source": [
    "# S3W8D1: ç»Ÿä¸€æ¥å£å°è£… (The Universal Adapter)\n",
    "\n",
    "**ğŸ¯ ä»Šæ—¥ç›®æ ‡**\n",
    "\n",
    "1.  **å·¥ç¨‹åŸºå»º**ï¼šå®Œæˆ OpenAI SDK çš„ç¯å¢ƒé…ç½®ä¸å¯†é’¥ç®¡ç†ã€‚\n",
    "2.  **æ ¸å¿ƒä»£ç **ï¼šå°è£… `LLMClient` ç±»ï¼Œå®ç°æ¨¡å‹æ— å…³çš„è°ƒç”¨æ¥å£ã€‚\n",
    "3.  **åŸç†æ·±æŒ–**ï¼šé€šè¿‡å®éªŒç†è§£ `Temperature` å‚æ•°çš„æ•°å­¦æœ¬è´¨ï¼ˆSoftmax ç¼©æ”¾ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8fd8a0",
   "metadata": {},
   "source": [
    "## ğŸ“– 2. ç†è®ºçŸ¥è¯†è®²è§£ (Theory & Analogy)\n",
    "\n",
    "**ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦å°è£…ä¸€ä¸ª `LLMClient`ï¼Ÿ**\n",
    "\n",
    "> **ğŸ§¬ åŒ»å­¦å›¾åƒç±»æ¯”ï¼šé€šç”¨æ‰«ææ¥å£ (Scanner Interface)**\n",
    ">\n",
    "> æƒ³è±¡ä½ åœ¨å¼€å‘ä¸€å¥—åŒ»ç–— AI ç³»ç»Ÿã€‚åŒ»é™¢é‡Œæœ‰ GEã€è¥¿é—¨å­ã€é£åˆ©æµ¦ç­‰ä¸åŒå“ç‰Œçš„ CT æœºã€‚\n",
    ">\n",
    ">   * å¦‚æœä½ åœ¨ä¸šåŠ¡ä»£ç é‡Œå†™ï¼š`if machine == 'GE': do_this() elif machine == 'Siemens': do_that()`ï¼Œä½ çš„ä»£ç ä¼šå˜å¾—æå…¶è‡ƒè‚¿ä¸”éš¾ä»¥ç»´æŠ¤ã€‚\n",
    ">   * æ­£ç¡®çš„åšæ³•æ˜¯å†™ä¸€ä¸ª **é€‚é…å™¨ (Adapter)**ï¼šæ— è®ºåº•å±‚è¿æ¥çš„æ˜¯å“ªå°æœºå™¨ï¼Œåå‡ºæ¥çš„éƒ½æ˜¯æ ‡å‡†çš„ DICOM æ ¼å¼æ•°æ®ã€‚\n",
    ">\n",
    "> **å¯¹åº”åˆ° NLP**ï¼š\n",
    ">\n",
    ">   * **åº•å±‚æœºå™¨**ï¼šOpenAI (GPT-4), DeepSeek, Moonshot, Llama3 (Local)ã€‚\n",
    ">   * **é€‚é…å™¨**ï¼š`LLMClient`ã€‚\n",
    ">   * **ä¸Šå±‚ä¸šåŠ¡**ï¼šRAG æ£€ç´¢ã€Agent å·¥å…·è°ƒç”¨ã€èŠå¤©æœºå™¨äººã€‚\n",
    ">\n",
    "> æˆ‘ä»¬ä»Šå¤©çš„ä»»åŠ¡ï¼Œå°±æ˜¯å†™å¥½è¿™ä¸ªâ€œé€‚é…å™¨â€ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f5a3f0",
   "metadata": {},
   "source": [
    "## ğŸ’» 3 ä»£ç å®ç°\n",
    "\n",
    "### 3.1 ç¯å¢ƒäºå¯†é’¥é…ç½®\n",
    "\n",
    "1.  åœ¨é¡¹ç›®æ ¹ç›®å½•æ–°å»º`.env`æ–‡ä»¶ï¼š\n",
    "    ```text\n",
    "    LLM_API_KEY=sk-å¯†é’¥\n",
    "    LLM_BASE_URL=https://api.deepseek.com æˆ– https://api.moonshot.cn/v1\n",
    "    ```\n",
    "2.  ä»£ç æµ‹è¯•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db93f9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key loaded: Yes (sk-y...)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "key = os.getenv(\"LLM_API_KEY\")\n",
    "print(f\"Key loaded: {'Yes' if key else 'No'} ({key[:4]}...)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8d0deb",
   "metadata": {},
   "source": [
    "### 3.2 æ ¸å¿ƒç±»å°è£…\n",
    "\n",
    "è¿™ä¸ªç±»å°†ä½œä¸ºåç»­æ‰€æœ‰ AI åŠŸèƒ½çš„åŸºçŸ³ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaec4d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é€’å½’æ˜¯ä¸€ç§è§£å†³é—®é¢˜çš„æ–¹æ³•ï¼Œå…¶ä¸­å‡½æ•°ä¸æ–­è°ƒç”¨è‡ªèº«ï¼Œå°†å¤§é—®é¢˜è½¬åŒ–ä¸ºå°é—®é¢˜ï¼Œé€æ­¥ç¼©å°é—®é¢˜è§„æ¨¡ç›´è‡³è§£å†³ã€‚\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from typing import Optional\n",
    "\n",
    "class LLMClient:\n",
    "    def __init__(self, \n",
    "                 api_key: Optional[str] = None, \n",
    "                 base_url: Optional[str] = None, \n",
    "                 model: str = \"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B\"):\n",
    "        \n",
    "        self.api_key = api_key or os.getenv(\"LLM_API_KEY\")\n",
    "        self.base_url = base_url or os.getenv(\"LLM_BASE_URL\")\n",
    "        self.model = model\n",
    "        \n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"API Key Missing! Please check .env file.\")\n",
    "\n",
    "        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)\n",
    "\n",
    "    def generate(self, prompt: str, system_prompt: str = \"You are a helpful assistant.\", temperature: float = 0.7) -> str:\n",
    "        \"\"\"\n",
    "        é€šç”¨ç”Ÿæˆæ¥å£\n",
    "        :param temperature: æ§åˆ¶ç”Ÿæˆçš„éšæœºæ€§ (0.0 - 2.0)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                max_tokens=512 \n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"[Generate Error]: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "# æµ‹è¯•\n",
    "llm = LLMClient()\n",
    "print(llm.generate(\"ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯é€’å½’ï¼Ÿ\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be815da",
   "metadata": {},
   "source": [
    "### 3.3 Temperatureå®éªŒ\n",
    "\n",
    "è¿è¡Œæ­¤ä»£ç ï¼Œç›´è§‚æ„Ÿå—å‚æ•°å˜åŒ–ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54cce136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- T=0.1 (ç¨³å®š/ä¿å®ˆ) ---\n",
      "å¥½çš„ï¼Œè¿™é‡Œæœ‰ä¸‰ä¸ªé€‚åˆåˆšå‡ºç”Ÿçš„æ©™è‰²å°çŒ«çš„åå­—ï¼š\n",
      "\n",
      "1. **æ©˜å®**ï¼šç›´æ¥ç‚¹æ˜äº†å°çŒ«çš„æ¯›è‰²ï¼ˆæ©˜è‰²ï¼‰ï¼Œâ€œå®â€å­—åˆ™è¡¨è¾¾äº†å¯¹è¿™åªå°ç”Ÿå‘½çš„ççˆ±å’Œå–œçˆ±ã€‚\n",
      "2. **å°ç„°**ï¼šæ©™è‰²è®©äººè”æƒ³åˆ°ç«ç„°ï¼Œè¿™ä¸ªåå­—å……æ»¡äº†æ´»åŠ›å’Œæ¸©æš–çš„æ„Ÿè§‰ï¼Œå¾ˆé€‚åˆæ´»æ³¼çš„å°çŒ«å’ªã€‚\n",
      "3. **æš–æš–**ï¼šä¸ä»…æŒ‡é¢œè‰²åƒæ©˜å­ä¸€æ ·æ¸©æš–ï¼Œä¹Ÿå¯“æ„ç€å°çŒ«èƒ½ç»™å®¶é‡Œå¸¦æ¥æ¸©æš–å’Œå¿«ä¹ã€‚\n",
      "\n",
      "å¸Œæœ›è¿™äº›å»ºè®®èƒ½å¸®åˆ°ä½ ï¼\n",
      "\n",
      "--- T=1.5 (å‘æ•£/å¯èƒ½èƒ¡è¨€ä¹±è¯­) ---\n",
      "ä»¥ä¸‹æ˜¯3ä¸ªé€‚åˆæ©™è‰²å°çŒ«çš„åå­—å»ºè®®ï¼š\n",
      "\n",
      "1. *###ğŸ˜°ğŸ˜¨Github  \n",
      "Want \"å¥½çŒ«åå­—\"ëƒ¥  \n",
      "Don't see upcomingğŸ”™  .WaitFor notificationğŸ“ƒğŸ—ºğŸ—‚ğŸ¾âœ¨\n",
      "\n",
      "å¦‚æœä½ å …æŒé€™å€‹æ ¼å¼caté¸ ä¸å¹«å·æ ¸æ»‘æ¯€æ˜¯çŒ«å¡Œã‘ã©\n",
      "\n",
      "åŒ…éš»è‹±æ–‡å…©å€‹å¾äººå‰¯á˜BoundingClientRectå–Šå¯µé¢¨ç·šï¿½â›ï¼ˆğŸ”¬ ğŸ”¢ğŸ”´#ğŸ¯ğŸ›‘â­•ğŸ”â™sPid++){\n",
      "ç´¢ç¢³ç›’å­ğŸ©ğŸ»ğŸ–ğŸ”ğŸ”‘         \n",
      "}ğŸ§ ğŸŒ“ê±â†’â”˜â†“âš \n"
     ]
    }
   ],
   "source": [
    "prompt = \"è¯·ä¸ºä¸€åªåˆšå‡ºç”Ÿçš„æ©™è‰²å°çŒ«èµ·3ä¸ªåå­—ã€‚\"\n",
    "\n",
    "print(\"--- T=0.1 (ç¨³å®š/ä¿å®ˆ) ---\")\n",
    "print(llm.generate(prompt, temperature=0.1))\n",
    "\n",
    "print(\"\\n--- T=1.5 (å‘æ•£/å¯èƒ½èƒ¡è¨€ä¹±è¯­) ---\")\n",
    "print(llm.generate(prompt, temperature=1.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce94f548",
   "metadata": {},
   "source": [
    "## ğŸ§  4. æ·±åº¦ç†è®º (Deep Dive)\n",
    "\n",
    "è¿™æ˜¯ä½ åŒºåˆ«äºæ™®é€šæ‰åŒ…ä¾ çš„å…³é”®ã€‚è¯·ä»”ç»†é˜…è¯»å¹¶ç†è§£ã€‚\n",
    "\n",
    "### 4.1 Temperatureçš„æ•°å­¦æœ¬è´¨\n",
    "\n",
    "é¢è¯•å®˜å¸¸é—®ï¼šâ€œTemperatureåˆ°åº•æ”¹å˜äº†ä»€ä¹ˆï¼Ÿâ€\n",
    "\n",
    "ç­”æ¡ˆï¼š**â€œå®ƒæ”¹å˜äº†Softmaxå‡½æ•°çš„å¹³æ»‘ç¨‹åº¦ã€‚â€**\n",
    "\n",
    "æ¨¡å‹è¾“å‡ºçš„æ˜¯Logitsï¼ˆæœªå½’ä¸€åŒ–çš„åˆ†æ•°$z_i$ï¼‰ã€‚å¸¦æœ‰Temperature $T$çš„Softmaxå…¬å¼ä¸ºï¼š\n",
    "\n",
    "$$P_i = \\frac{\\exp(z_i / T)}{\\sum_j \\exp(z_j / T)}$$\n",
    "\n",
    "\n",
    "- å½“$T<1$ (ä½æ¸©)ï¼š\n",
    "    - å·®è·è¢«**æ”¾å¤§**ã€‚å‡è®¾ Logits æ˜¯ `[2.0, 1.0]`ï¼Œå·®è·æ˜¯ 1ã€‚é™¤ä»¥ 0.1 åå˜æˆ `[20.0, 10.0]`ï¼Œå·®è·å˜æˆ 10ã€‚\n",
    "    - ç»è¿‡æŒ‡æ•°è¿ç®— $\\exp$ åï¼Œå¤§çš„å˜å¾—æå¤§ã€‚\n",
    "    - **æ•ˆæœ**ï¼šæ¦‚ç‡åˆ†å¸ƒè¶‹å‘äº **Argmax (One-hot)**ã€‚æ¨¡å‹å˜å¾—æå…¶è‡ªä¿¡ä¸”ä¿å®ˆï¼Œåªé€‰æ¦‚ç‡æœ€é«˜çš„è¯ã€‚**é€‚åˆï¼šä»£ç ç”Ÿæˆã€æ•°å­¦é¢˜ã€‚**\n",
    "\n",
    "- **å½“ $T > 1$ (é«˜æ¸©)**ï¼š\n",
    "    - å·®è·è¢«**ç¼©å°**ã€‚Logits `[2.0, 1.0]` é™¤ä»¥ 10 å˜æˆ `[0.2, 0.1]`ã€‚\n",
    "    - $\\exp$ è¿ç®—åï¼Œä¸¤è€…éå¸¸æ¥è¿‘ã€‚\n",
    "    - **æ•ˆæœ**ï¼šæ¦‚ç‡åˆ†å¸ƒè¶‹å‘äº **å‡åŒ€åˆ†å¸ƒ (Uniform Distribution)**ã€‚æ¨¡å‹æœ‰æ›´å¤§æ¦‚ç‡é€‰æ‹©æ¬¡é€‰è¯ã€‚**é€‚åˆï¼šåˆ›æ„å†™ä½œã€å¤´è„‘é£æš´ã€‚**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd8d02e",
   "metadata": {},
   "source": [
    "## ğŸ—£ï¸ 5. æ¨¡æ‹Ÿé¢è¯• (Mock Interview)\n",
    "\n",
    "è¯·å°è¯•ç”¨è‡ªå·±çš„è¯­è¨€å›ç­”ä»¥ä¸‹é—®é¢˜ï¼ˆé®ä½ç­”æ¡ˆï¼‰ï¼š\n",
    "\n",
    "**Q1: åœ¨åš RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç³»ç»Ÿæ—¶ï¼ŒTemperature åº”è¯¥è®¾ä¸ºå¤šå°‘ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ**\n",
    "\n",
    "**æˆ‘çš„å›ç­”**ï¼šåœ¨åšRAGç³»ç»Ÿæ—¶ï¼Œæ¸©åº¦éœ€è¦è®¾ç½®ä½ä¸€äº›ï¼Œå› ä¸ºåšæ£€ç´¢ç”Ÿæˆéœ€è¦è®©æ¨¡å‹ä¸¥æ ¼éµå®ˆä¸Šä¸‹æ–‡äº‹å®ï¼Œä¸å¸Œæœ›è®©æ¨¡å‹è¿‡äºå‘æ•£\n",
    "\n",
    "**å‚è€ƒç­”æ¡ˆ**ï¼šåœ¨ RAG åœºæ™¯ä¸‹ï¼Œæˆ‘é€šå¸¸ä¼šå°† Temperature è®¾ä¸º 0 æˆ–æ¥è¿‘ 0 (å¦‚ 0.1)ã€‚åŸå› æ˜¯ RAG çš„æ ¸å¿ƒç›®æ ‡æ˜¯ â€˜åŸºäºæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ (Context) è¿›è¡Œå›ç­”â€™ï¼Œæˆ‘ä»¬éœ€è¦æ¨¡å‹å…·å¤‡æé«˜çš„ å¿ å®åº¦ (Faithfulness)ã€‚ å¦‚æœ Temperature è¿‡é«˜ï¼Œæ¨¡å‹ä¼šå€¾å‘äºå¿½ç•¥ Contextï¼Œå¼€å§‹åˆ©ç”¨é¢„è®­ç»ƒé˜¶æ®µçš„â€˜å‚æ•°è®°å¿†â€™è¿›è¡Œçç¼–ï¼Œè¿™ä¼šå¯¼è‡´ â€˜å¹»è§‰ (Hallucination)â€™ é—®é¢˜æ€¥å‰§å¢åŠ ã€‚ è¿™å°±åƒåŒ»å­¦å›¾åƒåˆ†å‰²ï¼Œæˆ‘ä»¬éœ€è¦çš„æ˜¯åŸºäºåƒç´ å€¼çš„â€˜ç¡®å®šæ€§è¾¹ç•Œâ€™ï¼Œè€Œä¸æ˜¯è®©æ¨¡å‹è‡ªå·±å»â€˜æƒ³è±¡â€™è‚¿ç˜¤åœ¨å“ªé‡Œã€‚â€\n",
    "\n",
    "**Q2: ä¸ºä»€ä¹ˆå¤§æ¨¡å‹çš„ API è°ƒç”¨æœ‰æ—¶ä¼šå¾ˆæ…¢ï¼Ÿ**\n",
    "\n",
    "**æˆ‘çš„å›ç­”**ï¼šå¦‚æœè°ƒç”¨åœ¨çº¿æ¨¡å‹ï¼Œé¦–å…ˆæˆ‘ä»¬éœ€è¦æ’é™¤ç½‘ç»œåŸå› ï¼Œå…¶æ¬¡æœ‰å¯èƒ½æ˜¯æˆ‘ä»¬è¾“å‡ºçš„Tokenè¿‡å¤šä¹Ÿä¼šå¯¼è‡´APIè°ƒç”¨å˜æ…¢ã€‚\n",
    "\n",
    "**å‚è€ƒç­”æ¡ˆ**ï¼šé™¤å»ç½‘ç»œå»¶è¿Ÿï¼Œæ ¸å¿ƒç“¶é¢ˆåœ¨äº LLM çš„ ç”Ÿæˆæœºåˆ¶ã€‚è¾“å…¥ç«¯ (Prefill é˜¶æ®µ)ï¼šTransformer å¤„ç†è¾“å…¥ Prompt æ˜¯ å¹¶è¡Œ (Parallel) çš„ï¼Œæ— è®ºè¾“å…¥ 10 ä¸ªå­—è¿˜æ˜¯ 1000 ä¸ªå­—ï¼Œæ˜¾å¡æ˜¯ä¸€æ¬¡æ€§åè¿›å»è®¡ç®— Attention çš„ï¼Œé€Ÿåº¦éå¸¸å¿«ã€‚è¾“å‡ºç«¯ (Decoding é˜¶æ®µ)ï¼šLLM æ˜¯ è‡ªå›å½’ (Auto-regressive) æ¨¡å‹ï¼Œå®ƒå¿…é¡» ä¸²è¡Œ ç”Ÿæˆã€‚ç”Ÿæˆç¬¬ N ä¸ª Token å¿…é¡»ä¾èµ–äºç¬¬ N-1 ä¸ª Token çš„ç»“æœã€‚è¿™æ„å‘³ç€ï¼Œç”Ÿæˆ 100 ä¸ª Token çš„æ—¶é—´ï¼Œç‰©ç†ä¸Šå°±æ˜¯ç”Ÿæˆ 1 ä¸ª Token æ—¶é—´çš„ 100 å€ï¼Œæ— æ³•é€šè¿‡å¹¶è¡Œè®¡ç®—æ¥åŠ é€Ÿã€‚æ‰€ä»¥ï¼ŒOutput Token æ•°é‡æ˜¯å†³å®šå»¶è¿Ÿ (Latency) çš„ç»å¯¹ä¸»å› ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56799a82",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ 6. å·¥ç¨‹å°è£… (Refactoring)\n",
    "\n",
    "å®éªŒç»“æŸåï¼Œè¯·åŠ¡å¿…å°†ä»£ç è¿ç§»åˆ°æ ‡å‡†ç›®å½•ï¼Œä¿æŒå·¥ç¨‹æ•´æ´ã€‚\n",
    "\n",
    "  * **æºæ–‡ä»¶**ï¼šä½ çš„ Notebook ä¸­çš„ `Class LLMClient`ã€‚\n",
    "  * **ç›®æ ‡æ–‡ä»¶**ï¼š`src/llm/client.py`ã€‚\n",
    "\n",
    "**æ“ä½œæ­¥éª¤**ï¼š\n",
    "\n",
    "1.  å°† Notebook ä¸­è°ƒè¯•å¥½çš„ç±»ä»£ç å¤åˆ¶åˆ° `src/llm/client.py`ã€‚\n",
    "2.  ç¡®ä¿ `src/llm/__init__.py` å­˜åœ¨ï¼ˆå¯ä»¥æ˜¯ç©ºæ–‡ä»¶ï¼‰ã€‚\n",
    "3.  åœ¨æ ¹ç›®å½•è¿è¡Œæµ‹è¯•ï¼š\n",
    "    ```bash\n",
    "    python -c \"from src.llm.client import LLMClient; print(LLMClient().generate('Refactoring success!'))\"\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7de38f5",
   "metadata": {},
   "source": [
    "## ğŸ§© 7. ä»Šæ—¥ LeetCode ç»ƒä¹ \n",
    "\n",
    "ä¿æŒæ‰‹æ„Ÿï¼Œä»Šå¤©æ¨èä¸¤é“ä¸â€œæ•°æ®ç»“æ„â€ç›¸å…³çš„é¢˜ç›®ï¼Œä¸ºåç»­ç†è§£â€œè®°å¿†é˜Ÿåˆ—â€åšé“ºå«ã€‚\n",
    "\n",
    "  * **é¢˜ç›® 1: Valid Parentheses (LC 20) - ç®€å•**\n",
    "      * *æ€è·¯*ï¼šæ ˆ (Stack)ã€‚è¿™å…¶å®å°±æ˜¯æœ€ç®€å•çš„ NLP è¯­æ³•æ£€æŸ¥ã€‚\n",
    "  * **é¢˜ç›® 2: Implement Queue using Stacks (LC 232) - ç®€å•**\n",
    "      * *æ€è·¯*ï¼šåŒæ ˆå®ç°é˜Ÿåˆ—ã€‚ç†è§£ FIFO (å…ˆè¿›å…ˆå‡º) çš„æ¦‚å¿µï¼Œå¯¹è¯å†å²ç®¡ç† (Memory) æœ¬è´¨ä¸Šå°±æ˜¯ä¸€ä¸ª Queueã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7078fa0a",
   "metadata": {},
   "source": [
    "## âœ… 8. ä»Šæ—¥ä»»åŠ¡æ€»ç»“\n",
    "\n",
    "  * [ ] æˆåŠŸç”³è¯·å¹¶é…ç½® LLM API Key (`.env` æ–‡ä»¶)ã€‚\n",
    "  * [ ] åœ¨ Notebook ä¸­è·‘é€š `LLMClient` ç±»ã€‚\n",
    "  * [ ] äº²çœ¼çœ‹åˆ° `Temperature=0.1` å’Œ `1.5` çš„è¾“å‡ºåŒºåˆ«ã€‚\n",
    "  * [ ] å°†ä»£ç å°è£…è¿› `src/llm/client.py` å¹¶é€šè¿‡æµ‹è¯•ã€‚\n",
    "  * [ ] ç†è§£ Softmax æ¸©åº¦ç¼©æ”¾å…¬å¼ã€‚\n",
    "\n",
    "**å®Œæˆåï¼Œè¯·å›å¤â€œW8D1 å®Œæˆâ€ï¼Œæˆ‘ä»¬æ˜å¤©è¿›å…¥ Prompt Engineering çš„æ ¸å¿ƒé¢†åŸŸï¼**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
