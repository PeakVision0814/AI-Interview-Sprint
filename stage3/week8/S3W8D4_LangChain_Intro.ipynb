{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bfea308",
   "metadata": {},
   "source": [
    "# S3W8D4: LangChain å…¥é—¨ (The Orchestrator)\n",
    "\n",
    "å‰ä¸‰å¤©æˆ‘ä»¬åƒæ˜¯åœ¨â€œæ‰‹æ“ä»£ç â€ï¼šæ‰‹åŠ¨å‘ HTTP è¯·æ±‚ã€æ‰‹åŠ¨æ‹¼ Prompt å­—ç¬¦ä¸²ã€æ‰‹åŠ¨è§£æ JSONã€‚è™½ç„¶è¿™æ ·èƒ½è®©ä½ ç†è§£åº•å±‚åŸç†ï¼Œä½†åœ¨å¤§å‹é¡¹ç›®ï¼ˆå‡ åä¸ªæ­¥éª¤çš„ Agentï¼‰ä¸­ï¼Œè¿™ç§å†™æ³•ä¼šåƒé¢æ¡ä¸€æ ·æ··ä¹±ã€‚\n",
    "\n",
    "ä»Šå¤©ï¼Œæˆ‘ä»¬è¦å¼•å…¥ **AI åº”ç”¨å¼€å‘çš„â€œæ“ä½œç³»ç»Ÿâ€â€”â€”LangChain**ã€‚\n",
    "\n",
    "LangChain æœ€è¿·äººçš„åœ°æ–¹åœ¨äº **LCEL (LangChain Expression Language)**ï¼Œå®ƒè®©å†™ AI é€»è¾‘å˜å¾—åƒå†™ Linux ç®¡é“å‘½ä»¤ï¼ˆPipeï¼‰ä¸€æ ·ä¼˜é›…ã€‚\n",
    "\n",
    "**ğŸ¯ ä»Šæ—¥ç›®æ ‡**\n",
    "\n",
    "1. **ç¯å¢ƒé…ç½®**ï¼šç”¨ `LangChain` è¿æ¥ç¡…åŸºæµåŠ¨ (SiliconFlow) çš„ DeepSeek æ¨¡å‹ã€‚\n",
    "2. **æ ¸å¿ƒæ¦‚å¿µ**ï¼šæŒæ¡ `ChatPromptTemplate` å’Œ `LCEL` ç®¡é“å†™æ³• (`|`)ã€‚\n",
    "3. **é‡æ„å®æˆ˜**ï¼šç”¨ 3 è¡Œä»£ç é‡å†™å‰ 3 å¤©å†™äº† 50 è¡Œçš„â€œæ³•å¾‹æ„å›¾åˆ†ç±»å™¨â€ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4b93c4",
   "metadata": {},
   "source": [
    "## ğŸ“– 1 ç†è®ºçŸ¥è¯†è®²è§£ (Theory & Analogy)\n",
    "\n",
    "**ä¸ºä»€ä¹ˆè¦ç”¨ LangChainï¼Ÿ**\n",
    "\n",
    "> **ğŸ§¬ åŒ»å­¦å›¾åƒç±»æ¯”ï¼šæ‰‹åŠ¨å¤„ç† vs. Nipype æµæ°´çº¿**\n",
    "> * **Day 1-3 çš„å†™æ³•**ï¼šå°±åƒä½ ç”¨ Python æ‰‹å†™è„šæœ¬å¤„ç†åŒ»å­¦å›¾åƒã€‚\n",
    "> * `img = load_dicom(...)`\n",
    "> * `mask = unet_predict(img)`\n",
    "> * `report = generate_report(mask)`\n",
    "> * *ç—›ç‚¹*ï¼šå¦‚æœæˆ‘æƒ³æŠŠ U-Net æ¢æˆ ODP-Netï¼Œæˆ–è€…æƒ³åœ¨ predict å‰åŠ ä¸€ä¸ªâ€œå»å™ªâ€æ­¥éª¤ï¼Œæˆ‘å¾—å»æ”¹è¿™ä¸€å¤§å¨èƒ¶æ°´ä»£ç ã€‚\n",
    "> \n",
    "> \n",
    "> * **LangChain (LCEL)**ï¼šå°±åƒ **Nipype** æˆ– **Linux ç®¡é“**ã€‚\n",
    "> * `pipeline = Loader | Denoise | Segmentor | Reporter`\n",
    "> * *ä¼˜åŠ¿*ï¼š**æ¨¡å—åŒ–**ã€‚æˆ‘æƒ³æ¢æ¨¡å‹ï¼Ÿæ‹”ä¸‹æ¥æ’ä¸ªæ–°çš„ä¸Šå»å°±è¡Œã€‚æˆ‘æƒ³åŠ æ—¥å¿—ï¼Ÿä¸­é—´æ’ä¸ªç¯èŠ‚å°±è¡Œã€‚\n",
    "> \n",
    "> \n",
    "> \n",
    "> \n",
    "\n",
    "**LCEL è¯­æ³•æ ¸å¿ƒ**ï¼š\n",
    "\n",
    "\n",
    "\n",
    "ç¬¦å· `|` çš„æ„æ€æ˜¯ï¼š**å·¦è¾¹çš„è¾“å‡ºï¼Œè‡ªåŠ¨æˆä¸ºå³è¾¹çš„è¾“å…¥ã€‚**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fe5740",
   "metadata": {},
   "source": [
    "## ğŸ’» 2 ä»£ç å®ç° (Notebook å®éªŒ)\n",
    "\n",
    "### 2.1 è¿æ¥å¤§æ¨¡å‹ (The Model)\n",
    "\n",
    "LangChain æŠŠæ‰€æœ‰ LLM éƒ½æŠ½è±¡æˆäº† `ChatOpenAI` ç±»ï¼ˆä¸è¦è¢«åå­—è¿·æƒ‘ï¼Œåªè¦å…¼å®¹ OpenAI åè®®çš„éƒ½èƒ½ç”¨ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33aae527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ä½ å¥½å‘€ï¼æˆ‘æ˜¯ DeepSeek-R1ï¼Œä½ å¯ä»¥æŠŠæˆ‘å½“ä½œä¸€ä¸ªçŸ¥è¯†å°ä¼™ä¼´ï½ğŸ§ \n",
      "\n",
      "æˆ‘å¯ä»¥å¸®ä½ æŸ¥èµ„æ–™ã€å†™æ–‡ç« ã€è§£é¢˜ã€ç¿»è¯‘ã€å­¦ä¹ ã€åŠå…¬ã€èŠå¤©â€¦â€¦åªè¦ä½ æœ‰éœ€è¦ï¼Œæˆ‘éƒ½ä¼šå°½åŠ›å¸®å¿™ï¼è€Œä¸”æˆ‘24å°æ—¶åœ¨çº¿ï¼Œéšæ—¶ç­‰ä½ æ¥é—®ï½\n",
      "\n",
      "æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼ŸğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹ (LangChain å¸®ä½ å¤„ç†äº† API è°ƒç”¨ç»†èŠ‚)\n",
    "# æ³¨æ„ï¼šmodel_name è¦å¡«ä½ ç¡…åŸºæµåŠ¨çš„å®é™…æ¨¡å‹å\n",
    "llm = ChatOpenAI(\n",
    "    model=\"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B\",  # ä½ çš„æ¨¡å‹å\n",
    "    openai_api_key=os.getenv(\"LLM_API_KEY\"),\n",
    "    openai_api_base=os.getenv(\"LLM_BASE_URL\"),\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# æµ‹è¯•ä¸€ä¸‹ (ç›´æ¥ invoke)\n",
    "response = llm.invoke(\"ä½ å¥½ï¼Œä½ æ˜¯è°ï¼Ÿ\")\n",
    "print(response.content) \n",
    "# æ³¨æ„ï¼šè¿”å›çš„æ˜¯ä¸€ä¸ª AIMessage å¯¹è±¡ï¼Œä¸æ˜¯çº¯å­—ç¬¦ä¸²"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2857807d",
   "metadata": {},
   "source": [
    "### Step 2: æ¨¡æ¿ç®¡ç† (The Prompt)\n",
    "\n",
    "ä¸å†ç”¨ f-stringï¼Œè€Œæ˜¯ç”¨ `ChatPromptTemplate`ï¼Œå®ƒæ”¯æŒ System/User è§’è‰²åˆ†ç¦»ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9239803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='ä½ æ˜¯ä¸€åèµ„æ·±çš„æ³•å¾‹é¡¾é—®ï¼Œæ“…é•¿å¤„ç†æ°‘äº‹ç±»æ¡ˆä»¶ã€‚', additional_kwargs={}, response_metadata={}), HumanMessage(content='æ¡ˆæƒ…æè¿°ï¼šé‚»å±…å®¶çš„æ ‘å€’äº†ç ¸åäº†æˆ‘çš„è½¦ã€‚è¯·ç®€çŸ­ç»™å‡ºæ³•å¾‹å»ºè®®ã€‚', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# å®šä¹‰æ¨¡ç‰ˆ\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€åèµ„æ·±çš„æ³•å¾‹é¡¾é—®ï¼Œæ“…é•¿å¤„ç†{case_type}ç±»æ¡ˆä»¶ã€‚\"),\n",
    "    (\"user\", \"æ¡ˆæƒ…æè¿°ï¼š{text}ã€‚è¯·ç®€çŸ­ç»™å‡ºæ³•å¾‹å»ºè®®ã€‚\")\n",
    "])\n",
    "\n",
    "# çœ‹çœ‹å®ƒæ¸²æŸ“å‡ºæ¥æ˜¯ä»€ä¹ˆæ ·\n",
    "print(prompt_template.invoke({\"case_type\": \"æ°‘äº‹\", \"text\": \"é‚»å±…å®¶çš„æ ‘å€’äº†ç ¸åäº†æˆ‘çš„è½¦\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f147fe12",
   "metadata": {},
   "source": [
    "### 2.3 ç»„è£…æµæ°´çº¿ (The Chain via LCEL) ğŸš€\n",
    "\n",
    "è¿™æ˜¯ LangChain çš„é«˜å…‰æ—¶åˆ»ã€‚æˆ‘ä»¬å°† Promptã€Model å’Œ OutputParser ä¸²è”èµ·æ¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c35d949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- AIå»ºè®® ---\n",
      "\n",
      "å…³äºé‚»å±…æ ‘æœ¨å€’å¡Œè‡´è½¦è¾†æŸåçš„æ³•å¾‹å»ºè®®ï¼š\n",
      "\n",
      "1. **æ”¶é›†è¯æ®**ï¼šç«‹å³æ‹æ‘„æ ‘æœ¨å€’ä¼ç°åœºç…§ç‰‡ã€è½¦è¾†å—æŸç…§ç‰‡ï¼Œè®°å½•äº‹å‘æ—¶é—´åŠå‘¨å›´ç¯å¢ƒï¼ˆå¦‚æ˜¯å¦æœ‰æ˜æ˜¾é£åŠ›ã€é›¨æƒ…ç­‰ï¼‰ã€‚è‹¥æ›¾å°±æ ‘æœ¨å®‰å…¨éšæ‚£è¿›è¡Œè¿‡æ²Ÿé€šæˆ–æ”¶åˆ°é‚»å±…æ‰¿è¯ºå¤„ç†ï¼Œåº”ä¿ç•™ä¹¦é¢è®°å½•æˆ–å½•éŸ³ã€‚\n",
      "\n",
      "2. **ç¡®è®¤è¿‡é”™å½’å±**ï¼šæ ¹æ®ã€Šæ°‘æ³•å…¸ã€‹ç¬¬125æ¡ï¼Œæ ‘æœ¨æ‰€æœ‰æƒäººæˆ–ç®¡ç†äººè‹¥æœªå°½åˆ°ç»´æŠ¤ä¹‰åŠ¡ï¼ˆå¦‚æœªåŠæ—¶ä¿®å‰ªã€å­˜åœ¨æ˜æ˜¾æ¯ææ–­è£‚é£é™©ç­‰ï¼‰ï¼Œåˆ™éœ€æ‰¿æ‹…èµ”å¿è´£ä»»ã€‚éœ€åˆæ­¥åˆ¤æ–­ï¼šæ ‘æœ¨æ˜¯å¦å±äºå¹´ä¹…å¤±ä¿®çŠ¶æ€ï¼Ÿå€’ä¼æ˜¯å¦å› è‡ªç„¶ç¾å®³ï¼ˆå¦‚å°é£ï¼‰å¯¼è‡´ï¼Ÿè‹¥æœ‰è¯æ®è¯æ˜é‚»å±…å­˜åœ¨è¿‡é”™ï¼Œå¯ä¸»å¼ èµ”å¿ã€‚\n",
      "\n",
      "3. **å‘èµ·åå•†**ï¼šä¹¦é¢é€šçŸ¥é‚»å±…ï¼Œæ˜ç¡®è¦æ±‚å…¶æ‰¿æ‹…èµ”å¿è´£ä»»ï¼Œå¹¶ç»™äºˆåˆç†æœŸé™åå•†ã€‚åå•†ä¸æˆæ—¶ï¼Œå¯è€ƒè™‘é€šè¿‡åŸºå±‚è°ƒè§£ç»„ç»‡æˆ–12348æ³•å¾‹æ´åŠ©çƒ­çº¿å¯»æ±‚è°ƒè§£ã€‚\n",
      "\n",
      "4. **è¯‰è®¼é€”å¾„**ï¼šè‹¥è°ƒè§£å¤±è´¥ï¼Œå¯å‘äººæ°‘æ³•é™¢æèµ·ä¾µæƒè´£ä»»çº çº·è¯‰è®¼ï¼Œä¸»å¼ èµ”å¿è½¦è¾†ç»´ä¿®è´¹ç”¨åŠç›¸å…³æŸå¤±ã€‚éœ€æ³¨æ„æ”¶é›†ç»´ä¿®å‘ç¥¨ã€è¯„ä¼°æŠ¥å‘Šç­‰è¯æ®ï¼Œå¹¶æ˜ç¡®è¯‰è®¼è¯·æ±‚é‡‘é¢ã€‚\n",
      "\n",
      "**å»ºè®®è¡ŒåŠ¨**ï¼šç«‹å³å›ºå®šè¯æ®å¹¶å‘å‡ºä¹¦é¢ç´¢èµ”é€šçŸ¥ï¼Œå¿…è¦æ—¶å’¨è¯¢ä¸“ä¸šå¾‹å¸ˆè¯„ä¼°æ¡ˆä»¶å¯è¡Œæ€§ã€‚è¯‰è®¼æ—¶æ•ˆä¸ºä¸‰å¹´ï¼Œè‡ªæƒåˆ©å—æŸä¹‹æ—¥èµ·è®¡ç®—ã€‚\n",
      "\n",
      "ï¼ˆæ³¨ï¼šå…·ä½“è´£ä»»è®¤å®šéœ€ç»“åˆç°åœºå‹˜æŸ¥åŠåŒæ–¹è¿‡é”™ç¨‹åº¦ï¼Œå»ºè®®å°½å¿«å¯åŠ¨ç»´æƒç¨‹åºï¼‰\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. å®šä¹‰è§£æå™¨ (è‡ªåŠ¨æŠŠ AIMessage å¯¹è±¡è½¬æˆçº¯å­—ç¬¦ä¸²)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 2. ç»„è£…é“¾æ¡ (LCEL è¯­æ³•)\n",
    "# é€»è¾‘ï¼šè¾“å…¥å­—å…¸ -> å¡«å…¥ Prompt -> å–‚ç»™ LLM -> æå–å­—ç¬¦ä¸²\n",
    "chain = prompt_template | llm | parser\n",
    "\n",
    "# 3. è¿è¡Œé“¾æ¡\n",
    "result = chain.invoke({\n",
    "    \"case_type\": \"ä¾µæƒ\", \n",
    "    \"text\": \"é‚»å±…å®¶çš„æ ‘å€’äº†ç ¸åäº†æˆ‘çš„è½¦ï¼Œä½†ä»–æ‹’ç»èµ”å¿ã€‚\"\n",
    "})\n",
    "\n",
    "print(\"--- AI å»ºè®® ---\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f03c709",
   "metadata": {},
   "source": [
    "> **ğŸ‘€ è§‚å¯Ÿ**ï¼š\n",
    "> ä½ çš„ä»£ç é€»è¾‘å˜å¾—æå…¶æ¸…æ™°ã€‚æ²¡æœ‰ `json.loads`ï¼Œæ²¡æœ‰ `requests.post`ï¼Œåªæœ‰ä¸šåŠ¡é€»è¾‘çš„æµè½¬ã€‚\n",
    "\n",
    "### 2.4 ç»“æ„åŒ–è¾“å‡ºé‡æ„ (Structured Output Refactor)\n",
    "\n",
    "è¿˜è®°å¾—æ˜¨å¤©å†™çš„ `Pydantic` è§£æå—ï¼ŸLangChain å†…ç½®äº†æ›´å¥½çš„æ”¯æŒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92d7fb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ç»“æ„åŒ–ç»“æœ ---\n",
      "æ‘˜è¦: å¼ ä¸‰æ‰¿è®¤å€Ÿæ¬¾ä½†ä»…æœ‰èŠå¤©è®°å½•ä½œä¸ºè¯æ®ï¼Œéœ€è¿›ä¸€æ­¥æ”¶é›†è¯æ®å¹¶è¯„ä¼°èƒœè¯‰æ¦‚ç‡ã€‚\n",
      "æ¦‚ç‡: 0.4\n",
      "<class '__main__.LegalAdvice'>\n"
     ]
    }
   ],
   "source": [
    "# Cell 4\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate # è®°å¾—å¯¼å…¥è¿™ä¸ª\n",
    "\n",
    "# 1. å®šä¹‰æ•°æ®ç»“æ„\n",
    "class LegalAdvice(BaseModel):\n",
    "    summary: str = Field(description=\"æ¡ˆæƒ…ä¸€å¥è¯æ‘˜è¦\")\n",
    "    advice: str = Field(description=\"å…·ä½“çš„æ³•å¾‹å»ºè®®\")\n",
    "    confidence: float = Field(description=\"èƒœè¯‰æ¦‚ç‡é¢„ä¼°ï¼Œ0-1ä¹‹é—´\")\n",
    "\n",
    "# 2. åˆ›å»ºè§£æå™¨\n",
    "pydantic_parser = PydanticOutputParser(pydantic_object=LegalAdvice)\n",
    "\n",
    "# 3. è·å–æ ¼å¼æŒ‡ä»¤\n",
    "format_instructions = pydantic_parser.get_format_instructions()\n",
    "\n",
    "# 4. å®šä¹‰ Prompt (æŒ–äº†ä¸¤ä¸ªå‘)\n",
    "prompt_struct = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ä½ æ˜¯ä¸€åå¾‹å¸ˆã€‚åˆ†æä»¥ä¸‹æ¡ˆæƒ…ã€‚\n",
    "    {format_instructions}\n",
    "    \n",
    "    æ¡ˆæƒ…ï¼š{text}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# â­ï¸ æ ¸å¿ƒä¿®æ­£ï¼šä½¿ç”¨ partial å°† format_instructions \"é¢„å¡«å……\" è¿›å»\n",
    "# è¿™æ ·æ–°çš„ prompt_final å°±åªå‰©ä¸‹ä¸€ä¸ª {text} å‘äº†\n",
    "prompt_final = prompt_struct.partial(format_instructions=format_instructions)\n",
    "\n",
    "# 5. æ–°çš„é“¾æ¡ (æ³¨æ„è¿™é‡Œç”¨çš„æ˜¯ prompt_final)\n",
    "chain_struct = prompt_final | llm | pydantic_parser\n",
    "\n",
    "# 6. è¿è¡Œ (ç°åœ¨åªéœ€è¦ä¼  text å³å¯)\n",
    "try:\n",
    "    result_obj = chain_struct.invoke({\"text\": \"å¼ ä¸‰å€Ÿäº†æˆ‘5000å…ƒä¸è¿˜ï¼Œåªæœ‰å¾®ä¿¡èŠå¤©è®°å½•ã€‚\"})\n",
    "    print(\"\\n--- ç»“æ„åŒ–ç»“æœ ---\")\n",
    "    print(f\"æ‘˜è¦: {result_obj.summary}\")\n",
    "    print(f\"æ¦‚ç‡: {result_obj.confidence}\")\n",
    "    print(type(result_obj)) \n",
    "except Exception as e:\n",
    "    print(f\"è§£æå¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f812f5",
   "metadata": {},
   "source": [
    "## ğŸ§  3 æ·±åº¦ç†è®º & é¢è¯•å¿…é—® (Deep Dive)\n",
    "\n",
    "### ğŸ”¥ Q1: LangChain çš„æ ¸å¿ƒä»·å€¼æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "**é¢è¯•å®˜æƒ³å¬åˆ°çš„å…³é”®è¯**ï¼š**æŠ½è±¡ (Abstraction)**ã€**ç¼–æ’ (Orchestration)**ã€**ç”Ÿæ€ (Ecosystem)**ã€‚\n",
    "\n",
    "**å‚è€ƒå›ç­”**ï¼š\n",
    "\n",
    "1. **ç»„ä»¶æŠ½è±¡ (Abstraction)**ï¼š\n",
    "* å®ƒå°†ä¸åŒçš„ LLM (OpenAI, DeepSeek, Llama) ç»Ÿä¸€æŠ½è±¡ä¸º `ChatModel` æ¥å£ã€‚\n",
    "* å°±åƒ **PyTorch çš„ Dataset ç±»**ï¼Œæ— è®ºåº•å±‚æ˜¯ CSV è¿˜æ˜¯ JPGï¼Œä¸Šå±‚è®­ç»ƒä»£ç  `DataLoader` éƒ½ä¸ç”¨æ”¹ã€‚è¿™é¿å…äº†**ä¾›åº”å•†é”å®š (Vendor Lock-in)**ã€‚\n",
    "\n",
    "\n",
    "2. **é“¾å¼ç¼–æ’ (Chaining / LCEL)**ï¼š\n",
    "* é€šè¿‡ Unix ç®¡é“é£æ ¼çš„ `|` æ“ä½œç¬¦ï¼Œå°† Promptã€Modelã€Parserã€Retriever (æ£€ç´¢å™¨) ä¸²è”èµ·æ¥ï¼Œæå¤§åœ°æé«˜äº†ä»£ç çš„**å¯è¯»æ€§**å’Œ**å¤ç”¨æ€§**ã€‚\n",
    "\n",
    "\n",
    "3. **ç”Ÿæ€é›†æˆ (Integrations)**ï¼š\n",
    "* å®ƒå†…ç½®äº†ä¸ å‘é‡æ•°æ®åº“ (Chroma/Milvus)ã€æœç´¢å¼•æ“ (Google/Bing)ã€å·¥å…· (Calculator/Python) çš„æ¥å£ã€‚å¼€å‘è€…ä¸éœ€è¦è‡ªå·±å»å†™è¿™äº›å¤æ‚çš„å¯¹æ¥ä»£ç ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef071bf",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## ğŸ§© 4 ä»Šæ—¥ LeetCode ç»ƒä¹ \n",
    "\n",
    "LangChain çš„æ ¸å¿ƒæ˜¯ **Chain (é“¾)**ã€‚ä¸ºäº†è‡´æ•¬è¿™ä¸ªæ¦‚å¿µï¼Œä»Šå¤©å¤ä¹ é“¾è¡¨ä¸­æœ€ç»å…¸çš„é¢˜ç›®ã€‚\n",
    "\n",
    "* **é¢˜ç›®**: **[Merge Two Sorted Lists (LC 21)](../../LeetCode%20practice/1-50.ipynb)** - ç®€å•\n",
    "* **å…³è”**:\n",
    "* LCEL çš„ `Chain` å°±åƒä¸€ä¸ªå•å‘é“¾è¡¨ï¼Œæ•°æ®ä» Head æµå‘ Tailã€‚\n",
    "* ç†è§£æŒ‡é’ˆçš„ç§»åŠ¨å’ŒèŠ‚ç‚¹çš„è¿æ¥ï¼Œæœ‰åŠ©äºç†è§£ LangChain å†…éƒ¨çš„æ•°æ®æµå‘ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a53469a",
   "metadata": {},
   "source": [
    "## âœ… 5 ä»Šæ—¥ä»»åŠ¡æ€»ç»“\n",
    "\n",
    "* [ ] å®‰è£… `langchain` åº“ã€‚\n",
    "* [ ] åœ¨ Notebook ä¸­è·‘é€šäº† `ChatOpenAI` è¿æ¥ç¡…åŸºæµåŠ¨ã€‚\n",
    "* [ ] æŒæ¡äº† LCEL å†™æ³•ï¼š`chain = prompt | model | parser`ã€‚\n",
    "* [ ] ä½¿ç”¨ LangChain å†…ç½®çš„ `PydanticOutputParser` å®ç°äº†ç»“æ„åŒ–è¾“å‡ºã€‚\n",
    "* [ ] **é¢è¯•å‡†å¤‡**ï¼šç†è§£ LangChain çš„â€œé€‚é…å™¨â€æœ¬è´¨ã€‚\n",
    "\n",
    "**å®Œæˆåï¼Œè¯·å›å¤â€œW8D4 å®Œæˆâ€ï¼Œæˆ‘ä»¬å°†è¿›å…¥ Week 8 çš„æœ€åä¸€å—æ‹¼å›¾â€”â€”è®© AI æ‹¥æœ‰â€œè®°å¿†â€ (Memory)ï¼**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
