{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "237f6832",
   "metadata": {},
   "source": [
    "# S3W8D5: è®°å¿†æœºåˆ¶ä¸ä¸Šä¸‹æ–‡ (Memory Management)\n",
    "\n",
    "ä»Šå¤©æˆ‘ä»¬è¦ç»™ä½ çš„ AI æ³¨å…¥â€œçµé­‚â€ã€‚æ²¡æœ‰è®°å¿†çš„ AI å°±åƒä¸€æ¡é‡‘é±¼ï¼ˆä¼ è¯´åªæœ‰ 7 ç§’è®°å¿†ï¼‰ï¼Œå“ªæ€•ä½ åˆšæ‰å‘Šè¯‰è¿‡å®ƒä½ çš„åå­—ï¼Œä¸‹ä¸€ç§’å®ƒå°±ä¼šé—®ï¼šâ€œä½ å¥½ï¼Œè¯·é—®ä½ æ˜¯è°ï¼Ÿâ€\n",
    "\n",
    "åœ¨ç®—æ³•å²—é¢è¯•ä¸­ï¼Œ**Memory (è®°å¿†)** æ˜¯è¿æ¥ LLM å’Œ Agent çš„æ¡¥æ¢ï¼Œä¹Ÿæ˜¯è€ƒå¯Ÿä½ å¯¹ **Context Window (ä¸Šä¸‹æ–‡çª—å£)** ç†è§£æ·±åº¦çš„æœ€ä½³è€ƒç‚¹ã€‚\n",
    "\n",
    "**ğŸ¯ ä»Šæ—¥ç›®æ ‡**\n",
    "\n",
    "1. **åŸç†ç†è§£**ï¼šä¸ºä»€ä¹ˆ API æ˜¯æ— çŠ¶æ€çš„ï¼Ÿæˆ‘ä»¬å¦‚ä½•åœ¨å®¢æˆ·ç«¯ç»´æŠ¤çŠ¶æ€ï¼Ÿ\n",
    "2. **æ ¸å¿ƒå®ç°**ï¼šæ‰‹åŠ¨ç¼–å†™ `ConversationBuffer` å’Œ `WindowBuffer`ã€‚\n",
    "3. **å·¥ç¨‹éš¾ç‚¹**ï¼šå®ç° Token è®¡æ•°ä¸è‡ªåŠ¨æˆªæ–­ï¼ˆSliding Windowï¼‰ï¼Œé˜²æ­¢æ’‘çˆ†æ¨¡å‹ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc459cd0",
   "metadata": {},
   "source": [
    "## ğŸ“– 1 ç†è®ºçŸ¥è¯†è®²è§£ (Theory & Analogy)\n",
    "\n",
    "**ä¸ºä»€ä¹ˆéœ€è¦è®°å¿†æ¨¡å—ï¼Ÿ**\n",
    "\n",
    "> **ğŸ§¬ åŒ»å­¦å›¾åƒç±»æ¯”ï¼šç—…å† (Patient History)**\n",
    "> * **Stateless (æ— çŠ¶æ€)**ï¼šå°±åƒæ”¾å°„ç§‘åŒ»ç”Ÿåªçœ‹**å½“å‰**è¿™å¼  X å…‰ç‰‡ã€‚ä»–èƒ½çœ‹å‡ºâ€œè¿™é‡Œéª¨æŠ˜äº†â€ï¼Œä½†ä»–ä¸çŸ¥é“â€œè¿™å·²ç»æ˜¯ç—…äººè¿™å‘¨ç¬¬ä¸‰æ¬¡éª¨æŠ˜äº†â€ï¼ˆç¼ºä¹ä¸Šä¸‹æ–‡ï¼‰ï¼Œå¯èƒ½ä¼šæ¼æ‰â€œéª¨è´¨ç–æ¾â€çš„è¯Šæ–­ã€‚\n",
    "> * **Full Memory (å…¨é‡è®°å¿†)**ï¼šæŠŠç—…äººä»å‡ºç”Ÿåˆ°ç°åœ¨çš„**æ‰€æœ‰**ç—…å†éƒ½æ‰”ç»™åŒ»ç”Ÿã€‚\n",
    "> * *ä¼˜ç‚¹*ï¼šä¿¡æ¯å…¨ã€‚\n",
    "> * *ç¼ºç‚¹*ï¼šåŒ»ç”Ÿçœ‹ä¸å®Œï¼ˆContext Limit é™åˆ¶ï¼‰ï¼Œè€Œä¸”å¾ˆè´µï¼ˆToken è®¡è´¹ï¼‰ã€‚\n",
    "> \n",
    "> \n",
    "> * **Window Memory (æ»‘åŠ¨çª—å£)**ï¼šåªç»™åŒ»ç”Ÿçœ‹**æœ€è¿‘ 3 æ¬¡**çš„å°±è¯Šè®°å½•ã€‚\n",
    "> * **Summary Memory (æ‘˜è¦è®°å¿†)**ï¼šç»™åŒ»ç”Ÿçœ‹ä¸€ä»½**å‡ºé™¢å°ç»“**ï¼ˆæ¯”å¦‚ï¼šâ€œæ‚£è€…æœ‰ä¸¥é‡éª¨è´¨ç–æ¾å²â€ï¼‰ï¼Œè€Œä¸æ˜¯åŸå§‹çš„æµæ°´è´¦ã€‚\n",
    "> \n",
    "> \n",
    "\n",
    "åœ¨ LLM å¼€å‘ä¸­ï¼Œæˆ‘ä»¬å°±éœ€è¦æ ¹æ®åœºæ™¯é€‰æ‹©ä¸åŒçš„â€œç—…å†ç®¡ç†ç­–ç•¥â€ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b98e23b",
   "metadata": {},
   "source": [
    "## ğŸ’» 2 ä»£ç å®ç°\n",
    "\n",
    "### 2.1 ç®€å•çš„Buffer Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e00a0cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'æˆ‘å«é»„åŒå­¦'}, {'role': 'assistant', 'content': 'ä½ å¥½ï¼Œé»„åŒå­¦'}, {'role': 'user', 'content': 'æˆ‘åˆšæ‰è¯´äº†æˆ‘å«ä»€ä¹ˆï¼Ÿ'}]\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "class SimpleMemory:\n",
    "    def __init__(self):\n",
    "        self.messages = [] # å­˜å‚¨ {\"role\": \"user\", \"content\": \"...\"}\n",
    "\n",
    "    def add_user_message(self, text: str):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": text})\n",
    "\n",
    "    def add_ai_message(self, text: str):\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": text})\n",
    "\n",
    "    def get_history(self) -> List[Dict]:\n",
    "        return self.messages\n",
    "\n",
    "    def clear(self):\n",
    "        self.messages = []\n",
    "\n",
    "# æµ‹è¯•\n",
    "memory = SimpleMemory()\n",
    "memory.add_user_message(\"æˆ‘å«é»„åŒå­¦\")\n",
    "memory.add_ai_message(\"ä½ å¥½ï¼Œé»„åŒå­¦\")\n",
    "memory.add_user_message(\"æˆ‘åˆšæ‰è¯´äº†æˆ‘å«ä»€ä¹ˆï¼Ÿ\")\n",
    "\n",
    "print(memory.get_history())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d75c670",
   "metadata": {},
   "source": [
    "### 2.2 ç»“åˆ LLM å®æˆ˜\n",
    "\n",
    "è®©æˆ‘ä»¬çœ‹çœ‹æŠŠè¿™ä¸ª list å‘ç»™ LLM ä¼šå‘ç”Ÿä»€ä¹ˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dacf0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Round 1 ---\n",
      "æ‚¨åˆšæ‰è¯´æ‚¨æ˜¯ä¸€å**ç®—æ³•å·¥ç¨‹å¸ˆ**ã€‚\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../../\"))\n",
    "from src.llm.client import LLMClient\n",
    "\n",
    "client = LLMClient()\n",
    "memory = SimpleMemory()\n",
    "\n",
    "# ç¬¬ä¸€è½®å¯¹è¯\n",
    "user_input = \"æˆ‘å«é»„åŒå­¦ï¼Œæˆ‘æ˜¯ä¸€åç®—æ³•å·¥ç¨‹å¸ˆã€‚\"\n",
    "memory.add_user_message(user_input)\n",
    "\n",
    "# æ„é€  Promptï¼šSystem + History\n",
    "# æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨æŠŠ list æ‹¼æˆ promptï¼Œæˆ–è€…ç›´æ¥å‘ list ç»™ client (å¦‚æœ client æ”¯æŒ)\n",
    "# ä¸ºäº†æ¼”ç¤ºï¼Œå‡è®¾æˆ‘ä»¬çš„ client.generate åªæ¥å— stringï¼Œæˆ‘ä»¬éœ€è¦æŠŠ history å˜æˆ text\n",
    "def build_prompt(history, query):\n",
    "    prompt_str = \"\"\n",
    "    for msg in history:\n",
    "        prompt_str += f\"{msg['role']}: {msg['content']}\\n\"\n",
    "    prompt_str += f\"user: {query}\\nassistant:\"\n",
    "    return prompt_str\n",
    "\n",
    "# è¿™é‡Œæˆ‘ä»¬ç¨å¾® hack ä¸€ä¸‹ï¼Œç›´æ¥æŠŠ history å¡è¿› client çš„ messages é‡Œä¼šæ›´æ ‡å‡†\n",
    "# ä½†ä¸ºäº†æ¼”ç¤ºåŸç†ï¼Œæˆ‘ä»¬å…ˆçœ‹æ•ˆæœã€‚\n",
    "print(\"--- Round 1 ---\")\n",
    "# è¿™é‡Œçš„ client.generate æ˜¯ Week 8 Day 1 å†™çš„ï¼Œå®ƒå†…éƒ¨åªæ¥å— prompt string\n",
    "# å¦‚æœè¦æ”¯æŒå¤šè½®ï¼Œæˆ‘ä»¬éœ€è¦ä¿®æ”¹ client.generate æ¥å— messages åˆ—è¡¨\n",
    "# æˆ–è€…æˆ‘ä»¬ç®€å•åœ°æŠŠ history æ‹¼æ¥åˆ° prompt é‡Œ (Stateless çš„æœ¬è´¨)\n",
    "\n",
    "response = client.generate(f\"History:\\n{memory.get_history()}\\n\\nUser: åˆšæ‰æˆ‘è¯´æˆ‘æ˜¯ä»€ä¹ˆèŒä¸šï¼Ÿ\")\n",
    "print(response)\n",
    "memory.add_ai_message(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b45c64c",
   "metadata": {},
   "source": [
    "> **ğŸ›‘ åœé¡¿æ€è€ƒ**ï¼šéšç€å¯¹è¯è¿›è¡Œï¼Œ`memory.get_history()` è¿”å›çš„åˆ—è¡¨ä¼šè¶Šæ¥è¶Šé•¿ã€‚å¦‚æœèŠäº† 1000 è½®ï¼ŒAPI å°±ä¼šæŠ¥é”™ï¼š`ContextLengthExceeded`ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4b8393",
   "metadata": {},
   "source": [
    "### 2.3 æ»‘åŠ¨çª—å£ä¸ Token æˆªæ–­ (Window Memory) ğŸš€\n",
    "\n",
    "è¿™æ˜¯å·¥ç¨‹ä¸­æœ€å®ç”¨çš„éƒ¨åˆ†ã€‚æˆ‘ä»¬éœ€è¦é™åˆ¶â€œè®°å¿†â€çš„å¤§å°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e103a2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Memory Full! Popping: ä½ å¥½ï¼Œæˆ‘æ˜¯é»„åŒå­¦ã€‚...\n",
      "âš ï¸ Memory Full! Popping: ä½ å¥½ï¼...\n",
      "âš ï¸ Memory Full! Popping: ä»Šå¤©å¤©æ°”çœŸä¸é”™ï¼Œé€‚åˆ...\n",
      "\n",
      "--- Current Memory ---\n",
      "{'role': 'assistant', 'content': 'æ˜¯çš„ï¼Œä½ æƒ³å»å“ªé‡Œï¼Ÿ'}\n"
     ]
    }
   ],
   "source": [
    "# Cell 3\n",
    "import tiktoken\n",
    "\n",
    "class WindowMemory:\n",
    "    def __init__(self, max_tokens: int = 500):\n",
    "        self.messages = []\n",
    "        self.max_tokens = max_tokens\n",
    "        # åŠ è½½ç¼–ç å™¨ (GPT-3.5/4 æ ‡å‡†)\n",
    "        self.encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    def count_tokens(self, text: str) -> int:\n",
    "        return len(self.encoder.encode(text))\n",
    "\n",
    "    def add_message(self, role: str, content: str):\n",
    "        self.messages.append({\"role\": role, \"content\": content})\n",
    "        self._trim_memory()\n",
    "\n",
    "    def _trim_memory(self):\n",
    "        \"\"\"æ ¸å¿ƒé€»è¾‘ï¼šå¦‚æœè¶…é•¿ï¼Œå°±ä»å¤´å¼€å§‹æ‰”ï¼Œç›´åˆ°æ»¡è¶³è¦æ±‚\"\"\"\n",
    "        while True:\n",
    "            # è®¡ç®—å½“å‰æ€»é•¿åº¦\n",
    "            total_tokens = sum([self.count_tokens(m[\"content\"]) for m in self.messages])\n",
    "            if total_tokens <= self.max_tokens:\n",
    "                break\n",
    "            \n",
    "            # å¼¹å‡ºæœ€æ—©çš„ä¸€æ¡ (FIFO - å…ˆè¿›å…ˆå‡º)\n",
    "            # æ³¨æ„ï¼šé€šå¸¸è¦æˆå¯¹å¼¹å‡º (User+AI)ï¼Œå¦åˆ™å¯¹è¯ä¼šé”™ä½ï¼Œè¿™é‡Œç®€å•å¤„ç†å¼¹å‡ºä¸€ä¸ª\n",
    "            if self.messages:\n",
    "                removed = self.messages.pop(0)\n",
    "                print(f\"âš ï¸ Memory Full! Popping: {removed['content'][:10]}...\")\n",
    "            else:\n",
    "                break\n",
    "\n",
    "# æµ‹è¯•æˆªæ–­\n",
    "window_mem = WindowMemory(max_tokens=20) # æ•…æ„è®¾å¾—å¾ˆå°\n",
    "window_mem.add_message(\"user\", \"ä½ å¥½ï¼Œæˆ‘æ˜¯é»„åŒå­¦ã€‚\")\n",
    "window_mem.add_message(\"assistant\", \"ä½ å¥½ï¼\")\n",
    "window_mem.add_message(\"user\", \"ä»Šå¤©å¤©æ°”çœŸä¸é”™ï¼Œé€‚åˆå‡ºå»ç©ã€‚\") # è¿™å¥åŠ è¿›å»å¯èƒ½å°±çˆ†äº†\n",
    "window_mem.add_message(\"assistant\", \"æ˜¯çš„ï¼Œä½ æƒ³å»å“ªé‡Œï¼Ÿ\")\n",
    "\n",
    "print(\"\\n--- Current Memory ---\")\n",
    "for msg in window_mem.messages:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abd9269",
   "metadata": {},
   "source": [
    "## ğŸ§  3 æ·±åº¦ç†è®º & é¢è¯•å¿…é—® (Deep Dive)\n",
    "\n",
    "### ğŸ”¥ Q1: å¦‚æœå¯¹è¯å†å²å¤ªé•¿è¶…è¿‡ Context Windowï¼Œæœ‰å“ªäº›å¤„ç†ç­–ç•¥ï¼Ÿ\n",
    "\n",
    "è¿™æ˜¯ Agent å¼€å‘ä¸­çš„æ ¸å¿ƒéš¾é¢˜ã€‚\n",
    "\n",
    "**æ ‡å‡†å›ç­” (ç”±æµ…å…¥æ·±)ï¼š**\n",
    "\n",
    "1. **ç›´æ¥æˆªæ–­ (Truncation / Sliding Window)**ï¼š\n",
    "* **åŸç†**ï¼šä¿ç•™æœ€è¿‘çš„  è½®å¯¹è¯ (FIFO é˜Ÿåˆ—)ã€‚\n",
    "* **ä¼˜ç‚¹**ï¼šå®ç°ç®€å•ï¼Œä¿ç•™äº†æœ€æ–°çš„ç»†èŠ‚ã€‚\n",
    "* **ç¼ºç‚¹**ï¼šä¸¢å¤±äº†æ—©æœŸçš„å…³é”®ä¿¡æ¯ï¼ˆæ¯”å¦‚ç”¨æˆ·åˆšå¼€å§‹è¯´çš„åå­—ï¼‰ã€‚\n",
    "* *LC å…³è”*ï¼šè¿™ä¸å°±æ˜¯ **Queue** å—ï¼Ÿ\n",
    "\n",
    "\n",
    "2. **æ‘˜è¦æ€»ç»“ (Summarization)**ï¼š\n",
    "* **åŸç†**ï¼šæ¯éš”å‡ è½®ï¼Œè§¦å‘ä¸€ä¸ª LLM è°ƒç”¨ï¼Œè®©å®ƒæŠŠä¹‹å‰çš„å¯¹è¯å‹ç¼©æˆä¸€æ®µ Summaryã€‚\n",
    "* *Prompt*ï¼š\"è¯·æŠŠä»¥ä¸Šå¯¹è¯æ€»ç»“ä¸º 100 å­—ä»¥å†…çš„æ‘˜è¦ï¼Œä¿ç•™å…³é”®å®ä½“ã€‚\"\n",
    "* **ç¼ºç‚¹**ï¼šå¢åŠ äº† API è°ƒç”¨æˆæœ¬ï¼Œä¸”æ‘˜è¦ä¼šä¸¢å¤±ç»†èŠ‚ã€‚\n",
    "\n",
    "\n",
    "3. **å‘é‡æ£€ç´¢ (Vector Store / Long-term Memory)**ï¼š\n",
    "* **åŸç†**ï¼šæŠŠå†å²å¯¹è¯åˆ‡ç‰‡å­˜å…¥å‘é‡æ•°æ®åº“ (Chroma/Faiss)ã€‚å½“ç”¨æˆ·é—®æ–°é—®é¢˜æ—¶ï¼Œå…ˆå»æ•°æ®åº“é‡Œ Retrieve ç›¸å…³çš„å†å²è®°å½•ã€‚\n",
    "* **åœºæ™¯**ï¼šç”¨æˆ·é—®â€œæˆ‘ä»¬ä¸Šå‘¨èŠåˆ°çš„é‚£ä¸ªæ³•å¾‹æ¡æ¬¾æ˜¯ä»€ä¹ˆï¼Ÿâ€ï¼Œè¿™æ—¶å€™æ»‘åŠ¨çª—å£æ—©å¿˜äº†ï¼Œä½†å‘é‡æ£€ç´¢èƒ½æ‰¾å›æ¥ã€‚è¿™æ˜¯ **RAG** çš„æ€æƒ³åœ¨ Memory ä¸Šçš„åº”ç”¨ã€‚\n",
    "\n",
    "\n",
    "\n",
    "### ğŸ”¥ Q2: ä¸ºä»€ä¹ˆä¸æŠŠæ‰€æœ‰å†å²éƒ½å‘ç»™æ¨¡å‹ï¼Ÿ\n",
    "\n",
    "1. **é’± (Cost)**ï¼šAPI æ˜¯æŒ‰ Token æ”¶è´¹çš„ã€‚æ¯è½®éƒ½å‘å…¨æ–‡ï¼Œè´¹ç”¨æ˜¯  å¢é•¿çš„ã€‚\n",
    "2. **å»¶è¿Ÿ (Latency)**ï¼šè¾“å…¥è¶Šé•¿ï¼ŒPrefill (é¦–å­—ç”Ÿæˆæ—¶é—´) è¶Šæ…¢ã€‚\n",
    "3. **æ€§èƒ½ (Performance)**ï¼šç ”ç©¶è¡¨æ˜ï¼ˆLost in the Middle ç°è±¡ï¼‰ï¼Œå½“ Context æé•¿æ—¶ï¼Œæ¨¡å‹å®¹æ˜“å¿½ç•¥ä¸­é—´çš„ä¿¡æ¯ï¼Œåªè®°å¾—å¼€å¤´å’Œç»“å°¾ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b17112",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ 4 å·¥ç¨‹å°è£… (Engineering)\n",
    "\n",
    "è¯·åœ¨ `src/llm/memory.py` ä¸­å°è£…ä»£ç ã€‚æˆ‘ä»¬å°†å®ç°ä¸€ä¸ªç»“åˆäº† Buffer å’Œ Window çš„ç±»ã€‚\n",
    "\n",
    "\n",
    "```python\n",
    "# src/llm/memory.py\n",
    "from typing import List, Dict, Optional\n",
    "import tiktoken\n",
    "\n",
    "class MemoryBuffer:\n",
    "    def __init__(self, max_tokens: Optional[int] = 2000, system_prompt: str = \"\"):\n",
    "        self.messages = []\n",
    "        if system_prompt:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "        \n",
    "        self.max_tokens = max_tokens\n",
    "        self.encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    def add(self, role: str, content: str):\n",
    "        self.messages.append({\"role\": role, \"content\": content})\n",
    "        if self.max_tokens:\n",
    "            self._trim()\n",
    "\n",
    "    def get_context(self) -> List[Dict]:\n",
    "        return self.messages\n",
    "\n",
    "    def _trim(self):\n",
    "        # ç®€å•ç²—æš´çš„ä¿®å‰ªç­–ç•¥ï¼šä¿ç•™ System Promptï¼Œä¿®å‰ªä¸­é—´çš„\n",
    "        while self._count_total_tokens() > self.max_tokens:\n",
    "            # ç¡®ä¿ä¸åˆ æ‰ system prompt (index 0)\n",
    "            if len(self.messages) > 1:\n",
    "                # åˆ é™¤ index 1 (æœ€æ—©çš„é system æ¶ˆæ¯)\n",
    "                self.messages.pop(1)\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "    def _count_total_tokens(self) -> int:\n",
    "        return sum([len(self.encoder.encode(m[\"content\"])) for m in self.messages])\n",
    "\n",
    "    def clear(self):\n",
    "        # ä¿ç•™ system prompt\n",
    "        system = self.messages[0] if self.messages and self.messages[0]['role'] == 'system' else None\n",
    "        self.messages = []\n",
    "        if system:\n",
    "            self.messages.append(system)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa22bc9f",
   "metadata": {},
   "source": [
    "## ğŸ§© 6. ä»Šæ—¥ LeetCode ç»ƒä¹ \n",
    "\n",
    "è®°å¿†ç®¡ç†æœ¬è´¨ä¸Šå°±æ˜¯ **Queue (é˜Ÿåˆ—)** çš„æ“ä½œã€‚\n",
    "\n",
    "* **é¢˜ç›®**: **LC 933. Number of Recent Calls (æœ€è¿‘çš„è¯·æ±‚æ¬¡æ•°)** - ç®€å•\n",
    "* **å…³è”**: è¿™é“é¢˜è¦æ±‚ä½ åªç»Ÿè®¡è¿‡å» 3000ms å†…çš„è¯·æ±‚ã€‚\n",
    "* è¿™å®Œå…¨å°±æ˜¯ **Window Memory** çš„é€»è¾‘ï¼\n",
    "* ä¸€æ—¦æ—¶é—´æˆ³è¶…å‡ºäº†çª—å£ï¼ˆ`t - 3000`ï¼‰ï¼Œå°± `popleft`ã€‚è¿™å’Œæˆ‘ä»¬åˆšæ‰å†™çš„ `_trim()` é€»è¾‘ä¸€æ¨¡ä¸€æ ·ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36122e6",
   "metadata": {},
   "source": [
    "## âœ… 7. ä»Šæ—¥ä»»åŠ¡æ€»ç»“\n",
    "\n",
    "* [ ] å®‰è£… `tiktoken`ã€‚\n",
    "* [ ] ç†è§£äº† Memory å°±æ˜¯ Listï¼ŒContext Window æ˜¯ç‰©ç†é™åˆ¶ã€‚\n",
    "* [ ] å®ç°äº† Token è®¡æ•°å’Œ Sliding Window æˆªæ–­é€»è¾‘ã€‚\n",
    "* [ ] å°è£…äº† `src/llm/memory.py`ã€‚\n",
    "* [ ] **é¢è¯•å‡†å¤‡**ï¼šå¯ä»¥æµåˆ©è¯´å‡ºå¤„ç†é•¿æ–‡æœ¬çš„ä¸‰ç§ç­–ç•¥ï¼ˆæˆªæ–­ã€æ‘˜è¦ã€æ£€ç´¢ï¼‰ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
