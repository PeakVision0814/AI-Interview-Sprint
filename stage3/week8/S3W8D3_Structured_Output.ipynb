{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "219dbf32",
   "metadata": {},
   "source": [
    "# S3W8D3: ç»“æ„åŒ–è¾“å‡º (Structured Output)\n",
    "\n",
    "å¦‚æœè¯´å‰ä¸¤å¤©çš„å†…å®¹æ˜¯åœ¨æ•™æ¨¡å‹â€œæ€ä¹ˆæ€è€ƒâ€ï¼ˆPromptingï¼‰ï¼Œé‚£ä¹ˆä»Šå¤©çš„å†…å®¹å°±æ˜¯æ•™æ¨¡å‹â€œ**æ€ä¹ˆå®ˆè§„çŸ©**â€ã€‚\n",
    "\n",
    "åœ¨å®é™…å·¥ç¨‹ä¸­ï¼Œè€æ¿å’Œå‰ç«¯å¼€å‘ä¸éœ€è¦ä¸€ä¸ªä¼šåŸè¯—ä½œå¯¹çš„ AIï¼Œä»–ä»¬åªéœ€è¦ä¸€ä¸ªèƒ½åå‡ºæ ‡å‡† JSON çš„ APIï¼Œè¿™æ ·æ‰èƒ½å­˜å…¥æ•°æ®åº“æˆ–æ˜¾ç¤ºåœ¨ç½‘é¡µä¸Šã€‚\n",
    "\n",
    "**ğŸ¯ ä»Šæ—¥ç›®æ ‡**\n",
    "\n",
    "1. **ç—›ç‚¹ä½“éªŒ**ï¼šçœ‹ LLM å¦‚ä½•â€œä¸å¬è¯â€åœ°è¾“å‡ºå¤šä½™çš„åºŸè¯ã€‚\n",
    "2. **æš´åŠ›ç ´è§£**ï¼šä½¿ç”¨ Regex (æ­£åˆ™è¡¨è¾¾å¼) å¼ºè¡Œæå– JSONã€‚\n",
    "3. **ä¼˜é›…æ–¹æ¡ˆ**ï¼šç»“åˆ **Pydantic** å®šä¹‰æ•°æ® Schemaï¼Œå¹¶åˆ©ç”¨ Prompt çº¦æŸè¾“å‡ºã€‚\n",
    "4. **å·¥ç¨‹å°è£…**ï¼šç¼–å†™ `src/llm/parsers.py`ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7829f31e",
   "metadata": {},
   "source": [
    "## ğŸ“– 1 ç†è®ºçŸ¥è¯†è®²è§£ (Theory & Analogy)\n",
    "\n",
    "> **ğŸ§¬ åŒ»å­¦å›¾åƒç±»æ¯”ï¼šå½±åƒæŠ¥å‘Š vs. DICOM Header**\n",
    "> * **éç»“æ„åŒ– (Natural Language)**ï¼šå°±åƒåŒ»ç”Ÿçš„å£è¿°å½•éŸ³ï¼šâ€œç—…äººè‚ºéƒ¨æœ‰ä¸€ä¸ªå¤§æ¦‚ 3 å˜ç±³çš„é˜´å½±ï¼Œä½ç½®åå·¦ä¸Š...â€\n",
    "> * è¿™å°±å¥½æ¯” LLM è¯´ï¼šâ€œæ ¹æ®æ¡ˆæƒ…ï¼Œæˆ‘è§‰å¾—å¼ ä¸‰æ˜¯ç›—çªƒï¼Œé‡‘é¢å¤§æ¦‚æ˜¯ 5000 å§ã€‚â€\n",
    "> * **åæœ**ï¼šä»£ç æ— æ³•å¤„ç†ï¼ˆ`if \"å¤§æ¦‚ 3 å˜ç±³\" > 2.0: ...` è‚¯å®šæŠ¥é”™ï¼‰ã€‚\n",
    "> \n",
    "> \n",
    "> * **ç»“æ„åŒ– (JSON/Schema)**ï¼šå°±åƒ **DICOM æ–‡ä»¶å¤´**æˆ–ç»“æ„åŒ–ç”µå­ç—…å†ã€‚\n",
    "> * `{\"lesion_size_mm\": 30, \"location\": \"LUL\", \"probability\": 0.85}`\n",
    "> * **åæœ**ï¼šä»£ç å¯ä»¥ç›´æ¥è¯»å– `data['lesion_size_mm']` è¿›è¡Œè‡ªåŠ¨åˆ†è¯Šã€‚\n",
    "> \n",
    "> \n",
    "> \n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba205773",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬çš„ç›®æ ‡ï¼Œå°±æ˜¯å¼ºè¿«é‚£ä¸ªçˆ±è¯´è¯çš„â€œåŒ»ç”Ÿâ€ï¼ˆLLMï¼‰ï¼ŒæŠŠç»“æœå¡«è¿›æˆ‘ä»¬çš„â€œè¡¨æ ¼â€ï¼ˆJSONï¼‰é‡Œï¼Œè€Œä¸æ˜¯å£è¿°ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6290357",
   "metadata": {},
   "source": [
    "## ğŸ’» 3. ä»£ç å®ç° (Notebook å®éªŒ)\n",
    "\n",
    "è¯·åœ¨ Notebook ä¸­ä¾æ¬¡è¿è¡Œã€‚\n",
    "\n",
    "### Step 1: é—®é¢˜çš„äº§ç”Ÿ (The \"Chatty\" Model)\n",
    "\n",
    "æˆ‘ä»¬è¯•å›¾è®©æ¨¡å‹æå–æ¡ˆä»¶ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "532eda1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- åŸå§‹å›å¤ ---\n",
      "{\n",
      "  \"å«Œç–‘äººå§“å\": \"å¼ ä¸‰\",\n",
      "  \"è¢«ç›—æ€»é‡‘é¢\": 7000,\n",
      "  \"çŠ¯ç½ªç±»å‹\": \"ç›—çªƒ\"\n",
      "}\n",
      "è§£ææˆåŠŸï¼\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../../\")) \n",
    "from src.llm.client import LLMClient\n",
    "\n",
    "client = LLMClient()\n",
    "\n",
    "case = \"å«Œç–‘äººå¼ ä¸‰è¶å¤œè‰²æºœè¿›æå››å®¶ï¼Œå·èµ°ç°é‡‘ 5000 å…ƒå’Œä¸€éƒ¨ä»·å€¼ 2000 å…ƒçš„æ‰‹æœºã€‚\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "è¯·åˆ†æä»¥ä¸‹æ¡ˆä»¶ï¼Œæå–ï¼šå«Œç–‘äººå§“åã€è¢«ç›—æ€»é‡‘é¢ã€çŠ¯ç½ªç±»å‹ã€‚\n",
    "è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºã€‚\n",
    "\n",
    "æ¡ˆä»¶ï¼š{case}\n",
    "\"\"\"\n",
    "\n",
    "response = client.generate(prompt)\n",
    "print(f\"--- åŸå§‹å›å¤ ---\\n{response}\")\n",
    "\n",
    "# å°è¯•è§£æ\n",
    "try:\n",
    "    data = json.loads(response)\n",
    "    print(\"è§£ææˆåŠŸï¼\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"\\nâŒ è§£æå¤±è´¥ï¼æ¨¡å‹å¯èƒ½è¾“å‡ºäº†å¤šä½™çš„æ–‡å­— (Markdown æ ‡è®°ç­‰)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e99645c",
   "metadata": {},
   "source": [
    "> **ğŸ”´ å¸¸è§ç¿»è½¦ç°åœº**ï¼š\n",
    "> æ¨¡å‹ç»å¸¸ä¼šè¾“å‡ºï¼š\n",
    "> ```markdown\n",
    "> ```json\n",
    "> {\n",
    ">     \"name\": \"å¼ ä¸‰\",\n",
    ">     ...\n",
    "> }\n",
    "> \n",
    "> ```\n",
    "> \n",
    "> \n",
    "> è¿™é‡Œçš„ JSON æ•°æ®ä¾›å‚è€ƒã€‚\n",
    "> ```\n",
    "> è¿™ç§å¸¦æœ‰ Markdown æ ‡è®° (` ```json `) æˆ–è€…å‰ååºŸè¯çš„å­—ç¬¦ä¸²ï¼Œç›´æ¥ç”¨ `json.loads()` ä¼šæŠ¥é”™ã€‚\n",
    "> \n",
    "> ```\n",
    "> \n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80028b8b",
   "metadata": {},
   "source": [
    "### Step 2: æ­£åˆ™è¡¨è¾¾å¼ - æš´åŠ›æ¸…æ´— (The Regex Fix)\n",
    "\n",
    "è¿™æ˜¯æœ€é€šç”¨çš„â€œåˆ›å¯è´´â€ä¿®å¤æ³•ã€‚ä¸ç®¡æ¨¡å‹è¯´äº†ä»€ä¹ˆåºŸè¯ï¼Œæˆ‘ä»¬åªæŠ“å– `{` å’Œ `}` ä¹‹é—´çš„å†…å®¹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a869e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Regex æå–ç»“æœ ---\n",
      "{'å«Œç–‘äººå§“å': 'å¼ ä¸‰', 'è¢«ç›—æ€»é‡‘é¢': 7000, 'çŠ¯ç½ªç±»å‹': 'ç›—çªƒ'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_json_with_regex(text):\n",
    "    # åŒ¹é…æœ€å¤–å±‚çš„ {}\n",
    "    # DOTALL æ¨¡å¼è®© . å¯ä»¥åŒ¹é…æ¢è¡Œç¬¦\n",
    "    match = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "    if match:\n",
    "        json_str = match.group()\n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except json.JSONDecodeError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "data = extract_json_with_regex(response)\n",
    "print(f\"--- Regex æå–ç»“æœ ---\\n{data}\")\n",
    "# å¦‚æœ Step 1 è¾“å‡ºå¸¦ Markdownï¼Œè¿™é‡Œé€šå¸¸èƒ½æ•‘å›æ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ae06f6",
   "metadata": {},
   "source": [
    "### Step 3: Pydantic - å®šä¹‰â€œå®Œç¾æ¨¡å…·â€ (The Schema Way)\n",
    "\n",
    "ä¸ºäº†è®©æ¨¡å‹æ›´å¬è¯ï¼Œæˆ‘ä»¬ç›´æ¥æŠŠ JSON çš„å®šä¹‰ï¼ˆSchemaï¼‰å–‚ç»™å®ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35181efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pydantic Schema ---\n",
      "{\n",
      "  \"properties\": {\n",
      "    \"suspect\": {\n",
      "      \"description\": \"å«Œç–‘äººçš„å§“å\",\n",
      "      \"title\": \"Suspect\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"amount\": {\n",
      "      \"description\": \"æ¶‰åŠçš„æ€»é‡‘é¢ï¼Œçº¯æ•°å­—\",\n",
      "      \"title\": \"Amount\",\n",
      "      \"type\": \"number\"\n",
      "    },\n",
      "    \"crime_type\": {\n",
      "      \"description\": \"çŠ¯ç½ªç±»å‹ï¼Œå¦‚ï¼šç›—çªƒã€æŠ¢åŠ«\",\n",
      "      \"title\": \"Crime Type\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"summary\": {\n",
      "      \"description\": \"ä¸€å¥è¯æ¡ˆæƒ…æ‘˜è¦ï¼Œä¸è¶…è¿‡20å­—\",\n",
      "      \"title\": \"Summary\",\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"suspect\",\n",
      "    \"amount\",\n",
      "    \"crime_type\",\n",
      "    \"summary\"\n",
      "  ],\n",
      "  \"title\": \"CrimeCase\",\n",
      "  \"type\": \"object\"\n",
      "}\n",
      "\n",
      "--- ç»“æ„åŒ–å›å¤ ---\n",
      "{\n",
      "  \"suspect\": \"å¼ ä¸‰\",\n",
      "  \"amount\": 7000,\n",
      "  \"crime_type\": \"ç›—çªƒ\",\n",
      "  \"summary\": \"å¼ ä¸‰ç›—çªƒæå››å®¶ç°é‡‘å’Œæ‰‹æœº\"\n",
      "}\n",
      "\n",
      "âœ… Pydantic éªŒè¯é€šè¿‡ï¼\n",
      "å«Œç–‘äºº: å¼ ä¸‰\n",
      "é‡‘é¢: 7000.0\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 1. å®šä¹‰æ•°æ®ç»“æ„ (ç±»æ¯”ï¼šå®šä¹‰ C++ çš„ Struct æˆ– SQL è¡¨ç»“æ„)\n",
    "class CrimeCase(BaseModel):\n",
    "    suspect: str = Field(description=\"å«Œç–‘äººçš„å§“å\")\n",
    "    amount: float = Field(description=\"æ¶‰åŠçš„æ€»é‡‘é¢ï¼Œçº¯æ•°å­—\")\n",
    "    crime_type: str = Field(description=\"çŠ¯ç½ªç±»å‹ï¼Œå¦‚ï¼šç›—çªƒã€æŠ¢åŠ«\")\n",
    "    summary: str = Field(description=\"ä¸€å¥è¯æ¡ˆæƒ…æ‘˜è¦ï¼Œä¸è¶…è¿‡20å­—\")\n",
    "\n",
    "# 2. è·å– Schema (è¿™å°±æ˜¯æˆ‘ä»¬è¦å–‚ç»™ Prompt çš„'è¡¨æ ¼')\n",
    "schema_str = json.dumps(CrimeCase.model_json_schema(), indent=2, ensure_ascii=False)\n",
    "print(f\"--- Pydantic Schema ---\\n{schema_str}\")\n",
    "\n",
    "# 3. æ„é€ ç²¾å‡† Prompt\n",
    "prompt_with_schema = f\"\"\"\n",
    "è¯·åˆ†ææ¡ˆä»¶å¹¶æå–ä¿¡æ¯ã€‚\n",
    "**å¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦è¾“å‡ºä»»ä½• Markdown æ ‡è®°æˆ–é¢å¤–è§£é‡Šï¼š**\n",
    "\n",
    "{schema_str}\n",
    "\n",
    "æ¡ˆä»¶ï¼š{case}\n",
    "\"\"\"\n",
    "\n",
    "response_structured = client.generate(prompt_with_schema, temperature=0.0) # ç»“æ„åŒ–ä»»åŠ¡è®°å¾—æŠŠ T é™ä¸º 0\n",
    "print(f\"\\n--- ç»“æ„åŒ–å›å¤ ---\\n{response_structured}\")\n",
    "\n",
    "# 4. éªŒè¯å¹¶è½¬å›å¯¹è±¡\n",
    "final_data = extract_json_with_regex(response_structured)\n",
    "if final_data:\n",
    "    try:\n",
    "        # Pydantic è¿˜èƒ½å¸®æˆ‘ä»¬æ£€æŸ¥æ•°æ®ç±»å‹ (æ¯”å¦‚ amount æ˜¯ä¸æ˜¯ float)\n",
    "        case_obj = CrimeCase(**final_data)\n",
    "        print(\"\\nâœ… Pydantic éªŒè¯é€šè¿‡ï¼\")\n",
    "        print(f\"å«Œç–‘äºº: {case_obj.suspect}\")\n",
    "        print(f\"é‡‘é¢: {case_obj.amount}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æ•°æ®ç±»å‹é”™è¯¯: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19ad7a7",
   "metadata": {},
   "source": [
    "## ğŸ§  4. æ·±åº¦ç†è®º & é¢è¯•å¿…é—® (Deep Dive)\n",
    "\n",
    "### ğŸ”¥ Q1: å¦‚æœæ¨¡å‹ç”Ÿæˆçš„ JSON å°‘äº†ä¸€ä¸ªæ‹¬å·ï¼Œå·¥ç¨‹ä¸Šæ€ä¹ˆå®¹é”™ï¼Ÿ\n",
    "\n",
    "è¿™ä¸ªé—®é¢˜éå¸¸ç»å…¸ã€‚ä½ æœ‰ä¸‰å±‚é˜²å¾¡ä½“ç³»ï¼š\n",
    "\n",
    "1. **Level 1: æç¤ºå·¥ç¨‹ (Prompting)**\n",
    "* åœ¨ System Prompt ä¸­å¼ºè°ƒï¼š*\"You are a JSON generator. Do not output anything else.\"*\n",
    "* ä½¿ç”¨ **One-shot**ï¼šç»™ä¸€ä¸ªåˆæ³•çš„ JSON ç¤ºä¾‹ã€‚\n",
    "* **JSON Mode**: ç°åœ¨å¾ˆå¤š API (OpenAI/DeepSeek) æ”¯æŒå‚æ•° `response_format={\"type\": \"json_object\"}`ï¼Œè¿™åœ¨åº•å±‚å¼ºè¡Œé™åˆ¶äº† Logits çš„ç”Ÿæˆï¼Œæå¤§é™ä½è¯­æ³•é”™è¯¯ç‡ã€‚\n",
    "\n",
    "\n",
    "2. **Level 2: è§„åˆ™ä¿®å¤ (Rule-based Repair)**\n",
    "* **Regex**: å°±åƒåˆšæ‰å†™çš„ï¼Œåªæå– `{}`ã€‚\n",
    "* **ç¬¬ä¸‰æ–¹åº“**: ä½¿ç”¨ `json_repair` åº“ï¼ˆPython åŒ…ï¼‰ï¼Œå®ƒå¯ä»¥è‡ªåŠ¨è¡¥å…¨ç¼ºå¤±çš„ `}` æˆ–å¼•å·ã€‚\n",
    "\n",
    "\n",
    "3. **Level 3: è‡ªæ„ˆå¾ªç¯ (Self-Correction / Retry) â€”â€” æ€æ‰‹é”**\n",
    "* å¦‚æœ `json.loads` æŠ¥é”™ï¼Œ**æ•è·é”™è¯¯ä¿¡æ¯**ï¼ŒæŠŠâ€œé”™è¯¯ä¿¡æ¯â€å’Œâ€œé”™è¯¯çš„ JSONâ€ä¸€èµ·æ‰”å›ç»™ LLMã€‚\n",
    "* **Prompt**: *\"ä½ åˆšæ‰ç”Ÿæˆçš„ JSON è§£ææŠ¥é”™äº†ï¼šExpectng value at line 1 column 10ã€‚è¯·ä¿®å¤å®ƒå¹¶é‡æ–°è¾“å‡ºã€‚\"*\n",
    "* è¿™åˆ©ç”¨äº† LLM å¼ºå¤§çš„çº é”™èƒ½åŠ›ã€‚LangChain çš„ `OutputParser` å°±å†…ç½®äº†è¿™ç§ Retry æœºåˆ¶ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b846a7f",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ 5. å·¥ç¨‹å°è£… (Engineering)\n",
    "\n",
    "è®©æˆ‘ä»¬æŠŠæå–é€»è¾‘å°è£…åˆ° `src/llm/parsers.py`ã€‚\n",
    "\n",
    "```python\n",
    "# src/llm/parsers.py\n",
    "import re\n",
    "import json\n",
    "from typing import Optional, Any, Type\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class BaseOutputParser:\n",
    "    def parse(self, text: str) -> Any:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class JsonOutputParser(BaseOutputParser):\n",
    "    def __init__(self, pydantic_model: Optional[Type[BaseModel]] = None):\n",
    "        \"\"\"\n",
    "        :param pydantic_model: å¦‚æœæä¾›ï¼Œä¼šç”¨å®ƒæ¥éªŒè¯æ•°æ®ç»“æ„\n",
    "        \"\"\"\n",
    "        self.pydantic_model = pydantic_model\n",
    "\n",
    "    def parse(self, text: str) -> dict:\n",
    "        # 1. å°è¯•æ¸…æ´— Markdown æ ‡è®° (```json ... ```)\n",
    "        cleaned_text = text.strip()\n",
    "        # åŒ¹é… ```json ... ``` æˆ– ``` ... ```\n",
    "        match = re.search(r\"```(json)?(.*?)```\", cleaned_text, re.DOTALL)\n",
    "        if match:\n",
    "            cleaned_text = match.group(2).strip()\n",
    "        \n",
    "        # 2. å¦‚æœè¿˜æœ‰å¤šä½™å­—ç¬¦ï¼Œå°è¯• Regex æå–æœ€å¤–å±‚ {}\n",
    "        match_bracket = re.search(r\"\\{.*\\}\", cleaned_text, re.DOTALL)\n",
    "        if match_bracket:\n",
    "            cleaned_text = match_bracket.group()\n",
    "\n",
    "        # 3. è§£æ JSON\n",
    "        try:\n",
    "            data = json.loads(cleaned_text)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"JSON è§£æå¤±è´¥: {e}\\nåŸæ–‡: {text}\")\n",
    "\n",
    "        # 4. Pydantic éªŒè¯\n",
    "        if self.pydantic_model:\n",
    "            try:\n",
    "                obj = self.pydantic_model(**data)\n",
    "                return obj.model_dump() # è½¬å› dictï¼Œæˆ–è€…ç›´æ¥è¿”å› obj\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Schema éªŒè¯å¤±è´¥: {e}\")\n",
    "        \n",
    "        return data\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de967624",
   "metadata": {},
   "source": [
    "## ğŸ§© 6. ä»Šæ—¥ LeetCode ç»ƒä¹ \n",
    "\n",
    "å¤„ç†ç»“æ„åŒ–è¾“å‡ºç»å¸¸æ¶‰åŠå­—ç¬¦ä¸²è§£æã€‚\n",
    "\n",
    "* **é¢˜ç›®**: **[String to Integer (atoi) (LC 8)](../../LeetCode%20practice/1-50.ipynb)** - ä¸­ç­‰\n",
    "* **å…³è”**: è¿™é“é¢˜å°±æ˜¯è®©ä½ å†™ä¸€ä¸ªç®€å•çš„ Parserã€‚\n",
    "* éœ€è¦ä¸¢å¼ƒå‰å¯¼ç©ºæ ¼ã€‚\n",
    "* å¤„ç†æ­£è´Ÿå·ã€‚\n",
    "* é‡åˆ°éæ•°å­—å­—ç¬¦åœæ­¢ã€‚\n",
    "* è¿™å’Œæˆ‘ä»¬ä» LLM çš„åºŸè¯ä¸­æå– JSON çš„é€»è¾‘ï¼ˆçŠ¶æ€æœºæ€ç»´ï¼‰éå¸¸åƒã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d6adbb",
   "metadata": {},
   "source": [
    "## âœ… 7. ä»Šæ—¥ä»»åŠ¡æ€»ç»“\n",
    "\n",
    "* [ ] åœ¨ Notebook ä¸­ä½“éªŒäº† LLM è¾“å‡º JSON æ—¶çš„â€œä¸å¬è¯â€ã€‚\n",
    "* [ ] å®ç°äº† **Regex** æå–æ³•ã€‚\n",
    "* [ ] ä½¿ç”¨ **Pydantic** ç”Ÿæˆäº† JSON Schemaï¼Œå¹¶ä»¥æ­¤çº¦æŸ Promptã€‚\n",
    "* [ ] **é¢è¯•å‡†å¤‡**ï¼šæŒæ¡äº† JSON å®¹é”™çš„ä¸‰å±‚ä½“ç³»ï¼ˆPrompt, Rule, Retryï¼‰ã€‚\n",
    "* [ ] **ä»£ç å°è£…**ï¼šå®Œæˆäº† `src/llm/parsers.py`ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
