import sys
import os
import json
from typing import List

# --- 1. ç¯å¢ƒè®¾ç½® (Week 8 Day 1) ---
# ç¡®ä¿èƒ½æ‰¾åˆ° src ç›®å½•
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))

from dotenv import load_dotenv
from pydantic import BaseModel, Field

# å¯¼å…¥æˆ‘ä»¬è‡ªå·±é€ çš„è½®å­
from src.llm.client import LLMClient       # W8D1
from src.llm.memory import MemoryBuffer     # W8D5
from src.llm.parsers import JsonOutputParser # W8D3

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# --- 2. å®šä¹‰æ•°æ®ç»“æ„ (Week 8 Day 3 - Structured Output) ---
class LegalVerdict(BaseModel):
    analysis: str = Field(description="æ¡ˆä»¶çš„è¯¦ç»†æ³•å¾‹åˆ†æï¼ŒåŒ…å«æ€è€ƒè¿‡ç¨‹")
    verdict: str = Field(description="åˆæ­¥åˆ¤å†³å»ºè®®ï¼Œå¦‚ï¼šæœ‰æœŸå¾’åˆ‘3å¹´")
    confidence: float = Field(description="ç½®ä¿¡åº¦ï¼Œ0.0åˆ°1.0ä¹‹é—´")
    laws: List[str] = Field(description="æ¶‰åŠçš„ç›¸å…³æ³•å¾‹æ¡æ¬¾åˆ—è¡¨")

# --- 3. åˆå§‹åŒ–ç»„ä»¶ ---
def init_app():
    print("ğŸ¤– åˆå§‹åŒ–æ³•å¾‹å°åŠ©æ‰‹ v0.1...")
    
    # 1. å®¢æˆ·ç«¯
    client = LLMClient() 
    
    # 2. è®°å¿†æ¨¡å— (é™åˆ¶æœ€è¿‘ 2000 token)
    memory = MemoryBuffer(max_tokens=2000, system_prompt="ä½ æ˜¯ä¸€åä¸“ä¸šçš„åˆ‘äº‹è¾©æŠ¤å¾‹å¸ˆã€‚")
    
    # 3. è§£æå™¨
    parser = JsonOutputParser(pydantic_model=LegalVerdict)
    
    return client, memory, parser

# --- 4. æ ¸å¿ƒäº¤äº’å¾ªç¯ (Integration) ---
def main():
    client, memory, parser = init_app()
    
    print("\nâš–ï¸  æ³•å¾‹å°åŠ©æ‰‹å·²å°±ç»ªï¼(è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡º)")
    print("--------------------------------------------------")

    while True:
        # A. è·å–ç”¨æˆ·è¾“å…¥
        user_input = input("\nğŸ‘¤ å½“äº‹äººæè¿°: ").strip()
        if user_input.lower() in ['exit', 'quit']:
            print("ğŸ‘‹ å†è§ï¼")
            break
        
        if not user_input:
            continue

        # B. è¿™é‡Œçš„é€»è¾‘æ ¸å¿ƒï¼šæ‹¼è£… Prompt (Week 8 Day 2 - Prompt Engineering)
        # æˆ‘ä»¬éœ€è¦æŠŠ å†å²è®°å½• + å½“å‰é—®é¢˜ + æ ¼å¼è¦æ±‚ æ‹¼åœ¨ä¸€èµ·
        
        # 1. è·å–æ ¼å¼è¯´æ˜ (Schema)
        schema_json = json.dumps(LegalVerdict.model_json_schema(), ensure_ascii=False)
        
        # 2. è·å–å†å²è®°å½• (è½¬æ¢ä¸ºæ–‡æœ¬)
        history_text = ""
        for msg in memory.get_context():
            role = msg['role']
            content = msg['content']
            # è·³è¿‡ system promptï¼Œå› ä¸ºå®ƒé€šå¸¸ä¸æ”¾åœ¨ history æ–‡æœ¬æ®µé‡Œé‡å¤
            if role != "system":
                history_text += f"{role}: {content}\n"

        # 3. æ„é€ æœ€ç»ˆ Prompt (CoT + JSON Mode)
        final_prompt = f"""
ä½ æ˜¯ä¸€åä¸“ä¸šå¾‹å¸ˆã€‚è¯·åŸºäºä»¥ä¸‹å¯¹è¯å†å²å’Œæ–°çš„æ¡ˆæƒ…æè¿°è¿›è¡Œåˆ†æã€‚

ã€å¯¹è¯å†å²ã€‘
{history_text}

ã€æ–°çš„æ¡ˆæƒ…ã€‘
{user_input}

ã€ä»»åŠ¡è¦æ±‚ã€‘
1. è¯·ä¸€æ­¥æ­¥æ€è€ƒ (Let's think step by step)ï¼Œåˆ†ææ¡ˆä»¶çš„èµ·å› ã€ç»è¿‡ã€ç»“æœå’Œæ³•å¾‹é€‚ç”¨ã€‚
2. å¿…é¡»ä»¥ä¸¥æ ¼çš„ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦åŒ…å« Markdown æ ‡è®°ã€‚
3. è¾“å‡ºç»“æ„å¿…é¡»ç¬¦åˆä»¥ä¸‹ Schemaï¼š
{schema_json}
"""

        print("\nğŸ¤– AI æ­£åœ¨æ€è€ƒä¸­... (æ¶‰åŠ CoT æ¨ç†)")
        
        try:
            # C. è°ƒç”¨æ¨¡å‹ (Week 8 Day 1)
            # æ³¨æ„ï¼šå¦‚æœä½ çš„ client æ”¯æŒ messages åˆ—è¡¨ï¼Œç›´æ¥ä¼  messages æ›´å¥½
            # ä½†ä¸ºäº†å…¼å®¹æœ€åŸºç¡€çš„ client.generate(str)ï¼Œæˆ‘ä»¬ä¼  string
            raw_response = client.generate(final_prompt, temperature=0.1) # é™ä½æ¸©åº¦ä»¥ä¿è¯ JSON æ ¼å¼
            
            # D. è§£æç»“æœ (Week 8 Day 3)
            # parser ä¼šè‡ªåŠ¨å¤„ç† Markdown æ¸…æ´—å’Œ JSON æå–
            result_dict = parser.parse(raw_response)
            
            # E. å±•ç¤ºç»“æœ
            print("-" * 30)
            print(f"ğŸ§ **æ¡ˆæƒ…åˆ†æ**: {result_dict.get('analysis')}")
            print(f"âš–ï¸  **åˆ¤å†³å»ºè®®**: {result_dict.get('verdict')}")
            print(f"ğŸ“Š **ç½®ä¿¡åº¦**: {result_dict.get('confidence')}")
            print(f"ğŸ“œ **å¼•ç”¨æ³•æ¡**: {', '.join(result_dict.get('laws', []))}")
            print("-" * 30)

            # F. æ›´æ–°è®°å¿† (Week 8 Day 5)
            # å­˜å…¥ç”¨æˆ·çš„åŸå§‹è¾“å…¥
            memory.add("user", user_input)
            # å­˜å…¥ AI çš„å›å¤ (ä¸ºäº†èŠ‚çœ Tokenï¼Œæˆ‘ä»¬åªå­˜ JSON å­—ç¬¦ä¸²ï¼Œæˆ–è€…å­˜ analysis)
            # è¿™é‡Œé€‰æ‹©å­˜å®Œæ•´çš„ JSON å­—ç¬¦ä¸²ï¼Œä»¥ä¾¿ AI è®°å¾—è‡ªå·±ä¹‹å‰çš„åˆ¤æ–­
            memory.add("assistant", json.dumps(result_dict, ensure_ascii=False))
            
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
            # å¦‚æœè§£æå¤±è´¥ï¼ŒæŠŠåŸå§‹å›å¤æ‰“å°å‡ºæ¥çœ‹çœ‹
            if 'raw_response' in locals():
                 print(f"åŸå§‹å›å¤: {raw_response}")

if __name__ == "__main__":
    main()