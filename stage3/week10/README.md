# Stage 3 Week 10: Deep Learning Math & RAG Refinement
**Owner**: Huang Gaopeng  
**Role**: AI Algorithm Engineer Candidate  
**Status**: In Progress  
**Focus**: Backpropagation, Optimizers, RAG Re-ranking, Binary Trees

## ğŸ¯ Weekly Objectives (æœ¬å‘¨ç›®æ ‡)
1.  **Math "Internal Strength" (æ•°å­¦å†…åŠŸ)**:
    * èƒ½å¤Ÿæ‰‹æ¨å…¨è¿æ¥å±‚ (Linear Layer) çš„åå‘ä¼ æ’­ (BP) è¿‡ç¨‹ã€‚
    * æ·±åˆ»ç†è§£â€œæ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸â€çš„æ•°å­¦æˆå› åŠè§£å†³æ–¹æ¡ˆ (Sigmoid vs ReLU, BatchNorm)ã€‚
    * ç†è§£ SGD, Momentum, Adam çš„æ ¸å¿ƒåŒºåˆ«ã€‚
2.  **RAG Enhancement (ç²¾æ’ä¼˜åŒ–)**:
    * ç†è§£ Bi-Encoder (å‘é‡æ£€ç´¢) ä¸ Cross-Encoder (é‡æ’åº) çš„åŒºåˆ«ã€‚
    * åœ¨ç°æœ‰ RAG æµç¨‹ä¸­å¼•å…¥ `Re-ranker` æ¨¡å—ï¼Œæé«˜ Context å‡†ç¡®æ€§ã€‚
3.  **Algorithm (æ•°æ®ç»“æ„)**:
    * æŒæ¡äºŒå‰æ ‘çš„åŸºç¡€éå† (DFS/BFS)ã€‚

---

## ğŸ“… Daily Schedule (æ¯æ—¥å®‰æ’)

### Day 1: The Calculus of Backpropagation (BP æ¨å¯¼æ—¥)
* **Theme**: ç—›è‹¦ä½†å¿…é¡»ç»å†çš„æ‰‹æ¨å…¬å¼ã€‚
* **Theory**:
    * å¤ä¹ é“¾å¼æ³•åˆ™ (Chain Rule)ã€‚
    * **Core Task**: åœ¨çº¸ä¸Šæ¨å¯¼ä¸€ä¸ªç®€å•çš„ 2 å±‚ç¥ç»ç½‘ç»œ (Input -> Linear -> Sigmoid -> Linear -> Loss) çš„æ¢¯åº¦æ›´æ–°å…¬å¼ã€‚
    * Key Question: å½“è¾“å…¥ç»´åº¦æ˜¯ $(N, D_{in})$ï¼Œè¾“å‡ºæ˜¯ $(N, D_{out})$ æ—¶ï¼Œæ¢¯åº¦çš„ç»´åº¦æ˜¯å¤šå°‘ï¼Ÿ
* **Action**:
    * åˆ›å»º `S3W10D1_Backprop_Derivation.md` è®°å½•æ¨å¯¼è¿‡ç¨‹ï¼ˆæ‹ç…§æˆ–æ‰‹å†™ LaTeXï¼‰ã€‚
* **LeetCode**: LC 104. Maximum Depth of Binary Tree (Easy - é€’å½’çƒ­èº«).

### Day 2: Gradient Problems & Activations (æ¢¯åº¦ä¸æ¿€æ´»å‡½æ•°)
* **Theme**: ä¸ºä»€ä¹ˆæ·±å±‚ç½‘ç»œéš¾è®­ç»ƒï¼Ÿ
* **Theory**:
    * åˆ†æ Sigmoid å¯¼æ•°å›¾åƒï¼ˆæœ€å¤§å€¼ 0.25ï¼‰ï¼Œè§£é‡Šå…¶å¯¼è‡´çš„æ¢¯åº¦æ¶ˆå¤± (Vanishing Gradient)ã€‚
    * å¯¹æ¯” ReLU çš„å¯¼æ•°ç‰¹æ€§ã€‚
* **Coding**:
    * åˆ›å»º `S3W10D2_Gradient_Viz.ipynb`ã€‚
    * æ„å»ºä¸€ä¸ªç®€å•çš„æ·±å±‚ç½‘ç»œï¼ˆ10å±‚+ï¼‰ï¼Œåˆ†åˆ«ä½¿ç”¨ Sigmoid å’Œ ReLUï¼Œæ‰“å°æ¯å±‚çš„æ¢¯åº¦å‡å€¼ï¼Œè§‚å¯Ÿâ€œæ¢¯åº¦æ¶ˆå¤±â€ç°è±¡ã€‚
* **LeetCode**: LC 226. Invert Binary Tree (ç¿»è½¬äºŒå‰æ ‘ - ç»å…¸é¢˜).

### Day 3: Optimizers - SGD vs Adam (ä¼˜åŒ–å™¨ä¹‹æˆ˜)
* **Theme**: ä¸ºä»€ä¹ˆ Adam æ˜¯â€œç‚¼ä¸¹â€é¦–é€‰ï¼Ÿ
* **Theory**:
    * **SGD**: éšæœºæ¢¯åº¦ä¸‹é™çš„ç¼ºç‚¹ï¼ˆéœ‡è¡ã€å¡åœ¨éç‚¹ï¼‰ã€‚
    * **Momentum**: åŠ¨é‡æ¦‚å¿µï¼ˆæƒ¯æ€§ï¼‰ã€‚
    * **Adam**: ç»“åˆ Momentum + RMSprop (è‡ªé€‚åº”å­¦ä¹ ç‡)ã€‚ä¸éœ€è¦èƒŒå¤æ‚å…¬å¼ï¼Œä½†è¦æ‡‚æ ¸å¿ƒæ€æƒ³ï¼šä¸€é˜¶åŠ¨é‡ï¼ˆæ–¹å‘ï¼‰ï¼ŒäºŒé˜¶åŠ¨é‡ï¼ˆæ­¥é•¿ç¼©æ”¾ï¼‰ã€‚
* **Coding**:
    * åœ¨ `S3W10D2` çš„ Notebook ä¸­ï¼Œå¯¹æ¯”ä½¿ç”¨ `torch.optim.SGD` å’Œ `torch.optim.Adam` çš„ Loss ä¸‹é™æ›²çº¿ã€‚

### Day 4: RAG Logic - The Need for Re-ranking (é‡æ’åºç†è®º)
* **Theme**: å‘é‡ç›¸ä¼¼åº¦ $\neq$ è¯­ä¹‰ç›¸å…³åº¦ã€‚
* **Theory**:
    * å›é¡¾ Naive RAG çš„ç—›ç‚¹ï¼šå‘é‡åº“å¬å› Top-Kï¼Œä½†ç¬¬ 1 åå¯èƒ½ä¸æ˜¯æœ€ç›¸å…³çš„ï¼ˆåªæ˜¯å­—é¢ç›¸ä¼¼ï¼‰ã€‚
    * **Cross-Encoder**: ä¸ºä»€ä¹ˆå®ƒæ¯” Bi-Encoder å‡†ä½†æ›´æ…¢ï¼Ÿ(Input: `[CLS] Query [SEP] Doc [SEP]`)ã€‚
    * è°ƒç ”æ¨¡å‹ï¼š`BAAI/bge-reranker-base` æˆ– `bge-reranker-v2-m3`ã€‚
* **Action**:
    * é˜…è¯» BGE Reranker çš„ Hugging Face Model Cardã€‚

### Day 5: Implementing RAG Re-ranker (å®æˆ˜é‡æ’åº)
* **Theme**: ç»™ RAG åŠ ä¸Šâ€œå®¡é¢˜â€æ¨¡å—ã€‚
* **Coding**:
    * åˆ›å»º `src/rag/reranker.py`ã€‚
    * å°è£…ä¸€ä¸ª `RerankClient` ç±»ï¼Œä½¿ç”¨ Hugging Face `CrossEncoder` æˆ– `AutoModelForSequenceClassification`ã€‚
    * **Integration**: ä¿®æ”¹ `src/rag/engine.py` (æˆ–ä½ çš„ä¸»æµç¨‹)ï¼Œåœ¨ `vector_db.search()` ä¹‹åï¼Œæ¥å…¥ `reranker.rank()`ï¼Œä» Top-10 ç­›é€‰å‡º Top-3ã€‚
* **Deliverable**: è¿è¡Œä¸€ä¸ª Queryï¼Œå¯¹æ¯”åŠ ä¸Š Rerank å‰åçš„æ£€ç´¢ç»“æœã€‚

### Day 6: Binary Tree BFS & Review (å¹¿åº¦ä¼˜å…ˆæœç´¢)
* **Theme**: é˜Ÿåˆ— (Queue) çš„åº”ç”¨ã€‚
* **LeetCode**:
    * LC 102. Binary Tree Level Order Traversal (å±‚åºéå† - ä¸­ç­‰é‡ç‚¹)ã€‚
    * ä½“ä¼š Queue åœ¨ BFS ä¸­çš„ä½œç”¨ã€‚
* **Review**:
    * æ•´ç†æœ¬å‘¨çš„æ•°å­¦ç¬”è®°ã€‚
    * æ£€æŸ¥ `src/rag/reranker.py` æ˜¯å¦å·²æäº¤åˆ° Gitã€‚

### Day 7: Weekly Summary & Rest
* **Check**:
    * [ ] èƒ½å¦å£è¿° BP çš„æ ¸å¿ƒé€»è¾‘ï¼Ÿ
    * [ ] RAG ç³»ç»Ÿæ˜¯å¦å·²ç»é›†æˆäº† Re-rankingï¼Ÿ
    * [ ] äºŒå‰æ ‘é¢˜ç›®æ˜¯å¦ç†Ÿç»ƒï¼ˆé€’å½’ vs è¿­ä»£ï¼‰ï¼Ÿ
* **Plan Next**: å‡†å¤‡ Week 11 çš„ Tool Use (Agent å·¥å…·è°ƒç”¨)ã€‚

---

## ğŸ“š Resources
* **Paper**: "Neural Machine Translation by Jointly Learning to Align and Translate" (Attention åŸºç¡€å›é¡¾)
* **Blog**: Jay Alammar - Visualizing A Neural Machine Translation
* **Docs**: Hugging Face `sentence-transformers` Cross-Encoder documentation.