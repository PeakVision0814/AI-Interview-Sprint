太好了！以下是为你量身定制的 **第 1 周详细学习计划（含每日任务）** 和 **项目目录结构建议**，目标是：

> **用 7 天时间，完成一个融合 Python + Pandas + NumPy + SQLite 的机器人日志分析工具，为后续 Agent 和简历项目打下坚实基础。**

---

## 📅 第 1 周详细学习计划（每日任务）

> ✅ 假设你每天可投入 **60–90 分钟**  
> ✅ 所有任务基于你已有的 Linux + Python 基础  
> ✅ 日志数据模拟你实习中的具身机器人输出

---

### **周一：项目初始化 + 日志模拟**

**目标**：创建项目骨架，生成模拟机器人日志数据。

**任务**：
1. 创建项目目录：
   ```bash
   mkdir -p smart-robot-log-analyzer/{data,src,docs}
   cd smart-robot-log-analyzer
   ```
2. 用 Python 生成模拟日志 CSV（`data/robot_logs_20251015.csv`）：
   - 字段：`timestamp`（ISO 格式）、`robot_id`、`x`、`y`、`theta`（角度）、`status`（"RUNNING"/"STOPPED"/"ERROR"）
   - 生成 1000 行，包含约 5% 的 "ERROR"
3. 初始化 Git：
   ```bash
   git init
   echo "venv/" > .gitignore
   echo "__pycache__/" >> .gitignore
   ```

**产出**：`data/robot_logs_20251015.csv`

---

### **周二：Pandas 基础分析**

**目标**：用 Pandas 加载并初步分析日志。

**任务**：
1. 创建 `src/log_loader.py`：
   - 函数 `load_logs(csv_path: str) -> pd.DataFrame`
   - 自动解析 `timestamp` 为 `datetime`
2. 创建 `src/analyzer.py`：
   - 函数 `basic_stats(df: pd.DataFrame)` → 打印：
     - 总记录数
     - 各 status 计数
     - x/y 范围
3. 主脚本 `main.py`：
   ```python
   from src.log_loader import load_logs
   from src.analyzer import basic_stats
   df = load_logs("data/robot_logs_20251015.csv")
   basic_stats(df)
   ```

**产出**：可运行的 `main.py`，输出基础统计

---

### **周三：NumPy 数值计算**

**目标**：用 NumPy 计算机器人运动特征。

**任务**：
1. 在 `analyzer.py` 中新增函数：
   - `compute_velocity(df: pd.DataFrame) -> np.ndarray`  
     （用 `np.diff` 计算相邻点距离 / 时间差）
   - `detect_stops(df: pd.DataFrame, min_duration_sec=2.0) -> pd.DataFrame`  
     （速度 < 0.01 且持续 ≥2 秒视为异常停顿）
2. 在 `main.py` 中调用并打印异常停顿时段

**关键点**：用 `.values` 将 DataFrame 列转为 NumPy 数组进行向量化计算

**产出**：能检测“异常停顿”的分析功能

---

### **周四：SQLite 数据库集成（基础）**

**目标**：将 CSV 导入 SQLite，实现双输入源。

**任务**：
1. 创建 `src/db_manager.py`：
   - 函数 `csv_to_sqlite(csv_path: str, db_path: str)`  
     （用 `df.to_sql("logs", conn, if_exists="replace")`）
2. 修改 `log_loader.py`：
   - 新增 `load_logs_from_db(db_path: str) -> pd.DataFrame`
3. 更新 `main.py`：
   - 支持 `--input data/logs.csv` 或 `--input data/logs.db`

**产出**：支持 CSV 和 SQLite 双模式输入

---

### **周五：SQL 查询实战**

**目标**：用 SQL 替代部分 Pandas 操作。

**任务**：
1. 在 `analyzer.py` 中新增函数：
   ```python
   def sql_error_count(conn) -> int:
       return conn.execute("SELECT COUNT(*) FROM logs WHERE status = 'ERROR'").fetchone()[0]
   ```
2. 添加函数：
   - `sql_daily_error_summary(conn)` → 按日期统计 ERROR 数
3. 在 `main.py` 中，当输入为 `.db` 时，优先使用 SQL 查询

**产出**：关键指标可通过 SQL 高效获取

---

### **周六：命令行接口 + 配置**

**目标**：工程化封装，支持灵活调用。

**任务**：
1. 用 `argparse` 重构 `main.py`：
   ```bash
   python main.py --input data/logs.csv --mode pandas
   python main.py --input data/logs.db --mode sql
   ```
2. 添加输出选项：
   - `--output summary.json`（保存统计结果）
3. 用 `logging` 替代 `print`

**产出**：专业级命令行工具

---

### **周日：文档 + GitHub 发布**

**目标**：完成第一个可展示项目。

**任务**：
1. 编写 `README.md`，包含：
   - 项目简介
   - 安装依赖（`pip install -r requirements.txt`）
   - 使用示例（含截图）
   - 技术栈说明（Python, Pandas, SQLite）
2. 创建 `requirements.txt`：
   ```
   pandas>=2.0
   numpy>=1.24
   ```
3. 提交并推送到 GitHub：
   ```bash
   git add .
   git commit -m "feat: complete week1 log analyzer"
   git remote add origin https://github.com/yourname/smart-robot-log-analyzer.git
   git push -u origin main
   ```

**产出**：完整的 GitHub 项目，可写入简历！

---

## 📂 推荐项目目录结构

```bash
smart-robot-log-analyzer/
├── data/
│   ├── robot_logs_20251015.csv      # 模拟日志
│   └── robot_logs.db                # SQLite 数据库（自动生成）
├── src/
│   ├── __init__.py
│   ├── log_loader.py                # 加载 CSV/DB
│   ├── analyzer.py                  # Pandas + SQL 分析逻辑
│   └── db_manager.py                # CSV ↔ SQLite 转换
├── main.py                          # 命令行入口
├── requirements.txt
├── README.md
└── .gitignore
```

> 💡 **设计原则**：
> - `src/` 存放核心模块，避免顶层文件混乱
> - 数据与代码分离（`data/` 独立）
> - 支持未来扩展（如加 `tests/`、`config/`）

---

## 🧪 示例：`analyzer.py` 片段（供参考）

```python
import pandas as pd
import numpy as np
import sqlite3
from datetime import datetime

def basic_stats(df: pd.DataFrame):
    print(f"Total records: {len(df)}")
    print("Status counts:")
    print(df['status'].value_counts())

def compute_velocity(df: pd.DataFrame):
    timestamps = pd.to_datetime(df['timestamp'])
    dt = timestamps.diff().dt.total_seconds().fillna(0).values
    dx = df['x'].diff().fillna(0).values
    dy = df['y'].diff().fillna(0).values
    dist = np.sqrt(dx**2 + dy**2)
    velocity = np.divide(dist, dt, out=np.zeros_like(dt), where=dt!=0)
    return velocity

def sql_error_count(conn: sqlite3.Connection) -> int:
    cur = conn.cursor()
    cur.execute("SELECT COUNT(*) FROM logs WHERE status = 'ERROR'")
    return cur.fetchone()[0]
```

---

## ✅ 第 1 周成功标志

- [ ] 能运行 `python main.py --input data/logs.csv` 并输出分析结果  
- [ ] 能运行 `python main.py --input data/logs.db --mode sql` 并得到相同结果  
- [ ] 项目已推送到 GitHub，README 清晰可读  
- [ ] 你能在简历中写下：  
  > “开发机器人日志分析工具，支持 CSV/SQLite 双模式，实现异常停顿检测与错误统计”

---

如果你希望我：
- **提供完整的 `main.py` / `analyzer.py` 模板代码**
- **生成模拟日志的 Python 脚本**
- **帮你写 `README.md` 初稿**

请直接告诉我！我可以立刻为你生成。祝你第 1 周顺利！🚀