{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1f0c3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f6a970",
   "metadata": {},
   "source": [
    "# ğŸ“˜S1W4D2: å¼•ç”¨ä¸å†…å­˜ (References & Memory)\n",
    "\n",
    "## 1 æ ¸å¿ƒæ¦‚å¿µï¼šçœ‹ä¸è§çš„â€œçº¿â€\n",
    "\n",
    "**åº•å±‚è”ç³» (The Connection):**\n",
    "\n",
    "  * **é“¾è¡¨ (Linked List)**ï¼šèŠ‚ç‚¹ä¹‹é—´é€šè¿‡æŒ‡é’ˆï¼ˆå¼•ç”¨ï¼‰è¿æ¥ã€‚ä¸¢å¤±äº†æŒ‡é’ˆï¼Œå°±ä¸¢å¤±äº†æ•´ä¸ªé“¾è¡¨ã€‚\n",
    "  * **è®¡ç®—å›¾ (Computational Graph)**ï¼šPyTorch çš„è‡ªåŠ¨å¾®åˆ†å›¾æœ¬è´¨ä¸Šå°±æ˜¯ä¸€ä¸ªå·¨å¤§çš„ã€å¤æ‚çš„é“¾è¡¨ï¼ˆDAGï¼‰ã€‚`Loss` é¡ºç€ `grad_fn` è¿™æ ¹çº¿å¾€å›æ‰¾ï¼Œæ‰èƒ½æ›´æ–° `Weights`ã€‚å¦‚æœä¸­é—´è¿™æ ¹çº¿æ–­äº†ï¼ˆæ¯”å¦‚è¯¯ç”¨äº† `detach`ï¼‰ï¼Œæ¨¡å‹å°±æ²¡æ³•å­¦ä¹ ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319b8705",
   "metadata": {},
   "source": [
    "## 2 PyTorch å†…å­˜å®æˆ˜ (The \"Job\" Skills)\n",
    "\n",
    "åœ¨è®­ç»ƒæ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬ç»å¸¸éœ€è¦å¤åˆ¶å¼ é‡ã€‚ä½†æ˜¯ï¼Œæ€ä¹ˆå¤åˆ¶å†³å®šäº†æ¢¯åº¦èƒ½ä¸èƒ½ä¼ è¿‡å»ã€‚\n",
    "\n",
    "### 2.1 å¼•ç”¨ vs æ‹·è´ (Reference vs Copy)\n",
    "\n",
    "è¯·è¿è¡Œä»¥ä¸‹ä»£ç ï¼Œè§‚å¯Ÿå†…å­˜åœ°å€å˜åŒ–ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650540b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. åŸºç¡€å¼•ç”¨ (Python é»˜è®¤è¡Œä¸º)\n",
    "x = torch.tensor([1.0, 2.0, 3.0,], requires_grad = True)\n",
    "y = x\n",
    "\n",
    "print(f\"x çš„å†…å­˜åœ°å€: {id(x)}\")\n",
    "print(f\"y çš„å†…å­˜åœ°å€: {id(y)}\")\n",
    "print(f\"x å’Œ y æ˜¯åŒä¸€ä¸ªå¯¹è±¡å—? {x is y}\") # True\n",
    "\n",
    "# ä¿®æ”¹ y ä¼šå½±å“ x\n",
    "with torch.no_grad():\n",
    "    y[0] = 100\n",
    "print(f\"ä¿®æ”¹ y å x çš„å€¼: {x}\") # x ä¹Ÿå˜äº†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee49fad",
   "metadata": {},
   "source": [
    "### 2.2 Clone vs Detach (é¢è¯•å¿…é—®)\n",
    "\n",
    "è¿™æ˜¯ä»Šå¤©æœ€é‡è¦çš„ PyTorch çŸ¥è¯†ç‚¹ã€‚\n",
    "\n",
    "  * **`clone()`**: å¤åˆ¶æ•°æ®ï¼Œ**ä¿ç•™**æ¢¯åº¦é“¾ã€‚ç”¨äºâ€œæˆ‘è¦å¤åˆ¶ä¸€ä»½æ•°æ®å‚ä¸è®¡ç®—ï¼Œä¸”å¸Œæœ›åå‘ä¼ æ’­èƒ½ä¼ å›æ¥â€ã€‚\n",
    "  * **`detach()`**: å…±äº«/å¤åˆ¶æ•°æ®ï¼ˆè§†æƒ…å†µè€Œå®šï¼‰ï¼Œ**åˆ‡æ–­**æ¢¯åº¦é“¾ã€‚ç”¨äºâ€œæˆ‘è¦æŠŠ tensor æ‹¿å‡ºæ¥ç”»å›¾ã€ä¿å­˜æˆ–åšæ¨ç†ï¼Œä¸æƒ³å½±å“åŸæ¥çš„è®¡ç®—å›¾â€ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be6d397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a çš„æ¢¯åº¦ (expect 6.0): tensor([6., 6., 6.])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m e \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     20\u001b[0m f \u001b[38;5;241m=\u001b[39m e \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# è¿™é‡Œåªä¼šç®—åˆ° f å’Œ eï¼Œå†å¾€åå°±æ–­äº†\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetach å a çš„æ¢¯åº¦ (expect 0): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# æŠ¥é”™æé†’ï¼šå¦‚æœå¼ºè¡Œå¯¹ e æ±‚å¯¼ä¹Ÿæ²¡ç”¨ï¼Œå› ä¸º e å·²ç»æ˜¯ leaf node ä¸” requires_grad=False\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/utils/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/utils/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/utils/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# åˆå§‹åŒ–\n",
    "a = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "b = a * 2 \n",
    "\n",
    "# --- å®éªŒ 1: .clone() ---\n",
    "# c æ˜¯ b çš„å…‹éš†ã€‚c å‚ä¸è®¡ç®—ï¼Œæ¢¯åº¦ä¼šä¼ å› bï¼Œä¹Ÿä¼šä¼ å› a\n",
    "c = b.clone()\n",
    "d = c * 3\n",
    "d.sum().backward()\n",
    "\n",
    "print(f\"a çš„æ¢¯åº¦ (expect 6.0): {a.grad}\") \n",
    "# æ¨å¯¼: d = c*3 = b*3 = (a*2)*3 = 6a -> d/da = 6\n",
    "\n",
    "# --- æ¸…ç©ºæ¢¯åº¦ ---\n",
    "a.grad.zero_()\n",
    "\n",
    "# --- å®éªŒ 2: .detach() (ä¿®æ­£ç‰ˆ) ---\n",
    "\n",
    "# e ä» b åˆ†ç¦»å‡ºæ¥ã€‚\n",
    "# æ­¤æ—¶ e æ˜¯ä¸€ä¸ªæ–°çš„ Leaf Nodeï¼ˆå¶å­èŠ‚ç‚¹ï¼‰ï¼Œå®ƒå’Œ b å…±äº«æ•°å€¼ï¼Œä½†æ²¡æœ‰æ¢¯åº¦è¿æ¥ã€‚\n",
    "e = b.detach()\n",
    "\n",
    "# ã€å…³é”®ä¿®æ­£ã€‘ï¼šä¸ºäº†èƒ½å¯¹ f è°ƒç”¨ backwardï¼Œæˆ‘ä»¬å¿…é¡»è®© e å¼€å§‹è¿½è¸ªæ¢¯åº¦ã€‚\n",
    "# è¿™æ¨¡æ‹Ÿäº† e ä½œä¸º\"æ–°ç½‘ç»œçš„è¾“å…¥\"çš„åœºæ™¯ã€‚\n",
    "e.requires_grad_(True)\n",
    "\n",
    "f = e * 3\n",
    "f.sum().backward() \n",
    "\n",
    "# éªŒè¯ç»“æœ\n",
    "print(f\"e çš„æ¢¯åº¦ (expect 3.0): {e.grad}\") # e è‡ªå·±æ˜¯ä¸€ä¸ªæ–°çš„æºå¤´ï¼Œå®ƒèƒ½æ”¶åˆ°æ¢¯åº¦\n",
    "print(f\"Detach å a çš„æ¢¯åº¦ (expect 0.0): {a.grad}\") # ä½†æ˜¯ï¼æ¢¯åº¦ä¼ ä¸åˆ° a é‚£é‡Œå»\n",
    "\n",
    "# ç»“è®ºï¼šdetach() å°±åƒä¸€æŠŠå‰ªåˆ€ï¼Œå‰ªæ–­äº† b å’Œ e ä¹‹é—´çš„åå‘ä¼ æ’­è·¯å¾„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50169ace",
   "metadata": {},
   "source": [
    "> **ğŸ› ï¸ å·¥ç¨‹åœºæ™¯**:\n",
    ">\n",
    ">   * **Transfer Learning (è¿ç§»å­¦ä¹ )**: å†»ç»“éª¨å¹²ç½‘ç»œæ—¶ï¼Œä¼šç”¨åˆ° `detach()` æˆ–è€…è®¾ç½® `requires_grad=False`ã€‚\n",
    ">   * **Reinforcement Learning (å¼ºåŒ–å­¦ä¹ )**: Target Network æ›´æ–°é€šå¸¸éœ€è¦ `detach()`ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9883e1",
   "metadata": {},
   "source": [
    "## 3 LeetCode ç®—æ³•çªå‡» (The \"Interview\" Skills)\n",
    "\n",
    "é“¾è¡¨é¢˜ä¸è€ƒå¤æ‚çš„é€»è¾‘ï¼Œåªè€ƒä½ \\*\\*â€œå¿ƒç»†â€\\*\\*ã€‚æ‰€æœ‰çš„å‘éƒ½åœ¨äºï¼šæŒ‡é’ˆæŒ‡æ­ªäº†ã€æ–­äº†ã€æˆ–è€…æ­»å¾ªç¯äº†ã€‚\n",
    "\n",
    "ä¸ºäº†åœ¨ Python ä¸­ç»ƒä¹ é“¾è¡¨ï¼Œæˆ‘ä»¬éœ€è¦å…ˆå®šä¹‰ä¸€ä¸ªç®€å•çš„èŠ‚ç‚¹ç±»ï¼ˆLeetCode ä¹Ÿæ˜¯è¿™æ ·å®šä¹‰çš„ï¼‰ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5efa488",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListNode:\n",
    "    def __init__(self, val=0, next=None):\n",
    "        self.val = val\n",
    "        self.next = next\n",
    "\n",
    "# è¾…åŠ©å‡½æ•°ï¼šå°†åˆ—è¡¨è½¬ä¸ºé“¾è¡¨ (æ–¹ä¾¿æµ‹è¯•)\n",
    "def create_linked_list(arr):\n",
    "    if not arr: return None\n",
    "    head = ListNode(arr[0])\n",
    "    curr = head\n",
    "    for val in arr[1:]:\n",
    "        curr.next = ListNode(val)\n",
    "        curr = curr.next\n",
    "    return head\n",
    "\n",
    "# è¾…åŠ©å‡½æ•°ï¼šæ‰“å°é“¾è¡¨\n",
    "def print_linked_list(head):\n",
    "    vals = []\n",
    "    curr = head\n",
    "    while curr:\n",
    "        vals.append(str(curr.val))\n",
    "        curr = curr.next\n",
    "    print(\" -> \".join(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310f3712",
   "metadata": {},
   "source": [
    "### 3.1: åè½¬é“¾è¡¨ (Reverse Linked List) - Easy\n",
    "\n",
    "  * **LeetCode é“¾æ¥**: [206. Reverse Linked List](../../LeetCode%20practice/201-250.ipynb)\n",
    "  * **AI å…³è”**: ç±»ä¼¼äºæ—¶é—´åºåˆ—çš„åå‘ä¼ æ’­ï¼ˆBPTTï¼‰ï¼Œæˆ‘ä»¬éœ€è¦ä»åå¾€å‰æ¨å¯¼ã€‚\n",
    "  * **æ ¸å¿ƒæ€è·¯**: **åŒæŒ‡é’ˆ/ä¸‰æŒ‡é’ˆ**ã€‚éœ€è¦ `prev` (å‰ä¸€ä¸ª), `curr` (å½“å‰), `next_temp` (å…ˆå­˜ä¸‹ä¸ªèŠ‚ç‚¹ï¼Œä¸ç„¶ä¸€æ–­é“¾å°±æ‰¾ä¸åˆ°äº†)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49471b74",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_linked_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prev \u001b[38;5;66;03m# prev å˜æˆäº†æ–°çš„å¤´èŠ‚ç‚¹\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# æµ‹è¯•\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_linked_list\u001b[49m([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m])\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124måŸå§‹é“¾è¡¨:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m print_linked_list(head)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_linked_list' is not defined"
     ]
    }
   ],
   "source": [
    "def reverseList(head):\n",
    "    prev = None\n",
    "    curr = head\n",
    "    \n",
    "    while curr:\n",
    "        # 1. æš‚å­˜ä¸‹ä¸€æ­¥è¦å»çš„åœ°æ–¹ (å…³é”®ï¼å¦åˆ™é“¾æ¡æ–­äº†å°±å›ä¸æ¥äº†)\n",
    "        next_temp = curr.next \n",
    "        \n",
    "        # 2. è°ƒè½¬ç®­å¤´æ–¹å‘\n",
    "        curr.next = prev\n",
    "        \n",
    "        # 3. æ•´ä½“å‘åç§»åŠ¨ä¸€æ­¥\n",
    "        prev = curr\n",
    "        curr = next_temp\n",
    "        \n",
    "    return prev # prev å˜æˆäº†æ–°çš„å¤´èŠ‚ç‚¹\n",
    "\n",
    "# æµ‹è¯•\n",
    "head = create_linked_list([1, 2, 3, 4, 5])\n",
    "print(\"åŸå§‹é“¾è¡¨:\")\n",
    "print_linked_list(head)\n",
    "\n",
    "new_head = reverseList(head)\n",
    "print(\"åè½¬å:\")\n",
    "print_linked_list(new_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254a685a",
   "metadata": {},
   "source": [
    "### 3.2: ç¯å½¢é“¾è¡¨ (Linked List Cycle) - Easy\n",
    "\n",
    "  * **LeetCode é“¾æ¥**: [141. Linked List Cycle](../../LeetCode%20practice/101-150.ipynb)\n",
    "  * **AI å…³è”**: **æ­»å¾ªç¯æ£€æµ‹**ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­çš„ Loss ä¸ä¸‹é™æˆ–è€…éœ‡è¡ï¼Œå°±åƒæ˜¯é™·å…¥äº†ä¸€ä¸ªâ€œç¯â€ã€‚\n",
    "  * **æ ¸å¿ƒæ€è·¯**: **å¿«æ…¢æŒ‡é’ˆ (Fast & Slow Pointers)**ã€‚\n",
    "      * `Slow` è·‘ä¸€æ­¥ï¼Œ`Fast` è·‘ä¸¤æ­¥ã€‚\n",
    "      * å¦‚æœæ²¡ç¯ï¼ŒFast ä¼šå…ˆè·‘åˆ°ç»ˆç‚¹ï¼ˆNoneï¼‰ã€‚\n",
    "      * å¦‚æœæœ‰ç¯ï¼ŒFast æœ€ç»ˆä¼šä»åé¢â€œå¥—åœˆâ€è¿½ä¸Š Slowã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732c6e69",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```python\n",
    "def hasCycle(head):\n",
    "    if not head or not head.next:\n",
    "        return False\n",
    "    \n",
    "    slow = head\n",
    "    fast = head.next\n",
    "    \n",
    "    while slow != fast:\n",
    "        # å¦‚æœ fast è·‘åˆ°å¤´äº†ï¼Œè¯´æ˜æ²¡ç¯\n",
    "        if not fast or not fast.next:\n",
    "            return False\n",
    "        \n",
    "        slow = slow.next      # æ…¢è·‘ 1 æ­¥\n",
    "        fast = fast.next.next # å¿«è·‘ 2 æ­¥\n",
    "        \n",
    "    return True # ç›¸é‡äº†ï¼Œè¯´æ˜æœ‰ç¯\n",
    "\n",
    "# --- æ„é€ ä¸€ä¸ªå¸¦ç¯çš„é“¾è¡¨æµ‹è¯• ---\n",
    "# 1 -> 2 -> 3 -> 4\n",
    "#           ^    |\n",
    "#           |____|\n",
    "node1 = ListNode(1)\n",
    "node2 = ListNode(2)\n",
    "node3 = ListNode(3)\n",
    "node4 = ListNode(4)\n",
    "\n",
    "node1.next = node2\n",
    "node2.next = node3\n",
    "node3.next = node4\n",
    "node4.next = node2 # 4 æŒ‡å› 2ï¼Œå½¢æˆç¯\n",
    "\n",
    "print(f\"\\né“¾è¡¨æ˜¯å¦æœ‰ç¯? {hasCycle(node1)}\")\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "## 4\\. æ€»ç»“ä¸ä½œä¸š\n",
    "\n",
    "### ä»Šæ—¥å¤ç›˜\n",
    "\n",
    "1.  **PyTorch å†…å­˜**:\n",
    "      * `clone()` = å½±åˆ†èº«ï¼ˆå¸¦è¿æ¥ï¼Œèƒ½ä¼ æ¢¯åº¦ï¼‰ã€‚\n",
    "      * `detach()` = æ–­ç»å…³ç³»ï¼ˆä¸å¸¦è¿æ¥ï¼Œä¸ä¼ æ¢¯åº¦ï¼‰ã€‚\n",
    "2.  **ç®—æ³•æŠ€å·§**:\n",
    "      * é“¾è¡¨æ“ä½œæ ¸å¿ƒæ˜¯ **\"å…ˆå­˜åæ”¹\"**ï¼ˆåœ¨æ”¹å˜ `curr.next` ä¹‹å‰ï¼ŒåŠ¡å¿…å…ˆå­˜ä¸‹ `next_temp`ï¼‰ã€‚\n",
    "      * å¿«æ…¢æŒ‡é’ˆæ˜¯è§£å†³å¾ªç¯é—®é¢˜çš„ç¥å™¨ã€‚\n",
    "\n",
    "### è¯¾åä½œä¸š\n",
    "\n",
    "1.  åœ¨ Notebook ä¸­è¿è¡Œä»¥ä¸Šä»£ç ï¼Œé‡ç‚¹ç”»å›¾ç†è§£ `reverseList` çš„è¿‡ç¨‹ï¼ˆå¯ä»¥ç”¨çº¸ç¬”ç”»ç®­å¤´è¾…åŠ©ï¼‰ã€‚\n",
    "\n",
    "2.  **æ€è€ƒé¢˜**: ä¸ºä»€ä¹ˆæˆ‘ä»¬åœ¨ `src/engine.py` çš„è®­ç»ƒå¾ªç¯é‡Œï¼Œè®¡ç®—å‡†ç¡®ç‡æ—¶é€šå¸¸è¦å†™ï¼š\n",
    "    `preds = torch.argmax(logits, dim=1).cpu().numpy()`\n",
    "    è¿™é‡Œå¦‚æœä¸åŠ  `.detach()` (é€šå¸¸è½¬ numpy ä¼šè‡ªåŠ¨ detachï¼Œä½†å¦‚æœæ˜¯æ˜¾å¼æ“ä½œå‘¢)ï¼Œä¼šæœ‰ä»€ä¹ˆé£é™©ï¼Ÿ\n",
    "\n",
    "    *(ç­”æ¡ˆæç¤ºï¼šå¦‚æœæŠŠå¸¦æ¢¯åº¦çš„ Tensor å­˜åˆ°åˆ—è¡¨é‡Œä¸€ç›´ä¸é‡Šæ”¾ï¼Œä¼šå¯¼è‡´è®¡ç®—å›¾è¶Šæ¥è¶Šå¤§ï¼Œæœ€åæ’‘çˆ†å†…å­˜ã€‚)*\n",
    "\n",
    "-----\n",
    "\n",
    "**Next Step**:\n",
    "å½“ä½ å®Œæˆ Day 2 åï¼Œæˆ‘ä»¬å°†åœ¨ Day 3 æ”»å…‹ **å“ˆå¸Œè¡¨ (Hash Table)**ï¼Œè¿™æ˜¯æ•°æ®å¤„ç†å’ŒæŸ¥æ‰¾æ•ˆç‡çš„æ ¸å¿ƒã€‚å‡†å¤‡å¥½ç»§ç»­äº†å—ï¼Ÿ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
