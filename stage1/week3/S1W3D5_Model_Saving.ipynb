{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5021f5b4",
   "metadata": {},
   "source": [
    "# 🚀 S1W3D5 (Day 19)：模型保存与调优 (Integration & Tuning)\n",
    "\n",
    "**今日任务**\n",
    "\n",
    "1.  **逻辑实现**：编写“保存最佳模型 (Save Best Model)”的逻辑。\n",
    "2.  **完整训练**：运行一次完整的 5-10 Epoch 训练，产出 `best_model.pth`。\n",
    "3.  **理论深究**：Batch Size 到底怎么影响模型？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82c11b7",
   "metadata": {},
   "source": [
    "## 🛠️ 为什么不仅是 `torch.save`？\n",
    "\n",
    "在 W2 我们学过 `torch.save(model.state_dict(), 'model.pth')`。但在实际项目中，我们不能训练完最后一步再保存。\n",
    "\n",
    "**面试点：Early Stopping & Model Checkpointing**\n",
    "\n",
    "  * **现象**：模型可能在第 3 个 Epoch 准确率最高 (98%)，到了第 10 个 Epoch 反而过拟合了 (Accuracy 降到 97%)。\n",
    "  * **策略**：我们需要在这个 Loop 中加一个\\*\\*“裁判”\\*\\*：\n",
    "      * 记录当前的 `best_accuracy`。\n",
    "      * 每轮评估完，比较 `current_acc` 和 `best_accuracy`。\n",
    "      * 如果**破纪录了**，立刻保存当前模型，并更新 `best_accuracy`。\n",
    "      * 如果没破纪录，什么都不做。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe21cb8",
   "metadata": {},
   "source": [
    "## 💻 编写完整训练脚本 (Notebook)\n",
    "\n",
    "请在你的新 Notebook 中运行以下代码。这段代码集成了我们之前封装的 `src`，并加入了**保存最佳模型**的核心逻辑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6aab3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔴 [Test set] Average loss: 0.0400, Accuracy: 9860/10000 (98.60%)\n",
      "\n",
      "💾 Model Saved! (Accuracy improved: 98.60%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔴 [Test set] Average loss: 0.0293, Accuracy: 9901/10000 (99.01%)\n",
      "\n",
      "💾 Model Saved! (Accuracy improved: 99.01%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔴 [Test set] Average loss: 0.0254, Accuracy: 9913/10000 (99.13%)\n",
      "\n",
      "💾 Model Saved! (Accuracy improved: 99.13%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔴 [Test set] Average loss: 0.0317, Accuracy: 9906/10000 (99.06%)\n",
      "\n",
      "⏳ No improvement (Best: 99.13%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔴 [Test set] Average loss: 0.0423, Accuracy: 9883/10000 (98.83%)\n",
      "\n",
      "⏳ No improvement (Best: 99.13%)\n",
      "\n",
      "🏆 最终最佳准确率: 99.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# 1. 挂载项目根目录\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\")) \n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "experiment_dir = os.path.join(project_root, 'experiments')\n",
    "os.makedirs(experiment_dir, exist_ok=True)\n",
    "\n",
    "# 2. 导入模块\n",
    "from src.utils import get_logger, get_data_loaders\n",
    "from src.models import SimpleCNN\n",
    "from src.engine import train, evaluate\n",
    "\n",
    "# 3. 准备工作\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 这里我们可以尝试调节 batch_size 看看效果\n",
    "train_loader, test_loader = get_data_loaders(batch_size=16, data_root=os.path.join(project_root, 'data'))\n",
    "\n",
    "# 4. 初始化 Logger (还是用它写文件，不用纠结屏幕显示了)\n",
    "log_path = os.path.join(experiment_dir, 'final_training.log')\n",
    "logger = get_logger(log_path)\n",
    "# logger = get_logger('../../experiments/final_training.log')\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# --- 5. 核心逻辑：保存最佳模型 ---\n",
    "EPOCHS = 5  # 我们跑 5 轮试试\n",
    "best_acc = 0.0 # 初始化最高分\n",
    "save_path = os.path.join(experiment_dir, 'best_model.pth')\n",
    "\n",
    "logger.info(f\"🚀 Start Final Training... Device: {device}, Batch Size: {train_loader.batch_size}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # A. 训练\n",
    "    train(model, device, train_loader, optimizer, epoch, log_interval=100, logger=logger)\n",
    "    \n",
    "    # B. 评估 (获取当前准确率)\n",
    "    test_acc = evaluate(model, device, test_loader, logger=logger)\n",
    "    \n",
    "    # C. 裁判逻辑 (Save Best)\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        \n",
    "        # 打印高光时刻\n",
    "        msg = f\"💾 Model Saved! (Accuracy improved: {best_acc:.2f}%)\"\n",
    "        print(msg) \n",
    "        logger.info(msg)\n",
    "    else:\n",
    "        print(f\"⏳ No improvement (Best: {best_acc:.2f}%)\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "logger.info(f\"✨ Training Finished in {total_time:.2f}s. Best Accuracy: {best_acc:.2f}%\")\n",
    "print(f\"\\n🏆 最终最佳准确率: {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ef7809",
   "metadata": {},
   "source": [
    "## 🧠 3. 理论补课：Batch Size 的玄学 (面试必问)\n",
    "\n",
    "在等待模型训练的时候（5个 Epoch 应该很快），请认真阅读并思考这个问题。这是深度学习面试中**最经典**的超参数问题。\n",
    "\n",
    "**Q: Batch Size (BS) 设得大一点好，还是小一点好？**\n",
    "\n",
    "#### 🔴 大 Batch Size (例如 1024, 2048)\n",
    "\n",
    "  * **优点**：\n",
    "      * **快**：GPU 并行效率极高，训练一个 Epoch 时间短。\n",
    "      * **稳**：梯度计算非常准确（取了 1000 张图的平均），Loss 曲线平滑，不震荡。\n",
    "  * **缺点 (致命)**：\n",
    "      * **泛化能力差 (Generalization Gap)**：这是 Yann LeCun 等大佬反复强调的。因为梯度太稳了，模型容易直接滑落到最近的一个\\*\\*“尖锐的极小值” (Sharp Minima)\\*\\* 坑里出不来。这种坑在训练集上 Loss 很低，但测试集稍微变一点数据，Loss 就飙升。\n",
    "      * **内存溢出**：显存容易炸。\n",
    "\n",
    "#### 🔵 小 Batch Size (例如 32, 64)\n",
    "\n",
    "  * **优点**：\n",
    "      * **泛化能力强**：这是反直觉的。因为样本少，每次计算的梯度都有点“不准”（自带噪声）。这种**噪声**其实是好事！它就像模型在下山时喝醉了，走路摇摇晃晃，反而更容易**跳出**那些尖锐的小坑，最终找到一个\\*\\*“平坦的极小值” (Flat Minima)\\*\\*。平坦的坑，泛化性最好。\n",
    "  * **缺点**：\n",
    "      * **慢**：GPU 等待时间多，训练时间长。\n",
    "      * **震荡**：Loss 曲线像心电图一样跳动，很难收敛到极致的 0。\n",
    "\n",
    "#### ⚖️ 黄金法则 (Rule of Thumb)\n",
    "\n",
    "1.  **默认起手式**：`32` 或 `64`。这是最安全的范围。\n",
    "2.  **线性缩放法则 (Linear Scaling Rule)**：如果你非要增加 Batch Size 来加速（比如加到 256），你通常需要**同比例增加学习率 (Learning Rate)**。\n",
    "      * $BatchSize \\times k \\rightarrow LearningRate \\times k$。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef0f65e",
   "metadata": {},
   "source": [
    "## 🔬 每日实验 (你的任务)\n",
    "\n",
    "1.  **运行代码**：确保上面的脚本跑通，并看到 `💾 Model Saved!` 的提示。\n",
    "2.  **检查产出**：\n",
    "      * 看看你的目录下是不是多了一个 `best_model.pth` 文件？\n",
    "      * 文件大小是多少？（应该在几百 KB 到 1 MB 之间，很小）。\n",
    "3.  **简单调参 (选做)**：\n",
    "      * 将 `batch_size` 改为 **16**，再跑一次。观察：\n",
    "          * 训练时间变长了吗？\n",
    "          * Loss 下降得是更平滑了还是更抖动了？\n",
    "\n",
    "完成这步，我们的**训练阶段**就彻底毕业了！你可以自豪地把 `best_model.pth` 也就是你的“智障 AI”（现在已经不智障了）存起来了。\n",
    "\n",
    "明天 **W3D6**，我们将学习如何写一个 `predict.py` 脚本，加载这个 `.pth` 文件，去识别一张它**从未见过**的、甚至是你自己手写的数字图片！\n",
    "\n",
    "运行完告诉我结果！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
