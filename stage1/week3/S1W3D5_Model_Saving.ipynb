{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5021f5b4",
   "metadata": {},
   "source": [
    "# ğŸš€ S1W3D5 (Day 19)ï¼šæ¨¡å‹ä¿å­˜ä¸è°ƒä¼˜ (Integration & Tuning)\n",
    "\n",
    "**ä»Šæ—¥ä»»åŠ¡**\n",
    "\n",
    "1.  **é€»è¾‘å®ç°**ï¼šç¼–å†™â€œä¿å­˜æœ€ä½³æ¨¡å‹ (Save Best Model)â€çš„é€»è¾‘ã€‚\n",
    "2.  **å®Œæ•´è®­ç»ƒ**ï¼šè¿è¡Œä¸€æ¬¡å®Œæ•´çš„ 5-10 Epoch è®­ç»ƒï¼Œäº§å‡º `best_model.pth`ã€‚\n",
    "3.  **ç†è®ºæ·±ç©¶**ï¼šBatch Size åˆ°åº•æ€ä¹ˆå½±å“æ¨¡å‹ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82c11b7",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ ä¸ºä»€ä¹ˆä¸ä»…æ˜¯ `torch.save`ï¼Ÿ\n",
    "\n",
    "åœ¨ W2 æˆ‘ä»¬å­¦è¿‡ `torch.save(model.state_dict(), 'model.pth')`ã€‚ä½†åœ¨å®é™…é¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬ä¸èƒ½è®­ç»ƒå®Œæœ€åä¸€æ­¥å†ä¿å­˜ã€‚\n",
    "\n",
    "**é¢è¯•ç‚¹ï¼šEarly Stopping & Model Checkpointing**\n",
    "\n",
    "  * **ç°è±¡**ï¼šæ¨¡å‹å¯èƒ½åœ¨ç¬¬ 3 ä¸ª Epoch å‡†ç¡®ç‡æœ€é«˜ (98%)ï¼Œåˆ°äº†ç¬¬ 10 ä¸ª Epoch åè€Œè¿‡æ‹Ÿåˆäº† (Accuracy é™åˆ° 97%)ã€‚\n",
    "  * **ç­–ç•¥**ï¼šæˆ‘ä»¬éœ€è¦åœ¨è¿™ä¸ª Loop ä¸­åŠ ä¸€ä¸ª\\*\\*â€œè£åˆ¤â€\\*\\*ï¼š\n",
    "      * è®°å½•å½“å‰çš„ `best_accuracy`ã€‚\n",
    "      * æ¯è½®è¯„ä¼°å®Œï¼Œæ¯”è¾ƒ `current_acc` å’Œ `best_accuracy`ã€‚\n",
    "      * å¦‚æœ**ç ´çºªå½•äº†**ï¼Œç«‹åˆ»ä¿å­˜å½“å‰æ¨¡å‹ï¼Œå¹¶æ›´æ–° `best_accuracy`ã€‚\n",
    "      * å¦‚æœæ²¡ç ´çºªå½•ï¼Œä»€ä¹ˆéƒ½ä¸åšã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe21cb8",
   "metadata": {},
   "source": [
    "## ğŸ’» ç¼–å†™å®Œæ•´è®­ç»ƒè„šæœ¬ (Notebook)\n",
    "\n",
    "è¯·åœ¨ä½ çš„æ–° Notebook ä¸­è¿è¡Œä»¥ä¸‹ä»£ç ã€‚è¿™æ®µä»£ç é›†æˆäº†æˆ‘ä»¬ä¹‹å‰å°è£…çš„ `src`ï¼Œå¹¶åŠ å…¥äº†**ä¿å­˜æœ€ä½³æ¨¡å‹**çš„æ ¸å¿ƒé€»è¾‘ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aab3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1:   3%|â–         | 111/3750 [00:01<00:37, 98.26it/s, loss=0.2015]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [100/3750 (3%)]\tLoss: 0.431391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1:   6%|â–Œ         | 214/3750 [00:02<00:35, 98.56it/s, loss=0.0984]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [200/3750 (5%)]\tLoss: 0.179231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1:   8%|â–Š         | 310/3750 [00:03<00:34, 98.69it/s, loss=0.3818] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [300/3750 (8%)]\tLoss: 0.494378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1:  11%|â–ˆ         | 418/3750 [00:04<00:33, 100.39it/s, loss=0.0995]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [400/3750 (11%)]\tLoss: 0.039944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1:  14%|â–ˆâ–        | 511/3750 [00:05<00:32, 98.80it/s, loss=0.0432] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [500/3750 (13%)]\tLoss: 0.057517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 43\u001b[0m\n\u001b[1;32m     39\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# A. è®­ç»ƒ\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# B. è¯„ä¼° (è·å–å½“å‰å‡†ç¡®ç‡)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m evaluate(model, device, test_loader, logger\u001b[38;5;241m=\u001b[39mlogger)\n",
      "File \u001b[0;32m~/study/AI-Interview-Sprint/src/engine.py:16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, log_interval, logger)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 1. åˆ›å»ºè¿›åº¦æ¡\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# leave=False: è·‘å®Œä¸€è½®åè¿›åº¦æ¡æ¶ˆå¤±ï¼Œä¿æŒå±å¹•æ¸…çˆ½\u001b[39;00m\n\u001b[1;32m     14\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pbar):\n\u001b[1;32m     17\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/utils/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/utils/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/utils/lib/python3.10/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/utils/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/utils/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/utils/lib/python3.10/site-packages/torchvision/datasets/mnist.py:146\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/anaconda3/envs/utils/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/anaconda3/envs/utils/lib/python3.10/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/utils/lib/python3.10/site-packages/torchvision/transforms/functional.py:140\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03mThis function does not support torchscript.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_tracing():\n\u001b[0;32m--> 140\u001b[0m     \u001b[43m_log_api_usage_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (F_pil\u001b[38;5;241m.\u001b[39m_is_pil_image(pic) \u001b[38;5;129;01mor\u001b[39;00m _is_numpy(pic)):\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpic should be PIL Image or ndarray. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(pic)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/utils/lib/python3.10/site-packages/torchvision/utils.py:619\u001b[0m, in \u001b[0;36m_log_api_usage_once\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    615\u001b[0m         colors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(v \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m color) \u001b[38;5;28;01mfor\u001b[39;00m color \u001b[38;5;129;01min\u001b[39;00m colors]  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m colors  \u001b[38;5;66;03m# type: ignore[return-value]\u001b[39;00m\n\u001b[0;32m--> 619\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_log_api_usage_once\u001b[39m(obj: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03m    Logs API usage(module and name) within an organization.\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;124;03m    In a large ecosystem, it's often useful to track the PyTorch and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m        obj (class instance or method): an object to extract info from.\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    637\u001b[0m     module \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# 1. æŒ‚è½½é¡¹ç›®æ ¹ç›®å½•\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\")) \n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "experiment_dir = os.path.join(project_root, 'experiments')\n",
    "os.makedirs(experiment_dir, exist_ok=True)\n",
    "\n",
    "# 2. å¯¼å…¥æ¨¡å—\n",
    "from src.utils import get_logger, get_data_loaders\n",
    "from src.models import SimpleCNN\n",
    "from src.engine import train, evaluate\n",
    "\n",
    "# 3. å‡†å¤‡å·¥ä½œ\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# è¿™é‡Œæˆ‘ä»¬å¯ä»¥å°è¯•è°ƒèŠ‚ batch_size çœ‹çœ‹æ•ˆæœ\n",
    "train_loader, test_loader = get_data_loaders(batch_size=16, data_root=os.path.join(project_root, 'data'))\n",
    "\n",
    "# 4. åˆå§‹åŒ– Logger (è¿˜æ˜¯ç”¨å®ƒå†™æ–‡ä»¶ï¼Œä¸ç”¨çº ç»“å±å¹•æ˜¾ç¤ºäº†)\n",
    "log_path = os.path.join(experiment_dir, 'final_training.log')\n",
    "logger = get_logger(log_path)\n",
    "# logger = get_logger('../../experiments/final_training.log')\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# --- 5. æ ¸å¿ƒé€»è¾‘ï¼šä¿å­˜æœ€ä½³æ¨¡å‹ ---\n",
    "EPOCHS = 5  # æˆ‘ä»¬è·‘ 5 è½®è¯•è¯•\n",
    "best_acc = 0.0 # åˆå§‹åŒ–æœ€é«˜åˆ†\n",
    "save_path = 'best_model.pth' # æ¨¡å‹ä¿å­˜è·¯å¾„\n",
    "\n",
    "logger.info(f\"ğŸš€ Start Final Training... Device: {device}, Batch Size: {train_loader.batch_size}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # A. è®­ç»ƒ\n",
    "    train(model, device, train_loader, optimizer, epoch, log_interval=100, logger=logger)\n",
    "    \n",
    "    # B. è¯„ä¼° (è·å–å½“å‰å‡†ç¡®ç‡)\n",
    "    test_acc = evaluate(model, device, test_loader, logger=logger)\n",
    "    \n",
    "    # C. è£åˆ¤é€»è¾‘ (Save Best)\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        \n",
    "        # æ‰“å°é«˜å…‰æ—¶åˆ»\n",
    "        msg = f\"ğŸ’¾ Model Saved! (Accuracy improved: {best_acc:.2f}%)\"\n",
    "        print(msg) \n",
    "        logger.info(msg)\n",
    "    else:\n",
    "        print(f\"â³ No improvement (Best: {best_acc:.2f}%)\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "logger.info(f\"âœ¨ Training Finished in {total_time:.2f}s. Best Accuracy: {best_acc:.2f}%\")\n",
    "print(f\"\\nğŸ† æœ€ç»ˆæœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ef7809",
   "metadata": {},
   "source": [
    "## ğŸ§  3. ç†è®ºè¡¥è¯¾ï¼šBatch Size çš„ç„å­¦ (é¢è¯•å¿…é—®)\n",
    "\n",
    "åœ¨ç­‰å¾…æ¨¡å‹è®­ç»ƒçš„æ—¶å€™ï¼ˆ5ä¸ª Epoch åº”è¯¥å¾ˆå¿«ï¼‰ï¼Œè¯·è®¤çœŸé˜…è¯»å¹¶æ€è€ƒè¿™ä¸ªé—®é¢˜ã€‚è¿™æ˜¯æ·±åº¦å­¦ä¹ é¢è¯•ä¸­**æœ€ç»å…¸**çš„è¶…å‚æ•°é—®é¢˜ã€‚\n",
    "\n",
    "**Q: Batch Size (BS) è®¾å¾—å¤§ä¸€ç‚¹å¥½ï¼Œè¿˜æ˜¯å°ä¸€ç‚¹å¥½ï¼Ÿ**\n",
    "\n",
    "#### ğŸ”´ å¤§ Batch Size (ä¾‹å¦‚ 1024, 2048)\n",
    "\n",
    "  * **ä¼˜ç‚¹**ï¼š\n",
    "      * **å¿«**ï¼šGPU å¹¶è¡Œæ•ˆç‡æé«˜ï¼Œè®­ç»ƒä¸€ä¸ª Epoch æ—¶é—´çŸ­ã€‚\n",
    "      * **ç¨³**ï¼šæ¢¯åº¦è®¡ç®—éå¸¸å‡†ç¡®ï¼ˆå–äº† 1000 å¼ å›¾çš„å¹³å‡ï¼‰ï¼ŒLoss æ›²çº¿å¹³æ»‘ï¼Œä¸éœ‡è¡ã€‚\n",
    "  * **ç¼ºç‚¹ (è‡´å‘½)**ï¼š\n",
    "      * **æ³›åŒ–èƒ½åŠ›å·® (Generalization Gap)**ï¼šè¿™æ˜¯ Yann LeCun ç­‰å¤§ä½¬åå¤å¼ºè°ƒçš„ã€‚å› ä¸ºæ¢¯åº¦å¤ªç¨³äº†ï¼Œæ¨¡å‹å®¹æ˜“ç›´æ¥æ»‘è½åˆ°æœ€è¿‘çš„ä¸€ä¸ª\\*\\*â€œå°–é”çš„æå°å€¼â€ (Sharp Minima)\\*\\* å‘é‡Œå‡ºä¸æ¥ã€‚è¿™ç§å‘åœ¨è®­ç»ƒé›†ä¸Š Loss å¾ˆä½ï¼Œä½†æµ‹è¯•é›†ç¨å¾®å˜ä¸€ç‚¹æ•°æ®ï¼ŒLoss å°±é£™å‡ã€‚\n",
    "      * **å†…å­˜æº¢å‡º**ï¼šæ˜¾å­˜å®¹æ˜“ç‚¸ã€‚\n",
    "\n",
    "#### ğŸ”µ å° Batch Size (ä¾‹å¦‚ 32, 64)\n",
    "\n",
    "  * **ä¼˜ç‚¹**ï¼š\n",
    "      * **æ³›åŒ–èƒ½åŠ›å¼º**ï¼šè¿™æ˜¯åç›´è§‰çš„ã€‚å› ä¸ºæ ·æœ¬å°‘ï¼Œæ¯æ¬¡è®¡ç®—çš„æ¢¯åº¦éƒ½æœ‰ç‚¹â€œä¸å‡†â€ï¼ˆè‡ªå¸¦å™ªå£°ï¼‰ã€‚è¿™ç§**å™ªå£°**å…¶å®æ˜¯å¥½äº‹ï¼å®ƒå°±åƒæ¨¡å‹åœ¨ä¸‹å±±æ—¶å–é†‰äº†ï¼Œèµ°è·¯æ‘‡æ‘‡æ™ƒæ™ƒï¼Œåè€Œæ›´å®¹æ˜“**è·³å‡º**é‚£äº›å°–é”çš„å°å‘ï¼Œæœ€ç»ˆæ‰¾åˆ°ä¸€ä¸ª\\*\\*â€œå¹³å¦çš„æå°å€¼â€ (Flat Minima)\\*\\*ã€‚å¹³å¦çš„å‘ï¼Œæ³›åŒ–æ€§æœ€å¥½ã€‚\n",
    "  * **ç¼ºç‚¹**ï¼š\n",
    "      * **æ…¢**ï¼šGPU ç­‰å¾…æ—¶é—´å¤šï¼Œè®­ç»ƒæ—¶é—´é•¿ã€‚\n",
    "      * **éœ‡è¡**ï¼šLoss æ›²çº¿åƒå¿ƒç”µå›¾ä¸€æ ·è·³åŠ¨ï¼Œå¾ˆéš¾æ”¶æ•›åˆ°æè‡´çš„ 0ã€‚\n",
    "\n",
    "#### âš–ï¸ é»„é‡‘æ³•åˆ™ (Rule of Thumb)\n",
    "\n",
    "1.  **é»˜è®¤èµ·æ‰‹å¼**ï¼š`32` æˆ– `64`ã€‚è¿™æ˜¯æœ€å®‰å…¨çš„èŒƒå›´ã€‚\n",
    "2.  **çº¿æ€§ç¼©æ”¾æ³•åˆ™ (Linear Scaling Rule)**ï¼šå¦‚æœä½ éè¦å¢åŠ  Batch Size æ¥åŠ é€Ÿï¼ˆæ¯”å¦‚åŠ åˆ° 256ï¼‰ï¼Œä½ é€šå¸¸éœ€è¦**åŒæ¯”ä¾‹å¢åŠ å­¦ä¹ ç‡ (Learning Rate)**ã€‚\n",
    "      * $BatchSize \\times k \\rightarrow LearningRate \\times k$ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef0f65e",
   "metadata": {},
   "source": [
    "## ğŸ”¬ æ¯æ—¥å®éªŒ (ä½ çš„ä»»åŠ¡)\n",
    "\n",
    "1.  **è¿è¡Œä»£ç **ï¼šç¡®ä¿ä¸Šé¢çš„è„šæœ¬è·‘é€šï¼Œå¹¶çœ‹åˆ° `ğŸ’¾ Model Saved!` çš„æç¤ºã€‚\n",
    "2.  **æ£€æŸ¥äº§å‡º**ï¼š\n",
    "      * çœ‹çœ‹ä½ çš„ç›®å½•ä¸‹æ˜¯ä¸æ˜¯å¤šäº†ä¸€ä¸ª `best_model.pth` æ–‡ä»¶ï¼Ÿ\n",
    "      * æ–‡ä»¶å¤§å°æ˜¯å¤šå°‘ï¼Ÿï¼ˆåº”è¯¥åœ¨å‡ ç™¾ KB åˆ° 1 MB ä¹‹é—´ï¼Œå¾ˆå°ï¼‰ã€‚\n",
    "3.  **ç®€å•è°ƒå‚ (é€‰åš)**ï¼š\n",
    "      * å°† `batch_size` æ”¹ä¸º **16**ï¼Œå†è·‘ä¸€æ¬¡ã€‚è§‚å¯Ÿï¼š\n",
    "          * è®­ç»ƒæ—¶é—´å˜é•¿äº†å—ï¼Ÿ\n",
    "          * Loss ä¸‹é™å¾—æ˜¯æ›´å¹³æ»‘äº†è¿˜æ˜¯æ›´æŠ–åŠ¨äº†ï¼Ÿ\n",
    "\n",
    "å®Œæˆè¿™æ­¥ï¼Œæˆ‘ä»¬çš„**è®­ç»ƒé˜¶æ®µ**å°±å½»åº•æ¯•ä¸šäº†ï¼ä½ å¯ä»¥è‡ªè±ªåœ°æŠŠ `best_model.pth` ä¹Ÿå°±æ˜¯ä½ çš„â€œæ™ºéšœ AIâ€ï¼ˆç°åœ¨å·²ç»ä¸æ™ºéšœäº†ï¼‰å­˜èµ·æ¥äº†ã€‚\n",
    "\n",
    "æ˜å¤© **W3D6**ï¼Œæˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•å†™ä¸€ä¸ª `predict.py` è„šæœ¬ï¼ŒåŠ è½½è¿™ä¸ª `.pth` æ–‡ä»¶ï¼Œå»è¯†åˆ«ä¸€å¼ å®ƒ**ä»æœªè§è¿‡**çš„ã€ç”šè‡³æ˜¯ä½ è‡ªå·±æ‰‹å†™çš„æ•°å­—å›¾ç‰‡ï¼\n",
    "\n",
    "è¿è¡Œå®Œå‘Šè¯‰æˆ‘ç»“æœï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
