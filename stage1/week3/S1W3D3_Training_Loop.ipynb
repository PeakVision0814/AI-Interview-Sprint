{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3287298",
   "metadata": {},
   "source": [
    "# 🚀 S1W3D3 (Day 17): 编写训练循环\n",
    "\n",
    "**今日目标**\n",
    "\n",
    "1. **复习与整合**：将`SimpleCNN`和`DataLoader`引入同一个脚本。\n",
    "2. **理解核心组件**：透彻理解**Loss Function(损失函数)**和**Optimizer (优化器)**的选择理由。\n",
    "3. **掌握“五步法”**：熟练默写 PyTorch 训练循环的 5 个标准步骤。\n",
    "4. **见证收敛**：亲眼看到 Loss 从高位下降，验证模型正在“学习”。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed42ea7",
   "metadata": {},
   "source": [
    "## 核心知识点：损失函数与优化器\n",
    "\n",
    "在开始循环之前，我们需要定义两个“教练”来指导模型学习。\n",
    "\n",
    "### 损失函数 (Loss Function): `nn.CrossEntropyLoss`\n",
    "\n",
    "- 为什么选它？ 它是多分类问题（如 0-9 数字分类）的标准答案。\n",
    "- 它做了什么？ 它内部实际上组合了两个操作：LogSoftmax + NLLLoss (负对数似然损失)。\n",
    "- 关键细节 (一定要懂)：\n",
    "    - 它的输入是模型的`Logits`（即全连接层直接出来的原始数值，比如 [2.1, -0.5, ...]）。\n",
    "    - 千万不要在模型 forward 的最后手动加 Softmax 层，否则就重复计算了，会导致梯度数值不稳定。\n",
    "\n",
    "### 优化器（Optimizer）：`torch.optim.Adam`\n",
    "- 为什么选它？\n",
    "    - `SGD (随机梯度下降)`：最经典，但需要精细调节学习率 (Learning Rate)，容易陷入局部最优。\n",
    "    - `Adam`：自带“自适应学习率”，它能根据梯度的变化自动调整步长。对于初学者和大多数任务来说，它是**无脑首选**，收敛速度快且稳。\n",
    "- 参数`lr=0.001`：这是学习率。如果你发现 Loss 不下降，或者震荡很厉害，通常第一个要调的就是这个数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd43bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# --- 1. 路径处理 (确保能找到 src) ---\n",
    "# 这一步在 Notebook 中必不可少\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\")) \n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# --- 2. 导入模型 ---\n",
    "# 假设你的文件结构是 src/model.py，里面定义了 SimpleCNN 类\n",
    "from src.models.simple_cnn import SimpleCNN \n",
    "\n",
    "# --- 3. 准备设备 ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- 4. 实例化模型 (关键修改！) ---\n",
    "# 必须加括号 () 来创建对象\n",
    "model = SimpleCNN().to(device) \n",
    "\n",
    "# --- 5. 定义组件 ---\n",
    "# 定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"✅ 模型、损失函数、优化器准备就绪！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64ba64d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
