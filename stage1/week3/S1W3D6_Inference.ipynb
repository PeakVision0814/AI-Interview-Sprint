{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f73152f3",
   "metadata": {},
   "source": [
    "# üöÄ S1W3D6: Êé®ÁêÜÂÆûÊàò\n",
    "\n",
    "**‰ªäÊó•ÁõÆÊ†á**ÔºöÂ≠¶‰π†Â¶Ç‰Ωï‰ΩøÁî®Â∑≤‰øùÂ≠òÁöÑÊ®°ÂûãËøõË°åÈ¢ÑÊµã„ÄÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4d2ccd",
   "metadata": {},
   "source": [
    "## 1. ÁéØÂ¢ÉËÆæÁΩÆ‰∏éÂØºÂÖ•\n",
    "\n",
    "> Á¨¨‰∏Ä‰∏™ÂçïÂÖÉÊ†ºÔºöÊåÇËΩΩË∑ØÂæÑÔºåÂØºÂÖ•Êàë‰ª¨‰πãÂâçÂ∞ÅË£ÖÂ•ΩÁöÑ`src`Ê®°Âùó„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9111dd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ë∑ØÂæÑÊåÇËΩΩÊàêÂäüÔºö/home/goodminton/study/AI-Interview-Sprint\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# ÊåÇËΩΩÈ°πÁõÆÊ†πÁõÆÂΩï\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(),\"../..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "print(f\"Ë∑ØÂæÑÊåÇËΩΩÊàêÂäüÔºö{project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688ca88c",
   "metadata": {},
   "source": [
    "## 2. ÂÆö‰πâÂä†ËΩΩÊ®°ÂûãÂáΩÊï∞\n",
    "\n",
    "> Á¨¨‰∫å‰∏™ÂçïÂÖÉÊ†ºÔºöÁºñÂÜô‰∏Ä‰∏™ÂáΩÊï∞Ôºå‰∏ìÈó®Ë¥üË¥£Êää`.pth`Êñá‰ª∂Âä†ËΩΩËøõÂÜÖÂ≠ò„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9012466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.models import SimpleCNN\n",
    "\n",
    "def load_model(model_path, device):\n",
    "    \"\"\"\n",
    "    Âä†ËΩΩËÆ≠ÁªÉÂ•ΩÁöÑÊ®°ÂûãÊùÉÈáç\n",
    "    \"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileExistsError(f\"Êâæ‰∏çÂà∞Ê®°ÂûãÊñá‰ª∂Ôºö{model_path}\")\n",
    "    \n",
    "    print(f\"Ê≠£Âú®Âä†ËΩΩÊ®°ÂûãÔºö{model_path}\")\n",
    "\n",
    "    # 1. ÂÆû‰æãÂåñÊ®°ÂûãÔºàÂøÖÈ°ªÂíåËÆ≠ÁªÉÊó∂‰∏ÄÊ®°‰∏ÄÊ†∑Ôºâ\n",
    "    model = SimpleCNN()\n",
    "\n",
    "    # 2. Âä†ËΩΩÊùÉÈáç\n",
    "    # map_locationÁ°Æ‰øùÂú®CPU/GPU‰πãÈó¥ËøÅÁßª‰∏çÂá∫Èîô\n",
    "    checkpoint = torch.load(model_path, map_location = device, weights_only = True)\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    # 3. ÂÖ≥ÈîÆÔºöÂàáÊç¢Âà∞ËØÑ‰º∞Ê®°Âºè\n",
    "    model.eval()\n",
    "\n",
    "    # 4. Êê¨ËøêÂà∞ËÆæÂ§á\n",
    "    model.to(device)\n",
    "\n",
    "    print(f\"Ê®°ÂûãÂä†ËΩΩÊàêÂäü\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f90e056",
   "metadata": {},
   "source": [
    "## 3. ÂÆö‰πâÈ¢ÑÊµãÂáΩÊï∞ÔºàÊ†∏ÂøÉÈÄªËæëÔºâ\n",
    "\n",
    "> Á¨¨‰∏â‰∏™ÂçïÂÖÉÊ†ºÔºöÂ§ÑÁêÜÂçïÂº†ÂõæÁâáÔºåÂ¢ûÂä†Áª¥Â∫¶ÔºåËøõË°åÈ¢ÑÊµã„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c3194e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(model, image_tensor, device):\n",
    "    \"\"\"\n",
    "    ÂØπÂçïÂº†ÂõæÁâáËøõË°åÈ¢ÑÊµã\n",
    "    :param image_tensor: [1, 28, 28]\n",
    "    \"\"\"\n",
    "    # 1. Â¢ûÂä† Batch Áª¥Â∫¶: [1, 28, 28] -> [1, 1, 28, 28]\n",
    "    input_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "    \n",
    "    # 2. ÈòªÊñ≠Ê¢ØÂ∫¶\n",
    "    with torch.no_grad():\n",
    "        # 3. Êé®ÁêÜ\n",
    "        output = model(input_tensor) # Logits\n",
    "        \n",
    "        # 4. Ëé∑ÂèñÁªìÊûú\n",
    "        # output ÊòØ [1, 10]ÔºåÊàë‰ª¨ÊâæÊúÄÂ§ßÂÄºÁöÑÁ¥¢Âºï\n",
    "        pred_index = output.argmax(dim=1).item()\n",
    "        \n",
    "        # 5. (ÂèØÈÄâ) ËÆ°ÁÆóÁΩÆ‰ø°Â∫¶\n",
    "        probs = torch.nn.functional.softmax(output, dim=1)\n",
    "        confidence = probs[0][pred_index].item() * 100\n",
    "        \n",
    "    return pred_index, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca67ad64",
   "metadata": {},
   "source": [
    "## 4. ÊâßË°åÈ¢ÑÊµãÂπ∂ÂèØËßÜÂåñ\n",
    "\n",
    "> Á¨¨Âõõ‰∏™ÂçïÂÖÉÊ†ºÔºöËøõË°åÂèØËßÜÂåñÈ¢ÑÊµã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2879fcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ê≠£Âú®Âä†ËΩΩÊ®°ÂûãÔºö/home/goodminton/study/AI-Interview-Sprint/experiments/best_model.pth\n",
      "Ê®°ÂûãÂä†ËΩΩÊàêÂäü\n",
      "\n",
      "üîç Ê≠£Âú®È¢ÑÊµãÁ¨¨ 1528 Âº†ÂõæÁâá...\n",
      "ü§ñ È¢ÑÊµãÁªìÊûú: 1 (ÁΩÆ‰ø°Â∫¶: 100.00%)\n",
      "üè∑Ô∏è ÁúüÂÆûÊ†áÁ≠æ: 1\n",
      "‚úÖ Ê≠£Á°Æ\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils import get_data_loaders\n",
    "\n",
    "# --- ÈÖçÁΩÆ ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = os.path.join(project_root, 'experiments', 'best_model.pth')\n",
    "\n",
    "# 1. Âä†ËΩΩÊ®°Âûã\n",
    "model = load_model(model_path, device)\n",
    "\n",
    "# 2. Ëé∑ÂèñÊµãËØïÊï∞ÊçÆÔºàÂè™Áî®Êù•ÂèñÂõæÔºâ\n",
    "_, test_loader = get_data_loaders(batch_size=1, data_root=os.path.join(project_root, 'data'))\n",
    "dataset = test_loader.dataset\n",
    "\n",
    "# 3. ÈöèÊú∫ÊäΩ‰∏ÄÂº†ÂõæÁâá\n",
    "random_index = random.randint(0, len(dataset)-1)\n",
    "image_tensor, true_label = dataset[random_index]\n",
    "\n",
    "print(f\"\\nüîç Ê≠£Âú®È¢ÑÊµãÁ¨¨ {random_index} Âº†ÂõæÁâá...\")\n",
    "\n",
    "# 4. È¢ÑÊµã\n",
    "pred_label, conf = predict_single_image(model, image_tensor, device)\n",
    "\n",
    "# 5. ÁªìÊûúÊòæÁ§∫\n",
    "print(f\"ü§ñ È¢ÑÊµãÁªìÊûú: {pred_label} (ÁΩÆ‰ø°Â∫¶: {conf:.2f}%)\")\n",
    "print(f\"üè∑Ô∏è ÁúüÂÆûÊ†áÁ≠æ: {true_label}\")\n",
    "\n",
    "if pred_label == true_label:\n",
    "    print(\"‚úÖ Ê≠£Á°Æ\")\n",
    "else:\n",
    "    print(\"‚ùå ÈîôËØØ (ÊâæÂà∞‰∏Ä‰∏™ÈîôÈ¢òÔºÅ)\")\n",
    "\n",
    "# 6. ÁîªÂõæ\n",
    "# ÂèçÂΩí‰∏ÄÂåñÔºö‰∏∫‰∫ÜËÆ©‰∫∫ÁúºÁúãÁùÄËàíÊúçÔºåÊää -1~1 ÂèòÂõû 0~1\n",
    "img_vis = image_tensor.squeeze().numpy() * 0.3081 + 0.1307\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(img_vis, cmap='gray')\n",
    "plt.title(f\"True: {true_label} | Pred: {pred_label}\", color=('green' if pred_label==true_label else 'red'))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
