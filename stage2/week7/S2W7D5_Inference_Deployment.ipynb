{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa8ed63d",
   "metadata": {},
   "source": [
    "# S2W7D5: æ¨¡å‹è½åœ°ä¸æ¨ç† (Inference & Deployment)\n",
    "\n",
    "ä»Šå¤©æ˜¯ä¸€ä¸ªé‡Œç¨‹ç¢‘ã€‚æˆ‘ä»¬è¦å½»åº•æŠ›å¼ƒæ²‰é‡çš„ `Trainer`ï¼Œåƒä¸€ä¸ªçœŸæ­£çš„**éƒ¨ç½²å·¥ç¨‹å¸ˆ**ä¸€æ ·ï¼Œå†™å‡ºä¸€ä¸ªè½»é‡çº§ã€é«˜æ€§èƒ½çš„æ¨ç†å¼•æ“ã€‚\n",
    "\n",
    "è¿™ä¸ä»…ä»…æ˜¯ä»£ç ï¼Œæ›´æ˜¯**å…·èº«æ™ºèƒ½ç³»ç»Ÿçš„â€œæ„Ÿå®˜æ¥å£â€**ã€‚ä½ çš„æœºå™¨äººæœ¬ä½“ï¼ˆæ¯”å¦‚åŸºäº ROS çš„ç³»ç»Ÿï¼‰å°†é€šè¿‡è¿™ä¸ªæ¥å£è°ƒç”¨ä½ çš„æ¨¡å‹ï¼ŒæŠŠå¬åˆ°çš„æŒ‡ä»¤è½¬åŒ–ä¸ºè¡ŒåŠ¨ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca2507f",
   "metadata": {},
   "source": [
    "## 1 ğŸ—ï¸ æ ¸å¿ƒæ¶æ„ï¼šè§£è€¦æ¨ç†å¼•æ“\n",
    "\n",
    "åœ¨è®­ç»ƒæ—¶ï¼Œæˆ‘ä»¬éœ€è¦ `Trainer` å¸®æˆ‘ä»¬ç®—æ¢¯åº¦ã€å­˜ Checkpointã€‚\n",
    "ä½†åœ¨æ¨ç†ï¼ˆInferenceï¼‰æ—¶ï¼Œæˆ‘ä»¬åªéœ€è¦ï¼š**Tokenizer + Modelæƒé‡ + å‰å‘ä¼ æ’­**ã€‚\n",
    "\n",
    "æˆ‘ä»¬è¦ç¼–å†™ä¸€ä¸ªç‹¬ç«‹çš„ `IntentPredictor` ç±»ï¼Œå°è£…æ‰€æœ‰ç»†èŠ‚ã€‚\n",
    "\n",
    "è¯·åœ¨ `src/` ç›®å½•ä¸‹æ–°å»ºæ–‡ä»¶ **`inference.py`**ã€‚\n",
    "\n",
    "**æ–‡ä»¶è·¯å¾„**: `project_root/src/inference.py`\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer\n",
    "from safetensors.torch import load_file\n",
    "from src.models.model_bert import BertClassifier\n",
    "from src.config import PRETRAINED_MODEL_DIR\n",
    "\n",
    "class IntentPredictor:\n",
    "    def __init__(self, checkpoint_path, num_labels=3):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–æ¨ç†å¼•æ“\n",
    "        :param checkpoint_path: è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡è·¯å¾„ (åŒ…å« model.safetensors)\n",
    "        :param num_labels: ç±»åˆ«æ•°é‡\n",
    "        \"\"\"\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.label_map = {0: \"MOVE\", 1: \"STOP\", 2: \"GRAB\"} # è¿™é‡Œçš„æ˜ å°„è¦å’Œè®­ç»ƒæ—¶ä¸€è‡´\n",
    "        \n",
    "        print(f\"æ­£åœ¨åŠ è½½æ¨ç†èµ„æº... (Device: {self.device})\")\n",
    "        \n",
    "        # 1. åŠ è½½åˆ†è¯å™¨ (ä»åŸå§‹é¢„è®­ç»ƒç›®å½•åŠ è½½ vocab)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_DIR)\n",
    "        \n",
    "        # 2. åˆå§‹åŒ–æ¨¡å‹æ¶æ„\n",
    "        self.model = BertClassifier(model_path=PRETRAINED_MODEL_DIR, num_labels=num_labels)\n",
    "        \n",
    "        # 3. åŠ è½½è®­ç»ƒå¥½çš„æƒé‡ (.safetensors)\n",
    "        # è¿™é‡Œçš„ checkpoint_path åº”è¯¥æ˜¯ç±»ä¼¼ output/results_weighted/checkpoint-500\n",
    "        weight_path = f\"{checkpoint_path}/model.safetensors\"\n",
    "        try:\n",
    "            state_dict = load_file(weight_path)\n",
    "            self.model.load_state_dict(state_dict)\n",
    "            print(\"âœ… æƒé‡åŠ è½½æˆåŠŸï¼\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ æƒé‡åŠ è½½å¤±è´¥: {e}\")\n",
    "            raise e\n",
    "            \n",
    "        # 4. å…³é”®ï¼šåˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼ & ç§»åŠ¨åˆ° GPU\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval() \n",
    "\n",
    "    def predict(self, text):\n",
    "        \"\"\"\n",
    "        å•æ¡æ–‡æœ¬é¢„æµ‹\n",
    "        :param text: ç”¨æˆ·æŒ‡ä»¤å­—ç¬¦ä¸² \"æŠŠæ¯å­æ‹¿èµ·æ¥\"\n",
    "        :return: å­—å…¸ {intent, confidence, latency}\n",
    "        \"\"\"\n",
    "        # 1. é¢„å¤„ç† (Tokenize)\n",
    "        inputs = self.tokenizer(\n",
    "            text, \n",
    "            return_tensors=\"pt\", \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            max_length=128\n",
    "        )\n",
    "        \n",
    "        # 2. æ¬è¿æ•°æ®åˆ° Device\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        \n",
    "        # 3. æ¨ç† (Inference)\n",
    "        with torch.no_grad(): # â˜… å¿…é¡»å…³æ‰æ¢¯åº¦ï¼ŒèŠ‚çœæ˜¾å­˜å¹¶åŠ é€Ÿ\n",
    "            logits = self.model(**inputs)\n",
    "            \n",
    "        # 4. åå¤„ç† (Post-processing)\n",
    "        # Logits -> Probabilities (Softmax)\n",
    "        probs = F.softmax(logits, dim=-1) \n",
    "        \n",
    "        # è·å–æœ€å¤§æ¦‚ç‡å’Œå¯¹åº”çš„ ID\n",
    "        confidence, pred_id = torch.max(probs, dim=-1)\n",
    "        \n",
    "        pred_id = pred_id.item()\n",
    "        confidence = confidence.item()\n",
    "        \n",
    "        return {\n",
    "            \"text\": text,\n",
    "            \"intent\": self.label_map[pred_id], # è½¬åŒ–ä¸ºäººç±»å¯è¯»æ ‡ç­¾\n",
    "            \"confidence\": f\"{confidence:.4f}\",\n",
    "            \"intent_id\": pred_id\n",
    "        }\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a6ca81",
   "metadata": {},
   "source": [
    "## 2 ğŸ’» äº¤äº’å¼ Demoï¼šæŒ‡æŒ¥ä½ çš„æœºå™¨äºº\n",
    "\n",
    "ç°åœ¨å›åˆ° Notebook `S2W7D5_Inference_Deployment.ipynb`ï¼Œæˆ‘ä»¬æ¥æ¨¡æ‹Ÿä¸€ä¸ªçœŸå®çš„æ§åˆ¶å°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a72ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨åŠ è½½æ¨¡å‹è·¯å¾„: /home/goodminton/study/AI-Interview-Sprint/output/train/checkpoints/final_best\n",
      "æ­£åœ¨åŠ è½½æ¨ç†èµ„æº... (Device: cuda)\n",
      "âœ… æƒé‡åŠ è½½æˆåŠŸï¼(å·²å¿½ç•¥å¤šä½™çš„ Loss æƒé‡)\n",
      "\n",
      "========================================\n",
      "ğŸ¤– å…·èº«æ™ºèƒ½æŒ‡ä»¤è§£æç³»ç»Ÿ v2.0 (Weighted)\n",
      "è¾“å…¥ 'q' é€€å‡º\n",
      "========================================\n",
      "  [è§£æç»“æœ] æ„å›¾: MOVE | ç½®ä¿¡åº¦: 74.95%\n",
      "  [æœºå™¨äººåŠ¨ä½œ] ?? åº•ç›˜å¼€å§‹ç§»åŠ¨...\n",
      "  [è§£æç»“æœ] æ„å›¾: GRAB | ç½®ä¿¡åº¦: 48.24%\n",
      "  [æœºå™¨äººåŠ¨ä½œ] âš ï¸ ç½®ä¿¡åº¦è¿‡ä½ï¼Œè¯·æ±‚é‡å¤æŒ‡ä»¤...\n",
      "  [è§£æç»“æœ] æ„å›¾: STOP | ç½®ä¿¡åº¦: 60.89%\n",
      "  [æœºå™¨äººåŠ¨ä½œ] ğŸ›‘ æ‰§è¡Œç´§æ€¥åˆ¶åŠ¨ï¼\n",
      "  [è§£æç»“æœ] æ„å›¾: MOVE | ç½®ä¿¡åº¦: 51.49%\n",
      "  [æœºå™¨äººåŠ¨ä½œ] âš ï¸ ç½®ä¿¡åº¦è¿‡ä½ï¼Œè¯·æ±‚é‡å¤æŒ‡ä»¤...\n",
      "ç³»ç»Ÿä¸‹çº¿ã€‚Bye!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from src.inference import IntentPredictor\n",
    "# â˜… å¼•å…¥ PROJECT_ROOTï¼Œå®ƒæ˜¯é¡¹ç›®æ ¹ç›®å½•çš„ç»å¯¹è·¯å¾„ï¼Œæœ€ç¨³å¥\n",
    "from src.config import CHECKPOINT_DIR \n",
    "\n",
    "# 1. æŒ‡å®šä½ çš„æœ€ä½³ Checkpoint è·¯å¾„\n",
    "# æˆ‘ä»¬åˆ©ç”¨ pathlib çš„è·¯å¾„æ‹¼æ¥åŠŸèƒ½ï¼ŒæŒ‡å‘åˆšæ‰ä¿å­˜çš„ final_best\n",
    "# è·¯å¾„é€»è¾‘: é¡¹ç›®æ ¹ç›®å½• -> output -> train -> weighted_model -> final_best\n",
    "best_ckpt_path = str(CHECKPOINT_DIR / \"final_best\")\n",
    "\n",
    "print(f\"æ­£åœ¨åŠ è½½æ¨¡å‹è·¯å¾„: {best_ckpt_path}\")\n",
    "\n",
    "# 2. å®ä¾‹åŒ–æ¨ç†å¼•æ“\n",
    "# æ³¨æ„ï¼šå¦‚æœæŠ¥é”™è¯´è·¯å¾„ä¸å­˜åœ¨ï¼Œè¯·å»å·¦ä¾§æ–‡ä»¶æ ç¡®è®¤ä¸€ä¸‹ output æ–‡ä»¶å¤¹åˆ°åº•æ˜¯åœ¨æ ¹ç›®å½•è¿˜æ˜¯åœ¨å½“å‰ç›®å½•ä¸‹\n",
    "try:\n",
    "    predictor = IntentPredictor(checkpoint_path=best_ckpt_path, num_labels=3)\n",
    "except Exception as e:\n",
    "    print(\"\\nâš ï¸ è·¯å¾„åŠ è½½å¤±è´¥ï¼Ÿå¯èƒ½æ˜¯å› ä¸ºè®­ç»ƒæ—¶çš„ä¿å­˜è·¯å¾„æ˜¯ç›¸å¯¹è·¯å¾„ã€‚\")\n",
    "    print(\"è¯·å°è¯•å°† best_ckpt_path æ”¹ä¸º: './output/train/weighted_model/final_best'\")\n",
    "    raise e\n",
    "\n",
    "# 3. æ¨¡æ‹Ÿå…·èº«æ™ºèƒ½æ§åˆ¶å°\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"ğŸ¤– å…·èº«æ™ºèƒ½æŒ‡ä»¤è§£æç³»ç»Ÿ v2.0 (Weighted)\")\n",
    "print(\"è¾“å…¥ 'q' é€€å‡º\")\n",
    "print(\"=\"*40)\n",
    " \n",
    "while True:\n",
    "    # æ¨¡æ‹Ÿæ¥æ”¶è¯­éŸ³è½¬æ–‡å­—çš„è¾“å…¥\n",
    "    user_input = input(\"\\nğŸ—£ï¸ è¯·è¾“å…¥æŒ‡ä»¤: \")\n",
    "    \n",
    "    if user_input.lower() == 'q': \n",
    "        print(\"ç³»ç»Ÿä¸‹çº¿ã€‚Bye!\")\n",
    "        break\n",
    "    \n",
    "    if not user_input.strip():\n",
    "        continue\n",
    "        \n",
    "    # è°ƒç”¨é¢„æµ‹\n",
    "    result = predictor.predict(user_input)\n",
    "    \n",
    "    # æ ¼å¼åŒ–è¾“å‡ºç»“æœ\n",
    "    intent = result['intent']\n",
    "    conf = float(result['confidence'])\n",
    "    \n",
    "    # æ¨¡æ‹Ÿæœºå™¨äººå†³ç­–é€»è¾‘\n",
    "    action_log = \"\"\n",
    "    if conf < 0.6:\n",
    "        action_log = \"âš ï¸ ç½®ä¿¡åº¦è¿‡ä½ï¼Œè¯·æ±‚é‡å¤æŒ‡ä»¤...\"\n",
    "    elif intent == \"STOP\":\n",
    "        action_log = \"ğŸ›‘ æ‰§è¡Œç´§æ€¥åˆ¶åŠ¨ï¼\"\n",
    "    elif intent == \"GRAB\":\n",
    "        action_log = \"ğŸ¦¾ å¯åŠ¨æœºæ¢°è‡‚æŠ“å–ç¨‹åº...\"\n",
    "    elif intent == \"MOVE\":\n",
    "        action_log = \"?? åº•ç›˜å¼€å§‹ç§»åŠ¨...\"\n",
    "        \n",
    "    print(f\"  [è§£æç»“æœ] æ„å›¾: {intent} | ç½®ä¿¡åº¦: {conf:.2%}\")\n",
    "    print(f\"  [æœºå™¨äººåŠ¨ä½œ] {action_log}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45ec94b",
   "metadata": {},
   "source": [
    "**ä»»åŠ¡**ï¼š\n",
    "å°è¯•è¾“å…¥ä»¥ä¸‹æŒ‡ä»¤ï¼Œè§‚å¯Ÿæœºå™¨äººååº”ï¼š\n",
    "\n",
    "1.  *\"å¾€å‰èµ°ä¸¤æ­¥\"* (é¢„æœŸ: MOVE)\n",
    "2.  *\"æŠŠå‰é¢çš„çº¢è‰²æ–¹å—æ‹¿èµ·æ¥\"* (é¢„æœŸ: GRAB)\n",
    "3.  *\"åˆ«åŠ¨ï¼\"* (é¢„æœŸ: STOP)\n",
    "4.  *\"ä»Šå¤©å¤©æ°”ä¸é”™\"* (é¢„æœŸ: ç½®ä¿¡åº¦ä½ æˆ– è¯¯åˆ¤ï¼Œè§‚å¯Ÿ Confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166be41b",
   "metadata": {},
   "source": [
    "## 3 ğŸ’¥ é¢è¯•å¿…é—®ï¼šæ¨¡å‹ä¸Šçº¿åå¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ\n",
    "\n",
    "**åœºæ™¯**ï¼š\n",
    "é¢è¯•å®˜é—®ï¼šâ€œé»„åŒå­¦ï¼Œä½ çš„ BERT æ¨¡å‹æ•ˆæœä¸é”™ï¼Œä½†ç°åœ¨æˆ‘ä»¬è¦æŠŠå®ƒéƒ¨ç½²åˆ°æœºå™¨äººçš„åµŒå…¥å¼èŠ¯ç‰‡ï¼ˆå¦‚ Jetson Nanoï¼‰ä¸Šï¼Œæ¯ç§’åªèƒ½è·‘ 3 å¸§ï¼Œå¤ªæ…¢äº†ï¼Œæ€ä¹ˆä¼˜åŒ–ï¼Ÿâ€\n",
    "\n",
    "**æ ‡å‡†å›ç­”æ¨¡æ¿ (ç”±æµ…å…¥æ·±)**ï¼š\n",
    "\n",
    "1.  **å·¥ç¨‹å±‚ä¼˜åŒ– (æœ€å¿«è½åœ°)**ï¼š\n",
    "\n",
    "      * **ONNX Runtime**: å°† PyTorch æ¨¡å‹å¯¼å‡ºä¸º `.onnx` æ ¼å¼ã€‚ONNX Runtime å¯¹å›¾è®¡ç®—åšäº†å¤§é‡åˆå¹¶ä¼˜åŒ–ï¼Œé€šå¸¸èƒ½æé€Ÿ 2-5 å€ã€‚\n",
    "      * **TensorRT**: å¦‚æœæ˜¯ç”¨ NVIDIA çš„èŠ¯ç‰‡ï¼ˆOrin/Jetsonï¼‰ï¼Œè½¬ä¸º TensorRT å¼•æ“æ˜¯ç»ˆææ–¹æ¡ˆï¼Œé’ˆå¯¹ç¡¬ä»¶å±‚çº§ä¼˜åŒ–ã€‚\n",
    "\n",
    "2.  **ç®—æ³•å±‚ä¼˜åŒ– (ç²¾åº¦ç½®æ¢é€Ÿåº¦)**ï¼š\n",
    "\n",
    "      * **é‡åŒ– (Quantization)**: ç›®å‰æˆ‘ä»¬ç”¨çš„æ˜¯ FP32ï¼ˆ32ä½æµ®ç‚¹ï¼‰ã€‚å¯ä»¥è½¬ä¸º **FP16** (åŠç²¾åº¦) ç”šè‡³ **INT8** (8ä½æ•´æ•°)ã€‚æ¨¡å‹ä½“ç§¯å˜æˆ 1/4ï¼Œé€Ÿåº¦é£å¿«ï¼Œç²¾åº¦é€šå¸¸åªæ‰ä¸€ç‚¹ç‚¹ã€‚\n",
    "      * **å‰ªæ (Pruning)**: æŠŠç¥ç»ç½‘ç»œä¸­æƒé‡æ¥è¿‘ 0 çš„è¿æ¥å‰ªæ‰ï¼Œç¨€ç–åŒ–æ¨¡å‹ã€‚\n",
    "\n",
    "3.  **æ¨¡å‹å±‚æ›¿æ¢ (æ¶æ„æ›¿æ¢)**ï¼š\n",
    "\n",
    "      * **è’¸é¦ (Distillation)**: ä½¿ç”¨ **DistilBERT** æˆ– **TinyBERT**ã€‚è®©ä¸€ä¸ªå°æ¨¡å‹å»æ¨¡ä»¿å¤§æ¨¡å‹ï¼ˆTeacherï¼‰çš„è¡Œä¸ºã€‚DistilBERT å‚æ•°é‡å°‘ 40%ï¼Œé€Ÿåº¦å¿« 60%ï¼Œä¿ç•™ 97% çš„æ€§èƒ½ã€‚\n",
    "\n",
    "**åŠ åˆ†æ“ä½œ**:\n",
    "\n",
    "  * *â€œæˆ‘åœ¨é¡¹ç›®ä¸­å…¶å®ä¹Ÿè€ƒè™‘è¿‡è¿™ä¸ªé—®é¢˜ï¼Œæ‰€ä»¥æˆ‘æŠŠ `inference.py` è®¾è®¡å¾—éå¸¸è§£è€¦ï¼Œæœªæ¥åªéœ€è¦æŠŠ `self.model` æ›¿æ¢æˆ `ort.InferenceSession` å°±å¯ä»¥æ— ç¼åˆ‡æ¢åˆ° ONNX Runtimeã€‚â€*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dc8e71",
   "metadata": {},
   "source": [
    "## 4 âš”ï¸ æ¯æ—¥ç®—æ³•é¢˜ (LeetCode 17)\n",
    "\n",
    "ä»Šå¤©æˆ‘ä»¬åšä¸€é“è·Ÿâ€œæ˜ å°„â€æœ‰å…³çš„ç»å…¸å›æº¯é¢˜ç›®ï¼Œéå¸¸é”»ç‚¼é€»è¾‘ã€‚\n",
    "\n",
    "### ğŸ¯ é¢˜ç›®: [LeetCode 17. ç”µè¯å·ç çš„å­—æ¯ç»„åˆ (Letter Combinations of a Phone Number)](../../LeetCode%20practice/1-50.ipynb)\n",
    "\n",
    "  * **éš¾åº¦**: Medium\n",
    "  * **æ ‡ç­¾**: å“ˆå¸Œè¡¨ã€å­—ç¬¦ä¸²ã€å›æº¯ (Backtracking)\n",
    "  * **æè¿°**: ç»™å®šä¸€ä¸ªä»…åŒ…å«æ•°å­— `2-9` çš„å­—ç¬¦ä¸²ï¼Œè¿”å›æ‰€æœ‰å®ƒèƒ½è¡¨ç¤ºçš„å­—æ¯ç»„åˆã€‚ï¼ˆå°±åƒè€å¼æ‰‹æœºé”®ç›˜æŒ‰é”®ï¼‰ã€‚\n",
    "      * è¾“å…¥: `\"23\"`\n",
    "      * è¾“å‡º: `[\"ad\",\"ae\",\"af\",\"bd\",\"be\",\"bf\",\"cd\",\"ce\",\"cf\"]`\n",
    "  * **ä¸ºä»€ä¹ˆé€‰è¿™é¢˜**:\n",
    "      * è¿™æ˜¯æ ‡å‡†çš„ **DFS / å›æº¯** æ¨¡æ¿é¢˜ã€‚\n",
    "      * åœ¨å…·èº«æ™ºèƒ½çš„ä»»åŠ¡è§„åˆ’ï¼ˆTask Planningï¼‰ä¸­ï¼Œç»å¸¸éœ€è¦éå†å¤šç§å¯èƒ½æ€§çš„ç»„åˆè·¯å¾„ï¼Œè¿™ç§æ€ç»´éå¸¸é‡è¦ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d27e03",
   "metadata": {},
   "source": [
    "## âœ… Day 5 ä»»åŠ¡æ¸…å•\n",
    "\n",
    "1.  **ç¼–å†™ `src/inference.py`**: å®ç° `IntentPredictor` ç±»ã€‚\n",
    "2.  **äº¤äº’æµ‹è¯•**: è¿è¡Œ Notebook ä¸­çš„ `while True` å¾ªç¯ï¼Œäº²è‡ªæŒ‡æŒ¥ä½ çš„â€œBERT æœºå™¨äººâ€ï¼Œæµ‹è¯•å®ƒçš„ååº”çµæ•åº¦ã€‚\n",
    "3.  **é¢è¯•å‡†å¤‡**: ç†Ÿè¯»å¹¶ç†è§£â€œæ¨ç†åŠ é€Ÿâ€çš„ä¸‰ç§æ–¹æ¡ˆï¼ˆONNX, é‡åŒ–, è’¸é¦ï¼‰ã€‚\n",
    "4.  **ç®—æ³•**: é€šè¿‡ LeetCode 17ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
