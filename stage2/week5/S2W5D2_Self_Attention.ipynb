{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfa98903",
   "metadata": {},
   "source": [
    "# S2W5D2: çµé­‚æ ¸å¿ƒ - Scaled Dot-Product Attention\n",
    "\n",
    "## 1 æ ¸å¿ƒæ¦‚å¿µï¼šQ\\K\\Våˆ°åº•æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "Tranformerçš„çµæ„Ÿæ¥æºäºæ£€ç´¢ç³»ç»Ÿï¼ˆæ¯”å¦‚ä½ æŸ¥å­—å…¸ï¼Œæˆ–è€…ç”¨æœç´¢å¼•æ“ï¼‰ã€‚æƒ³è±¡ä¸€ä¸‹å»å›¾ä¹¦é¦†æ‰¾ä¹¦ï¼š\n",
    "\n",
    "1. **Query**($Q$)ï¼šä½ æ‰‹é‡Œçš„â€œç´¢ä¹¦å·â€æˆ–è€…ä½ æƒ³æœçš„å…³é”®è¯ï¼ˆæ¯”å¦‚â€œäººå·¥æ™ºèƒ½â€ï¼‰ã€‚\n",
    "2. **Key**($K$)ï¼šå›¾ä¹¦é¦†æ¯æœ¬ä¹¦è„Šä¸Šçš„â€œæ ‡ç­¾â€æˆ–â€œåˆ†ç±»å·â€ã€‚\n",
    "3. **Value**($V$)ï¼šä¹¦é‡Œé¢çš„å…·ä½“**å†…å®¹**ã€‚\n",
    "\n",
    "**æ³¨æ„åŠ›æœºåˆ¶çš„è¿‡ç¨‹**ï¼š\n",
    "\n",
    "1. ä½ æ‹¿ç€ä½ çš„$Q$ï¼Œå»å’Œæ‰€æœ‰çš„$K$è¿›è¡Œ**æ¯”å¯¹**ï¼ˆè®¡ç®—ç›¸ä¼¼åº¦ï¼‰ã€‚\n",
    "2. å¦‚æœ $Q$ å’ŒæŸä¸ª$K$å¾ˆåƒï¼ˆç›¸ä¼¼åº¦é«˜ï¼‰ï¼Œä½ å°±ç»™è¿™æœ¬ä¹¦åˆ†é…æ›´å¤šçš„**å…³æ³¨åº¦**ï¼ˆæƒé‡ï¼‰ã€‚\n",
    "3. æœ€åï¼Œä½ è¯»åˆ°çš„çŸ¥è¯†ï¼Œæ˜¯æ‰€æœ‰ä¹¦çš„å†…å®¹ $V$ æ ¹æ®å…³æ³¨åº¦åŠ æƒèåˆåçš„ç»“æœã€‚\n",
    "\n",
    "> **åœ¨Self-Attentionä¸­**ï¼Œ$Q, K, V$å…¶å®éƒ½æ˜¯åŒä¸€ä¸ªä¸œè¥¿ï¼ˆè¾“å…¥$X$ï¼‰ç»è¿‡ä¸‰ç§ä¸åŒçš„çº¿æ€§å±‚å˜æ¢æ¥çš„ï¼Œä¹Ÿå°±æ˜¯**æˆ‘è‡ªå·±æŸ¥è¯¢æˆ‘è‡ªå·±ï¼Œçœ‹çœ‹æˆ‘å’Œä¸Šä¸‹æ–‡ä¸­å“ªäº›è¯å…³ç³»æœ€ç´§å¯†**ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dd43f8",
   "metadata": {},
   "source": [
    "## 2 æ•°å­¦å…¬å¼\n",
    "\n",
    "å¿…é¡»ç‰¢è®°è¿™ä¸ªå…¬å¼ï¼š\n",
    "\n",
    "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
    "\n",
    "è§£æï¼š\n",
    "\n",
    "1. **$QK^T$**: çŸ©é˜µä¹˜æ³•ã€‚è®¡ç®— **Query** å’Œ **Key** çš„ç›¸ä¼¼åº¦ã€‚\n",
    "    - $Q$ ç»´åº¦: $[Batch, Seq\\_Len, D_k]$\n",
    "    - $K^T$ (è½¬ç½®å) ç»´åº¦: $[Batch, D_k, Seq\\_Len]$\n",
    "    \n",
    "    - ç»“æœç»´åº¦: $[Batch, Seq\\_Len, Seq\\_Len]$ â€”â€” **è¿™æ˜¯ä¸€ä¸ª $N \\times N$ çš„åˆ†æ•°çŸ©é˜µ (Attention Scores)**ã€‚\n",
    "2. **$\\frac{1}{\\sqrt{d_k}}$ (Scale)**: **ç¼©æ”¾**ã€‚ä¸ºä»€ä¹ˆè¦é™¤ä»¥æ ¹å· $d_k$ï¼Ÿï¼ˆé¢è¯•å¿…é—®ï¼Œç¨åè¯¦è§£ï¼‰ã€‚\n",
    "3. **Softmax**: **å½’ä¸€åŒ–**ã€‚æŠŠåˆ†æ•°å˜æˆæ¦‚ç‡ï¼ˆè®©æ¯ä¸€è¡Œçš„å’Œä¸º 1ï¼‰ã€‚\n",
    "4. **$\\dots V$**: **åŠ æƒæ±‚å’Œ**ã€‚ç”¨ç®—å‡ºæ¥çš„æ¦‚ç‡å»ä¹˜ä»¥ $V$ï¼Œå¾—åˆ°æœ€ç»ˆè¾“å‡ºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbcb178",
   "metadata": {},
   "source": [
    "## 3 æ‰‹å†™ä»£ç å®ç°(Hand-Written Implementation)\n",
    "\n",
    "è¿™æ˜¯ä¸€æ®µ **\"å¿…é¡»èƒŒè¯µ\"** çº§åˆ«çš„ä»£ç ã€‚æˆ‘ä»¬å°†å®ç°ä¸€ä¸ªç‹¬ç«‹çš„å‡½æ•° `scaled_dot_product_attention`ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e09ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "    \"\"\"\n",
    "    è®¡ç®—Scaled Dot-Product Attention\n",
    "    \n",
    "    Args:\n",
    "        query:  [batch_size, n_heads, len_q, d_k](ä¸ºäº†é€šç”¨ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œå‡è®¾åˆå¤šå¤´å‚æ•°ï¼Œå•å¤´ä¹Ÿæ˜¯ä¸€æ ·çš„é€»è¾‘)\n",
    "        key:    [batch_size, n_heads, len_k, d_k]\n",
    "        value:  [batch_size, n_heads, len_v, d_v]\n",
    "\n",
    "    Returns:\n",
    "        output: [batch_size, n_heads, len_q, d_v]\n",
    "        attn_weights: [batch_size, n_heads, len_q, len_k]\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. è·å–d_kï¼ˆç”¨äºç¼©æ”¾ï¼‰\n",
    "    d_k = query.size(-1)\n",
    "\n",
    "    # 2. è®¡ç®— QK^T (Matmul)\n",
    "    # query: [..., len_q, d_k]\n",
    "    # key.transpose(-2, -1): [..., d_k, len_k] å°†æœ€åä¸¤ä¸ªç»´åº¦äº¤æ¢ï¼Œåšè½¬ç½®\n",
    "    # scores: [..., len_q, len_k]\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1))\n",
    "\n",
    "    #3. ç¼©æ”¾ï¼ˆScaleï¼‰\n",
    "    # è¿™é‡Œçš„æ•°å­¦æ„ä¹‰æ˜¯é˜²æ­¢ç‚¹ç§¯ç»“æœè¿‡å¤§å¯¼è‡´ Softmax æ¢¯åº¦æ¶ˆå¤±\n",
    "    scores = scores / math.sqrt(d_k)\n",
    "    \n",
    "    # 4. Mask (å¯é€‰)\n",
    "    # å¦‚æœæœ‰ maskï¼ŒæŠŠ mask ä¸º 0 çš„ä½ç½®çš„åˆ†æ•°è®¾ä¸ºè´Ÿæ— ç©·å¤§ (-1e9)\n",
    "    # è¿™æ · Softmax ä¹‹åï¼Œè¿™äº›ä½ç½®çš„æ¦‚ç‡å°±ä¼šå˜æˆ 0\n",
    "    if mask is not None:\n",
    "        # mask == 0çš„åœ°æ–¹ï¼Œå¡«ä¸Š-1e9\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "    # 5. Softmax å½’ä¸€åŒ–\n",
    "    # dim=-1 è¡¨ç¤ºå¯¹æ¯ä¸€è¡Œçš„æœ€åä¸€ä¸ªç»´åº¦(å³é’ˆå¯¹æ‰€æœ‰ key)åšå½’ä¸€åŒ–\n",
    "    attn_weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "    # 6. åŠ æƒæ±‚å’Œ (Weighted Sum)\n",
    "    # attn_weights: [..., len_q, len_k]\n",
    "    # value:        [..., len_k, d_v]\n",
    "    # output:       [..., len_q, d_v]\n",
    "    output = torch.matmul(attn_weights, value)\n",
    "    \n",
    "    return output, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc36e69e",
   "metadata": {},
   "source": [
    "## 4 å•å…ƒæµ‹è¯•\n",
    "\n",
    "æµ‹è¯•ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02092e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query shape: torch.Size([2, 1, 3, 4])\n",
      "Key shape:   torch.Size([2, 1, 3, 4])\n",
      "----------------\n",
      "Output shape:  torch.Size([2, 1, 3, 4]) (åº”è¯¥å’Œ Q ä¿æŒä¸€è‡´)\n",
      "Weights shape: torch.Size([2, 1, 3, 3]) (åº”è¯¥æ˜¯ [Batch, Heads, Seq, Seq])\n",
      "----------------\n",
      "Sum of weights (Check Softmax):\n",
      "tensor([1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "n_heads = 1 # æš‚æ—¶å½“åšå•å¤´æ¥çœ‹\n",
    "seq_len = 3\n",
    "d_k = 4 # å‡è®¾ç‰¹å¾ç»´åº¦æ˜¯ 4\n",
    "\n",
    "# éšæœºç”ŸæˆQ, K, V\n",
    "# å®é™…ä¸­Q, K, Vé€šå¸¸æ¥è‡ªåŒä¸€è¾“å…¥Xç»è¿‡Linearå˜æ¢ï¼Œè¿™é‡Œç®€åŒ–ç›´æ¥éšæœºç”Ÿæˆ\n",
    "q = torch.randn(batch_size, n_heads, seq_len, d_k)\n",
    "k = torch.randn(batch_size, n_heads, seq_len, d_k)\n",
    "v = torch.randn(batch_size, n_heads, seq_len, d_k)\n",
    "\n",
    "print(f\"Query shape: {q.shape}\")\n",
    "print(f\"Key shape:   {k.shape}\")\n",
    "\n",
    "# è°ƒç”¨å‡½æ•°\n",
    "output, weights = scaled_dot_product_attention(q, k, v)\n",
    "\n",
    "print(\"----------------\")\n",
    "print(f\"Output shape:  {output.shape} (åº”è¯¥å’Œ Q ä¿æŒä¸€è‡´)\")\n",
    "print(f\"Weights shape: {weights.shape} (åº”è¯¥æ˜¯ [Batch, Heads, Seq, Seq])\")\n",
    "\n",
    "# éªŒè¯ Softmax æ¯ä¸€è¡Œçš„å’Œæ˜¯å¦ä¸º 1\n",
    "print(\"----------------\")\n",
    "print(\"Sum of weights (Check Softmax):\")\n",
    "print(weights[0][0].sum(dim=-1)) # åº”è¯¥å…¨æ˜¯ 1.0000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3de3891",
   "metadata": {},
   "source": [
    "## 5 æ·±åº¦è§£æ & é¢è¯•å…«è‚¡ (Interview Deep Dive)\n",
    "\n",
    "åšå®Œå®éªŒåï¼Œè¯·åŠ¡å¿…é˜…è¯»ä»¥ä¸‹ä¸‰ä¸ªé—®é¢˜ï¼Œè¿™æ˜¯é¢è¯•å®˜æœ€çˆ±é—®çš„â€œä¸ºä»€ä¹ˆâ€ã€‚\n",
    "\n",
    "### Q1: ä¸ºä»€ä¹ˆè¦é™¤ä»¥ $\\sqrt{d_k}$ï¼Ÿ(Scaling çš„ä½œç”¨)\n",
    "\n",
    "  * **ç°è±¡**: å¦‚æœ $d_k$ (å‘é‡ç»´åº¦) å¾ˆå¤§ï¼Œç‚¹ç§¯ $Q \\cdot K$ çš„ç»“æœæ–¹å·®ä¼šå˜å¤§ï¼Œæ•°å€¼å¯èƒ½ä¼šéå¸¸å¤§ï¼ˆæ¯”å¦‚å‡ ç™¾ï¼‰ã€‚\n",
    "  * **åæœ**: æŠŠå¾ˆå¤§çš„æ•°å–‚ç»™ Softmax å‡½æ•°ï¼ˆæ¯”å¦‚ `softmax([100, 200])`ï¼‰ï¼Œæ¢¯åº¦ä¼šå˜å¾—æå°ï¼ˆè¶‹è¿‘äº 0ï¼‰ï¼Œå¯¼è‡´**æ¢¯åº¦æ¶ˆå¤±**ï¼Œæ¨¡å‹æ— æ³•è®­ç»ƒã€‚\n",
    "  * **è§£å†³**: é™¤ä»¥ $\\sqrt{d_k}$ å¯ä»¥å°†æ•°å€¼æ‹‰å›åˆ°å‡å€¼ä¸º 0ã€æ–¹å·®ä¸º 1 çš„èŒƒå›´å†…ï¼Œä¿è¯æ¢¯åº¦å¹³ç¨³æµè½¬ã€‚\n",
    "\n",
    "### Q2: è¿™é‡Œçš„ Mask æ˜¯å¹²ä»€ä¹ˆç”¨çš„ï¼Ÿ\n",
    "\n",
    "  * **Padding Mask**: è¾“å…¥å¥å­é•¿åº¦ä¸ä¸€ï¼ˆæ¯”å¦‚ \"Hello world \\<pad\\> \\<pad\\>\"ï¼‰ã€‚æ‰€æœ‰çš„ `<pad>` éƒ½æ˜¯æ²¡æœ‰æ„ä¹‰çš„å ä½ç¬¦ã€‚æˆ‘ä»¬ä¸å¸Œæœ›æ¨¡å‹æŠŠæ³¨æ„åŠ›æµªè´¹åœ¨ `<pad>` ä¸Šã€‚æ‰€ä»¥æˆ‘ä»¬åœ¨è®¡ç®— Softmax ä¹‹å‰ï¼ŒæŠŠ `<pad>` å¯¹åº”çš„åˆ†æ•°è®¾ä¸º `-1e9`ï¼Œè¿™æ · `softmax(-1e9) â‰ˆ 0`ï¼Œå®Œç¾å¿½ç•¥ã€‚\n",
    "\n",
    "### Q3: ä¸ºä»€ä¹ˆ $QK^T$ çš„ç»“æœæ˜¯ä¸€ä¸ª $N \\times N$ çš„çŸ©é˜µï¼Ÿ\n",
    "\n",
    "  * å› ä¸ºè¿™æ˜¯ä¸€ä¸ª **\"All-to-All\"** çš„æ¯”è¾ƒã€‚\n",
    "  * çŸ©é˜µçš„ç¬¬ $i$ è¡Œï¼Œç¬¬ $j$ åˆ—çš„æ•°å€¼ï¼Œä»£è¡¨äº† **\"ç¬¬ $i$ ä¸ªè¯ å¯¹ ç¬¬ $j$ ä¸ªè¯ çš„å…³æ³¨åº¦\"**ã€‚\n",
    "  * è¿™å°±æ˜¯ Self-Attention èƒ½å¤Ÿæ•æ‰å…¨å±€ä¾èµ–çš„åŸå› ï¼šæ— è®ºä¸¤ä¸ªè¯è·ç¦»å¤šè¿œï¼Œå®ƒä»¬éƒ½åœ¨è¿™ä¸ªçŸ©é˜µé‡Œç›´æ¥å‘ç”Ÿäº†äº¤äº’ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001fbc33",
   "metadata": {},
   "source": [
    "## ğŸš€ ä»Šæ—¥ä»»åŠ¡\n",
    "\n",
    "1.  **æ‰‹æ•²ä»£ç **: ä¸è¦å¤åˆ¶ï¼Œè¯·æ‰‹åŠ¨è¾“å…¥ä¸€é `scaled_dot_product_attention` å‡½æ•°ï¼Œä½“ä¼š `transpose` å’Œ `matmul` çš„è¿‡ç¨‹ã€‚\n",
    "2.  **è¿è¡Œæµ‹è¯•**: ç¡®ä¿ Output Shape æ­£ç¡®ï¼Œä¸” Softmax æ±‚å’Œä¸º 1ã€‚\n",
    "3.  **æ€è€ƒ**: å¦‚æœ `query` å’Œ `key` æ˜¯å®Œå…¨ä¸€æ ·çš„çŸ©é˜µï¼Œ`weights` å¯¹è§’çº¿ä¸Šçš„æ•°å€¼ä¼šæ¯”è¾ƒå¤§å—ï¼Ÿï¼ˆæç¤ºï¼šè‡ªå·±å’Œè‡ªå·±é€šå¸¸æœ€ç›¸ä¼¼ï¼‰ã€‚\n",
    "\n",
    "ç­‰ä½ è·‘é€šä»£ç ï¼Œæˆ‘ä»¬å°±å®Œæˆäº† Transformer çš„å¿ƒè„æ‰‹æœ¯ï¼æ˜å¤©æˆ‘ä»¬å°†æŠŠè¿™ä¸ªå¿ƒè„å¤åˆ¶ 8 ä»½ï¼Œç»„è£…æˆ **Multi-Head Attention**ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589aacdf",
   "metadata": {},
   "source": [
    "### 1. ã€çƒ­èº«ã€‘LeetCode 867. è½¬ç½®çŸ©é˜µ (Transpose Matrix)\n",
    "* **éš¾åº¦**: ğŸŸ¢ ç®€å•\n",
    "* **é“¾æ¥**: [https://leetcode.cn/problems/transpose-matrix/](https://leetcode.cn/problems/transpose-matrix/)\n",
    "* **ğŸ”¥ ä¸ºä»€ä¹ˆé€‰è¿™é“é¢˜**:\n",
    "    * **ç›´æ¥å¯¹åº”ä»£ç **: è¿™é“é¢˜å°±æ˜¯ä»Šå¤© Attention ä»£ç ä¸­ `key.transpose(-2, -1)` çš„ç‰©ç†å®ç°ï¼\n",
    "    * **æ ¸å¿ƒä»»åŠ¡**: æŠŠ $M \\times N$ çš„çŸ©é˜µå˜æˆ $N \\times M$ã€‚\n",
    "    * **æ³¨æ„äº‹é¡¹**: ä»Šå¤©çš„è¯¾ç¨‹é‡Œé€šè¿‡ PyTorch ä¸€è¡Œä»£ç è§£å†³äº†ï¼Œä½†è¿™é“é¢˜è¦æ±‚ä½ ç†è§£åº•å±‚çš„ç´¢å¼•å˜æ¢è§„åˆ™ `new_matrix[j][i] = matrix[i][j]`ã€‚\n",
    "\n",
    "### 2. ã€è¿›é˜¶ã€‘LeetCode 73. çŸ©é˜µç½®é›¶ (Set Matrix Zeroes)\n",
    "* **éš¾åº¦**: ğŸŸ¡ ä¸­ç­‰\n",
    "* **é“¾æ¥**: [https://leetcode.cn/problems/set-matrix-zeroes/](https://leetcode.cn/problems/set-matrix-zeroes/)\n",
    "* **ğŸ”¥ ä¸ºä»€ä¹ˆé€‰è¿™é“é¢˜**:\n",
    "    * **å…³è”æ¦‚å¿µ**: **Mask (æ©ç )**ã€‚\n",
    "    * **é€»è¾‘æ˜ å°„**: åœ¨ Attention ä¸­ï¼Œæˆ‘ä»¬ç”¨ `masked_fill` æŠŠä¸éœ€è¦å…³æ³¨çš„åœ°æ–¹ï¼ˆPaddingï¼‰å˜æˆè´Ÿæ— ç©·å¤§ï¼ˆç›¸å½“äºâ€œç½®é›¶â€æˆ–æ— æ•ˆåŒ–ï¼‰ã€‚\n",
    "    * **æŒ‘æˆ˜**: è¿™é“é¢˜è¦æ±‚ä½ æŠŠçŸ©é˜µä¸­æ‰€æœ‰ `0` æ‰€åœ¨çš„**æ•´è¡Œ**å’Œ**æ•´åˆ—**éƒ½è®¾ä¸º `0`ã€‚è¿™å¾ˆåƒ Attention ä¸­çš„å¹¿æ’­æœºåˆ¶ï¼ˆBroadcastingï¼‰â€”â€” ä¸€ä¸ªç‚¹å½±å“äº†ä¸€æ•´è¡Œ/åˆ—ã€‚\n",
    "    * **è¦æ±‚**: å°è¯•ç”¨ $O(1)$ çš„ç©ºé—´åŸåœ°è§£å†³ï¼ˆåˆ©ç”¨ç¬¬ä¸€è¡Œ/ç¬¬ä¸€åˆ—å½“åšæ ‡è®°ä½ï¼‰ï¼Œè¿™èƒ½æå¤§åœ°é”»ç‚¼ä½ çš„**åŸåœ°ä¸‹æ ‡æ“ä½œèƒ½åŠ›**ã€‚\n",
    "\n",
    "### 3. ã€æŒ‘æˆ˜ã€‘LeetCode 54. èºæ—‹çŸ©é˜µ (Spiral Matrix)\n",
    "* **éš¾åº¦**: ğŸŸ¡ ä¸­ç­‰\n",
    "* **é“¾æ¥**: [https://leetcode.cn/problems/spiral-matrix/](https://leetcode.cn/problems/spiral-matrix/)\n",
    "* **ğŸ”¥ ä¸ºä»€ä¹ˆé€‰è¿™é“é¢˜**:\n",
    "    * **æ ¸å¿ƒèƒ½åŠ›**: **æè‡´çš„ç´¢å¼•æ§åˆ¶ (Index Manipulation)**ã€‚\n",
    "    * **æ·±åº¦å­¦ä¹ æ˜ å°„**: è™½ç„¶ Transformer ä¸ä¼šèºæ—‹è¯»å–æ•°æ®ï¼Œä½†è¿™é“é¢˜è€ƒå¯Ÿçš„æ˜¯ä½ å¤„ç†è¾¹ç•Œæ¡ä»¶ï¼ˆBoundary Conditionsï¼‰å’Œå¤æ‚éå†é€»è¾‘çš„èƒ½åŠ›ã€‚\n",
    "    * **ç—›ç‚¹**: å†™è¿™é“é¢˜å¾ˆå®¹æ˜“æŠŠè‡ªå·±ç»•æ™•ï¼ˆä»€ä¹ˆæ—¶å€™æ‹å¼¯ï¼Ÿè¾¹ç•Œåœ¨å“ªé‡Œï¼Ÿï¼‰ã€‚å¦‚æœä½ èƒ½ä¸€æ¬¡ AC è¿™é“é¢˜ï¼Œè¯´æ˜ä½ å¯¹å¼ é‡çš„åˆ‡ç‰‡ï¼ˆSlicingï¼‰å’Œç´¢å¼•é€»è¾‘å·²ç»æœ‰äº†éå¸¸æ¸…æ™°çš„å¤´è„‘ï¼ŒDebug å¤æ‚çš„ Model ä»£ç å°±ä¸åœ¨è¯ä¸‹äº†ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "utils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
